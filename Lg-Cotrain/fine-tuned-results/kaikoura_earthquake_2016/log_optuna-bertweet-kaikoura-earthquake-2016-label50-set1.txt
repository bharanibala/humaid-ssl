2026-02-14 01:20:43 - INFO - 
[Optuna] Starting hyperparameter search with 10 trials.
2026-02-14 01:20:43 - INFO - A new study created in memory with name: study_humanitarian9_kaikoura_earthquake_2016
2026-02-14 01:20:43 - INFO - Using devices: cuda, cuda
2026-02-14 01:20:43 - INFO - Devices: cuda, cuda
2026-02-14 01:20:43 - INFO - Starting log
2026-02-14 01:20:43 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:20:44 - INFO - Learning Rate: 0.00011919124313454202
Weight Decay: 0.0007408419801750387
Batch Size: 16
No. Epochs: 13
Epoch Patience: 8
 Accumulation Steps: 4
2026-02-14 01:20:45 - INFO - Generating initial weights
2026-02-14 01:20:50 - INFO - Time taken for Epoch 1:5.15 - F1: 0.0406
2026-02-14 01:20:55 - INFO - Time taken for Epoch 2:5.00 - F1: 0.0086
2026-02-14 01:21:00 - INFO - Time taken for Epoch 3:5.00 - F1: 0.0365
2026-02-14 01:21:05 - INFO - Time taken for Epoch 4:4.99 - F1: 0.0365
2026-02-14 01:21:10 - INFO - Time taken for Epoch 5:5.00 - F1: 0.0365
2026-02-14 01:21:15 - INFO - Time taken for Epoch 6:5.00 - F1: 0.1775
2026-02-14 01:21:20 - INFO - Time taken for Epoch 7:5.00 - F1: 0.2361
2026-02-14 01:21:25 - INFO - Time taken for Epoch 8:5.00 - F1: 0.3527
2026-02-14 01:21:30 - INFO - Time taken for Epoch 9:5.00 - F1: 0.4296
2026-02-14 01:21:35 - INFO - Time taken for Epoch 10:5.00 - F1: 0.5036
2026-02-14 01:21:40 - INFO - Time taken for Epoch 11:5.01 - F1: 0.5731
2026-02-14 01:21:45 - INFO - Time taken for Epoch 12:5.00 - F1: 0.6225
2026-02-14 01:21:50 - INFO - Time taken for Epoch 13:5.00 - F1: 0.6201
2026-02-14 01:21:50 - INFO - Best F1:0.6225 - Best Epoch:12
2026-02-14 01:21:51 - INFO - Starting co-training
2026-02-14 01:21:57 - INFO - Time taken for Epoch 1: 5.55s - F1: 0.13508475
2026-02-14 01:22:03 - INFO - Time taken for Epoch 2: 6.11s - F1: 0.32372442
2026-02-14 01:22:09 - INFO - Time taken for Epoch 3: 6.16s - F1: 0.38139200
2026-02-14 01:22:15 - INFO - Time taken for Epoch 4: 6.18s - F1: 0.37245612
2026-02-14 01:22:21 - INFO - Time taken for Epoch 5: 5.54s - F1: 0.39908471
2026-02-14 01:22:27 - INFO - Time taken for Epoch 6: 6.16s - F1: 0.45269975
2026-02-14 01:22:33 - INFO - Time taken for Epoch 7: 6.16s - F1: 0.44546630
2026-02-14 01:22:39 - INFO - Time taken for Epoch 8: 5.56s - F1: 0.51837007
2026-02-14 01:22:45 - INFO - Time taken for Epoch 9: 6.61s - F1: 0.47975937
2026-02-14 01:22:51 - INFO - Time taken for Epoch 10: 5.53s - F1: 0.53319388
2026-02-14 01:22:57 - INFO - Time taken for Epoch 11: 6.13s - F1: 0.51709076
2026-02-14 01:23:02 - INFO - Time taken for Epoch 12: 5.53s - F1: 0.51610866
2026-02-14 01:23:08 - INFO - Time taken for Epoch 13: 5.54s - F1: 0.41998828
2026-02-14 01:23:09 - INFO - Fine-tuning models
2026-02-14 01:23:12 - INFO - Time taken for Epoch 1:2.33 - F1: 0.4582
2026-02-14 01:23:15 - INFO - Time taken for Epoch 2:2.93 - F1: 0.4774
2026-02-14 01:23:18 - INFO - Time taken for Epoch 3:2.92 - F1: 0.5277
2026-02-14 01:23:21 - INFO - Time taken for Epoch 4:2.96 - F1: 0.5484
2026-02-14 01:23:23 - INFO - Time taken for Epoch 5:2.92 - F1: 0.5892
2026-02-14 01:23:26 - INFO - Time taken for Epoch 6:3.03 - F1: 0.6472
2026-02-14 01:23:30 - INFO - Time taken for Epoch 7:3.11 - F1: 0.5952
2026-02-14 01:23:32 - INFO - Time taken for Epoch 8:2.30 - F1: 0.6625
2026-02-14 01:23:35 - INFO - Time taken for Epoch 9:3.05 - F1: 0.6783
2026-02-14 01:23:38 - INFO - Time taken for Epoch 10:3.05 - F1: 0.6572
2026-02-14 01:23:40 - INFO - Time taken for Epoch 11:2.30 - F1: 0.6656
2026-02-14 01:23:43 - INFO - Time taken for Epoch 12:2.30 - F1: 0.6891
2026-02-14 01:23:46 - INFO - Time taken for Epoch 13:3.12 - F1: 0.6611
2026-02-14 01:23:48 - INFO - Time taken for Epoch 14:2.31 - F1: 0.6741
2026-02-14 01:23:50 - INFO - Time taken for Epoch 15:2.31 - F1: 0.6615
2026-02-14 01:23:53 - INFO - Time taken for Epoch 16:2.31 - F1: 0.6439
2026-02-14 01:23:55 - INFO - Time taken for Epoch 17:2.31 - F1: 0.6586
2026-02-14 01:23:57 - INFO - Time taken for Epoch 18:2.31 - F1: 0.6723
2026-02-14 01:24:00 - INFO - Time taken for Epoch 19:2.31 - F1: 0.6772
2026-02-14 01:24:02 - INFO - Time taken for Epoch 20:2.31 - F1: 0.6528
2026-02-14 01:24:04 - INFO - Time taken for Epoch 21:2.31 - F1: 0.6421
2026-02-14 01:24:07 - INFO - Time taken for Epoch 22:2.31 - F1: 0.6428
2026-02-14 01:24:07 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:24:07 - INFO - Best F1:0.6891 - Best Epoch:11
2026-02-14 01:24:09 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.7604, Test ECE: 0.0525
2026-02-14 01:24:09 - INFO - All results: {'f1_macro': 0.7603710845111459, 'ece': np.float64(0.052492064306105694)}
2026-02-14 01:24:09 - INFO - 
Total time taken: 205.93 seconds
2026-02-14 01:24:09 - INFO - Trial 0 finished with value: 0.7603710845111459 and parameters: {'learning_rate': 0.00011919124313454202, 'weight_decay': 0.0007408419801750387, 'batch_size': 16, 'co_train_epochs': 13, 'epoch_patience': 8}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:24:09 - INFO - Using devices: cuda, cuda
2026-02-14 01:24:09 - INFO - Devices: cuda, cuda
2026-02-14 01:24:09 - INFO - Starting log
2026-02-14 01:24:09 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:24:09 - INFO - Learning Rate: 6.764555273788252e-05
Weight Decay: 7.910918695909644e-05
Batch Size: 16
No. Epochs: 6
Epoch Patience: 5
 Accumulation Steps: 4
2026-02-14 01:24:10 - INFO - Generating initial weights
2026-02-14 01:24:16 - INFO - Time taken for Epoch 1:5.04 - F1: 0.0566
2026-02-14 01:24:21 - INFO - Time taken for Epoch 2:5.02 - F1: 0.0554
2026-02-14 01:24:26 - INFO - Time taken for Epoch 3:5.01 - F1: 0.1720
2026-02-14 01:24:31 - INFO - Time taken for Epoch 4:5.01 - F1: 0.1331
2026-02-14 01:24:36 - INFO - Time taken for Epoch 5:5.01 - F1: 0.1954
2026-02-14 01:24:41 - INFO - Time taken for Epoch 6:5.01 - F1: 0.4438
2026-02-14 01:24:41 - INFO - Best F1:0.4438 - Best Epoch:6
2026-02-14 01:24:41 - INFO - Starting co-training
2026-02-14 01:24:47 - INFO - Time taken for Epoch 1: 5.58s - F1: 0.13763907
2026-02-14 01:24:53 - INFO - Time taken for Epoch 2: 6.16s - F1: 0.32138565
2026-02-14 01:25:00 - INFO - Time taken for Epoch 3: 6.35s - F1: 0.39929636
2026-02-14 01:25:06 - INFO - Time taken for Epoch 4: 6.17s - F1: 0.39785108
2026-02-14 01:25:11 - INFO - Time taken for Epoch 5: 5.55s - F1: 0.41498240
2026-02-14 01:25:17 - INFO - Time taken for Epoch 6: 6.14s - F1: 0.38236199
2026-02-14 01:25:19 - INFO - Fine-tuning models
2026-02-14 01:25:21 - INFO - Time taken for Epoch 1:2.33 - F1: 0.4075
2026-02-14 01:25:24 - INFO - Time taken for Epoch 2:2.89 - F1: 0.5036
2026-02-14 01:25:27 - INFO - Time taken for Epoch 3:2.95 - F1: 0.5477
2026-02-14 01:25:30 - INFO - Time taken for Epoch 4:2.93 - F1: 0.5414
2026-02-14 01:25:32 - INFO - Time taken for Epoch 5:2.31 - F1: 0.5925
2026-02-14 01:25:35 - INFO - Time taken for Epoch 6:2.94 - F1: 0.6359
2026-02-14 01:25:38 - INFO - Time taken for Epoch 7:2.95 - F1: 0.6207
2026-02-14 01:25:41 - INFO - Time taken for Epoch 8:2.31 - F1: 0.6292
2026-02-14 01:25:43 - INFO - Time taken for Epoch 9:2.31 - F1: 0.6326
2026-02-14 01:25:45 - INFO - Time taken for Epoch 10:2.31 - F1: 0.6328
2026-02-14 01:25:47 - INFO - Time taken for Epoch 11:2.31 - F1: 0.6431
2026-02-14 01:25:50 - INFO - Time taken for Epoch 12:2.95 - F1: 0.6249
2026-02-14 01:25:53 - INFO - Time taken for Epoch 13:2.31 - F1: 0.6485
2026-02-14 01:25:56 - INFO - Time taken for Epoch 14:3.27 - F1: 0.6294
2026-02-14 01:25:58 - INFO - Time taken for Epoch 15:2.31 - F1: 0.6789
2026-02-14 01:26:06 - INFO - Time taken for Epoch 16:8.11 - F1: 0.6572
2026-02-14 01:26:09 - INFO - Time taken for Epoch 17:2.30 - F1: 0.6859
2026-02-14 01:26:12 - INFO - Time taken for Epoch 18:2.91 - F1: 0.6691
2026-02-14 01:26:14 - INFO - Time taken for Epoch 19:2.31 - F1: 0.6742
2026-02-14 01:26:16 - INFO - Time taken for Epoch 20:2.31 - F1: 0.6722
2026-02-14 01:26:19 - INFO - Time taken for Epoch 21:2.30 - F1: 0.6701
2026-02-14 01:26:21 - INFO - Time taken for Epoch 22:2.30 - F1: 0.6747
2026-02-14 01:26:23 - INFO - Time taken for Epoch 23:2.31 - F1: 0.6747
2026-02-14 01:26:25 - INFO - Time taken for Epoch 24:2.31 - F1: 0.6787
2026-02-14 01:26:28 - INFO - Time taken for Epoch 25:2.31 - F1: 0.6787
2026-02-14 01:26:30 - INFO - Time taken for Epoch 26:2.31 - F1: 0.6787
2026-02-14 01:26:32 - INFO - Time taken for Epoch 27:2.31 - F1: 0.6787
2026-02-14 01:26:32 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:26:32 - INFO - Best F1:0.6859 - Best Epoch:16
2026-02-14 01:26:35 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.7536, Test ECE: 0.0679
2026-02-14 01:26:35 - INFO - All results: {'f1_macro': 0.7535684735426502, 'ece': np.float64(0.067903121860548)}
2026-02-14 01:26:35 - INFO - 
Total time taken: 145.78 seconds
2026-02-14 01:26:35 - INFO - Trial 1 finished with value: 0.7535684735426502 and parameters: {'learning_rate': 6.764555273788252e-05, 'weight_decay': 7.910918695909644e-05, 'batch_size': 16, 'co_train_epochs': 6, 'epoch_patience': 5}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:26:35 - INFO - Using devices: cuda, cuda
2026-02-14 01:26:35 - INFO - Devices: cuda, cuda
2026-02-14 01:26:35 - INFO - Starting log
2026-02-14 01:26:35 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:26:35 - INFO - Learning Rate: 5.233205645597941e-05
Weight Decay: 3.024595846277873e-05
Batch Size: 16
No. Epochs: 12
Epoch Patience: 8
 Accumulation Steps: 4
2026-02-14 01:26:36 - INFO - Generating initial weights
2026-02-14 01:26:41 - INFO - Time taken for Epoch 1:5.06 - F1: 0.0503
2026-02-14 01:26:46 - INFO - Time taken for Epoch 2:5.02 - F1: 0.0614
2026-02-14 01:26:51 - INFO - Time taken for Epoch 3:5.01 - F1: 0.2181
2026-02-14 01:26:56 - INFO - Time taken for Epoch 4:5.01 - F1: 0.1266
2026-02-14 01:27:01 - INFO - Time taken for Epoch 5:5.02 - F1: 0.2172
2026-02-14 01:27:06 - INFO - Time taken for Epoch 6:5.02 - F1: 0.4603
2026-02-14 01:27:11 - INFO - Time taken for Epoch 7:5.02 - F1: 0.5427
2026-02-14 01:27:16 - INFO - Time taken for Epoch 8:5.02 - F1: 0.5222
2026-02-14 01:27:21 - INFO - Time taken for Epoch 9:5.02 - F1: 0.5779
2026-02-14 01:27:26 - INFO - Time taken for Epoch 10:5.02 - F1: 0.5713
2026-02-14 01:27:31 - INFO - Time taken for Epoch 11:5.01 - F1: 0.5892
2026-02-14 01:27:36 - INFO - Time taken for Epoch 12:5.02 - F1: 0.6069
2026-02-14 01:27:36 - INFO - Best F1:0.6069 - Best Epoch:12
2026-02-14 01:27:37 - INFO - Starting co-training
2026-02-14 01:27:43 - INFO - Time taken for Epoch 1: 5.55s - F1: 0.13047842
2026-02-14 01:27:49 - INFO - Time taken for Epoch 2: 6.23s - F1: 0.22720181
2026-02-14 01:27:55 - INFO - Time taken for Epoch 3: 6.38s - F1: 0.31126988
2026-02-14 01:28:02 - INFO - Time taken for Epoch 4: 6.35s - F1: 0.38117458
2026-02-14 01:28:08 - INFO - Time taken for Epoch 5: 6.26s - F1: 0.41078592
2026-02-14 01:28:14 - INFO - Time taken for Epoch 6: 6.20s - F1: 0.43537386
2026-02-14 01:28:20 - INFO - Time taken for Epoch 7: 6.35s - F1: 0.42841015
2026-02-14 01:28:26 - INFO - Time taken for Epoch 8: 5.56s - F1: 0.42738671
2026-02-14 01:28:31 - INFO - Time taken for Epoch 9: 5.55s - F1: 0.44806104
2026-02-14 01:28:38 - INFO - Time taken for Epoch 10: 6.22s - F1: 0.38515025
2026-02-14 01:28:43 - INFO - Time taken for Epoch 11: 5.54s - F1: 0.40965443
2026-02-14 01:28:49 - INFO - Time taken for Epoch 12: 5.55s - F1: 0.48949474
2026-02-14 01:28:51 - INFO - Fine-tuning models
2026-02-14 01:28:53 - INFO - Time taken for Epoch 1:2.32 - F1: 0.5098
2026-02-14 01:28:56 - INFO - Time taken for Epoch 2:3.08 - F1: 0.4531
2026-02-14 01:28:59 - INFO - Time taken for Epoch 3:2.30 - F1: 0.5305
2026-02-14 01:29:02 - INFO - Time taken for Epoch 4:2.94 - F1: 0.6354
2026-02-14 01:29:04 - INFO - Time taken for Epoch 5:2.92 - F1: 0.6598
2026-02-14 01:29:07 - INFO - Time taken for Epoch 6:2.91 - F1: 0.6390
2026-02-14 01:29:10 - INFO - Time taken for Epoch 7:2.31 - F1: 0.6361
2026-02-14 01:29:12 - INFO - Time taken for Epoch 8:2.31 - F1: 0.6335
2026-02-14 01:29:14 - INFO - Time taken for Epoch 9:2.31 - F1: 0.6644
2026-02-14 01:29:17 - INFO - Time taken for Epoch 10:3.08 - F1: 0.6584
2026-02-14 01:29:20 - INFO - Time taken for Epoch 11:2.31 - F1: 0.6600
2026-02-14 01:29:22 - INFO - Time taken for Epoch 12:2.31 - F1: 0.6596
2026-02-14 01:29:24 - INFO - Time taken for Epoch 13:2.31 - F1: 0.6571
2026-02-14 01:29:27 - INFO - Time taken for Epoch 14:2.31 - F1: 0.6823
2026-02-14 01:29:37 - INFO - Time taken for Epoch 15:9.91 - F1: 0.6618
2026-02-14 01:29:39 - INFO - Time taken for Epoch 16:2.30 - F1: 0.6566
2026-02-14 01:29:41 - INFO - Time taken for Epoch 17:2.30 - F1: 0.6536
2026-02-14 01:29:43 - INFO - Time taken for Epoch 18:2.30 - F1: 0.6578
2026-02-14 01:29:46 - INFO - Time taken for Epoch 19:2.31 - F1: 0.6788
2026-02-14 01:29:48 - INFO - Time taken for Epoch 20:2.31 - F1: 0.6840
2026-02-14 01:29:51 - INFO - Time taken for Epoch 21:2.96 - F1: 0.6910
2026-02-14 01:29:54 - INFO - Time taken for Epoch 22:2.92 - F1: 0.6933
2026-02-14 01:29:57 - INFO - Time taken for Epoch 23:2.96 - F1: 0.6882
2026-02-14 01:29:59 - INFO - Time taken for Epoch 24:2.31 - F1: 0.6871
2026-02-14 01:30:02 - INFO - Time taken for Epoch 25:2.31 - F1: 0.6808
2026-02-14 01:30:04 - INFO - Time taken for Epoch 26:2.31 - F1: 0.6808
2026-02-14 01:30:06 - INFO - Time taken for Epoch 27:2.31 - F1: 0.6808
2026-02-14 01:30:08 - INFO - Time taken for Epoch 28:2.31 - F1: 0.6808
2026-02-14 01:30:11 - INFO - Time taken for Epoch 29:2.32 - F1: 0.6855
2026-02-14 01:30:13 - INFO - Time taken for Epoch 30:2.31 - F1: 0.6855
2026-02-14 01:30:15 - INFO - Time taken for Epoch 31:2.32 - F1: 0.6855
2026-02-14 01:30:18 - INFO - Time taken for Epoch 32:2.30 - F1: 0.6836
2026-02-14 01:30:18 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:30:18 - INFO - Best F1:0.6933 - Best Epoch:21
2026-02-14 01:30:20 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.7198, Test ECE: 0.0725
2026-02-14 01:30:20 - INFO - All results: {'f1_macro': 0.7197654341542419, 'ece': np.float64(0.07253910357924714)}
2026-02-14 01:30:20 - INFO - 
Total time taken: 225.30 seconds
2026-02-14 01:30:20 - INFO - Trial 2 finished with value: 0.7197654341542419 and parameters: {'learning_rate': 5.233205645597941e-05, 'weight_decay': 3.024595846277873e-05, 'batch_size': 16, 'co_train_epochs': 12, 'epoch_patience': 8}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:30:20 - INFO - Using devices: cuda, cuda
2026-02-14 01:30:20 - INFO - Devices: cuda, cuda
2026-02-14 01:30:20 - INFO - Starting log
2026-02-14 01:30:20 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:30:21 - INFO - Learning Rate: 9.701642772514863e-05
Weight Decay: 0.001359240251842841
Batch Size: 8
No. Epochs: 17
Epoch Patience: 9
 Accumulation Steps: 8
2026-02-14 01:30:21 - INFO - Generating initial weights
2026-02-14 01:30:28 - INFO - Time taken for Epoch 1:5.85 - F1: 0.0520
2026-02-14 01:30:33 - INFO - Time taken for Epoch 2:5.83 - F1: 0.0580
2026-02-14 01:30:39 - INFO - Time taken for Epoch 3:5.83 - F1: 0.0872
2026-02-14 01:30:45 - INFO - Time taken for Epoch 4:5.83 - F1: 0.1155
2026-02-14 01:30:51 - INFO - Time taken for Epoch 5:5.82 - F1: 0.1867
2026-02-14 01:30:57 - INFO - Time taken for Epoch 6:5.83 - F1: 0.4426
2026-02-14 01:31:02 - INFO - Time taken for Epoch 7:5.82 - F1: 0.5069
2026-02-14 01:31:08 - INFO - Time taken for Epoch 8:5.83 - F1: 0.5608
2026-02-14 01:31:14 - INFO - Time taken for Epoch 9:5.83 - F1: 0.5602
2026-02-14 01:31:20 - INFO - Time taken for Epoch 10:5.85 - F1: 0.6153
2026-02-14 01:31:26 - INFO - Time taken for Epoch 11:5.83 - F1: 0.5985
2026-02-14 01:31:32 - INFO - Time taken for Epoch 12:5.82 - F1: 0.6589
2026-02-14 01:31:37 - INFO - Time taken for Epoch 13:5.82 - F1: 0.6264
2026-02-14 01:31:43 - INFO - Time taken for Epoch 14:5.83 - F1: 0.6542
2026-02-14 01:31:49 - INFO - Time taken for Epoch 15:5.83 - F1: 0.6187
2026-02-14 01:31:55 - INFO - Time taken for Epoch 16:5.82 - F1: 0.6511
2026-02-14 01:32:01 - INFO - Time taken for Epoch 17:5.84 - F1: 0.6317
2026-02-14 01:32:01 - INFO - Best F1:0.6589 - Best Epoch:12
2026-02-14 01:32:01 - INFO - Starting co-training
2026-02-14 01:32:07 - INFO - Time taken for Epoch 1: 5.49s - F1: 0.13442694
2026-02-14 01:32:13 - INFO - Time taken for Epoch 2: 6.06s - F1: 0.14373902
2026-02-14 01:32:19 - INFO - Time taken for Epoch 3: 6.11s - F1: 0.18630913
2026-02-14 01:32:25 - INFO - Time taken for Epoch 4: 6.13s - F1: 0.33734444
2026-02-14 01:32:31 - INFO - Time taken for Epoch 5: 6.15s - F1: 0.38430681
2026-02-14 01:32:38 - INFO - Time taken for Epoch 6: 6.14s - F1: 0.32767111
2026-02-14 01:32:43 - INFO - Time taken for Epoch 7: 5.49s - F1: 0.38863334
2026-02-14 01:32:54 - INFO - Time taken for Epoch 8: 11.28s - F1: 0.38537204
2026-02-14 01:33:00 - INFO - Time taken for Epoch 9: 5.48s - F1: 0.37056480
2026-02-14 01:33:05 - INFO - Time taken for Epoch 10: 5.47s - F1: 0.41605056
2026-02-14 01:33:11 - INFO - Time taken for Epoch 11: 6.15s - F1: 0.39591846
2026-02-14 01:33:17 - INFO - Time taken for Epoch 12: 5.48s - F1: 0.41017513
2026-02-14 01:33:22 - INFO - Time taken for Epoch 13: 5.49s - F1: 0.38353588
2026-02-14 01:33:28 - INFO - Time taken for Epoch 14: 5.50s - F1: 0.39273481
2026-02-14 01:33:33 - INFO - Time taken for Epoch 15: 5.49s - F1: 0.38960344
2026-02-14 01:33:39 - INFO - Time taken for Epoch 16: 5.50s - F1: 0.39569303
2026-02-14 01:33:44 - INFO - Time taken for Epoch 17: 5.48s - F1: 0.43975709
2026-02-14 01:33:47 - INFO - Fine-tuning models
2026-02-14 01:33:49 - INFO - Time taken for Epoch 1:2.76 - F1: 0.4977
2026-02-14 01:33:53 - INFO - Time taken for Epoch 2:3.37 - F1: 0.4823
2026-02-14 01:33:56 - INFO - Time taken for Epoch 3:2.74 - F1: 0.5754
2026-02-14 01:33:59 - INFO - Time taken for Epoch 4:3.43 - F1: 0.5925
2026-02-14 01:34:02 - INFO - Time taken for Epoch 5:3.33 - F1: 0.6234
2026-02-14 01:34:06 - INFO - Time taken for Epoch 6:3.37 - F1: 0.6204
2026-02-14 01:34:08 - INFO - Time taken for Epoch 7:2.74 - F1: 0.6404
2026-02-14 01:34:12 - INFO - Time taken for Epoch 8:3.36 - F1: 0.6445
2026-02-14 01:34:15 - INFO - Time taken for Epoch 9:3.40 - F1: 0.6536
2026-02-14 01:34:19 - INFO - Time taken for Epoch 10:3.35 - F1: 0.6619
2026-02-14 01:34:22 - INFO - Time taken for Epoch 11:3.38 - F1: 0.6529
2026-02-14 01:34:25 - INFO - Time taken for Epoch 12:2.74 - F1: 0.6741
2026-02-14 01:34:38 - INFO - Time taken for Epoch 13:13.43 - F1: 0.6936
2026-02-14 01:34:42 - INFO - Time taken for Epoch 14:3.44 - F1: 0.7198
2026-02-14 01:34:45 - INFO - Time taken for Epoch 15:3.36 - F1: 0.7358
2026-02-14 01:34:48 - INFO - Time taken for Epoch 16:3.41 - F1: 0.7046
2026-02-14 01:34:51 - INFO - Time taken for Epoch 17:2.73 - F1: 0.6629
2026-02-14 01:34:54 - INFO - Time taken for Epoch 18:2.74 - F1: 0.6701
2026-02-14 01:34:57 - INFO - Time taken for Epoch 19:2.74 - F1: 0.6615
2026-02-14 01:34:59 - INFO - Time taken for Epoch 20:2.74 - F1: 0.6461
2026-02-14 01:35:02 - INFO - Time taken for Epoch 21:2.75 - F1: 0.6390
2026-02-14 01:35:05 - INFO - Time taken for Epoch 22:2.75 - F1: 0.6567
2026-02-14 01:35:08 - INFO - Time taken for Epoch 23:2.74 - F1: 0.6889
2026-02-14 01:35:10 - INFO - Time taken for Epoch 24:2.74 - F1: 0.6481
2026-02-14 01:35:13 - INFO - Time taken for Epoch 25:2.75 - F1: 0.6755
2026-02-14 01:35:13 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:35:13 - INFO - Best F1:0.7358 - Best Epoch:14
2026-02-14 01:35:16 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6973, Test ECE: 0.0792
2026-02-14 01:35:16 - INFO - All results: {'f1_macro': 0.6972696472346583, 'ece': np.float64(0.07920062363832847)}
2026-02-14 01:35:16 - INFO - 
Total time taken: 295.46 seconds
2026-02-14 01:35:16 - INFO - Trial 3 finished with value: 0.6972696472346583 and parameters: {'learning_rate': 9.701642772514863e-05, 'weight_decay': 0.001359240251842841, 'batch_size': 8, 'co_train_epochs': 17, 'epoch_patience': 9}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:35:16 - INFO - Using devices: cuda, cuda
2026-02-14 01:35:16 - INFO - Devices: cuda, cuda
2026-02-14 01:35:16 - INFO - Starting log
2026-02-14 01:35:16 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:35:16 - INFO - Learning Rate: 8.796855938969102e-05
Weight Decay: 0.00904933552804665
Batch Size: 16
No. Epochs: 11
Epoch Patience: 6
 Accumulation Steps: 4
2026-02-14 01:35:17 - INFO - Generating initial weights
2026-02-14 01:35:22 - INFO - Time taken for Epoch 1:5.04 - F1: 0.0416
2026-02-14 01:35:27 - INFO - Time taken for Epoch 2:5.01 - F1: 0.0275
2026-02-14 01:35:32 - INFO - Time taken for Epoch 3:5.03 - F1: 0.0497
2026-02-14 01:35:37 - INFO - Time taken for Epoch 4:5.02 - F1: 0.1027
2026-02-14 01:35:42 - INFO - Time taken for Epoch 5:5.02 - F1: 0.1409
2026-02-14 01:35:47 - INFO - Time taken for Epoch 6:5.01 - F1: 0.4053
2026-02-14 01:35:52 - INFO - Time taken for Epoch 7:5.01 - F1: 0.4972
2026-02-14 01:35:57 - INFO - Time taken for Epoch 8:5.02 - F1: 0.5557
2026-02-14 01:36:02 - INFO - Time taken for Epoch 9:5.02 - F1: 0.6043
2026-02-14 01:36:07 - INFO - Time taken for Epoch 10:5.02 - F1: 0.6027
2026-02-14 01:36:12 - INFO - Time taken for Epoch 11:5.02 - F1: 0.6030
2026-02-14 01:36:12 - INFO - Best F1:0.6043 - Best Epoch:9
2026-02-14 01:36:13 - INFO - Starting co-training
2026-02-14 01:36:18 - INFO - Time taken for Epoch 1: 5.55s - F1: 0.12585846
2026-02-14 01:36:25 - INFO - Time taken for Epoch 2: 6.22s - F1: 0.24442829
2026-02-14 01:36:31 - INFO - Time taken for Epoch 3: 6.16s - F1: 0.40050702
2026-02-14 01:36:37 - INFO - Time taken for Epoch 4: 6.67s - F1: 0.41295763
2026-02-14 01:36:44 - INFO - Time taken for Epoch 5: 6.16s - F1: 0.38630940
2026-02-14 01:36:49 - INFO - Time taken for Epoch 6: 5.54s - F1: 0.46979009
2026-02-14 01:36:55 - INFO - Time taken for Epoch 7: 6.11s - F1: 0.48139944
2026-02-14 01:37:08 - INFO - Time taken for Epoch 8: 12.24s - F1: 0.52860319
2026-02-14 01:37:14 - INFO - Time taken for Epoch 9: 6.14s - F1: 0.53159257
2026-02-14 01:37:20 - INFO - Time taken for Epoch 10: 6.12s - F1: 0.53092434
2026-02-14 01:37:25 - INFO - Time taken for Epoch 11: 5.53s - F1: 0.47767315
2026-02-14 01:37:27 - INFO - Fine-tuning models
2026-02-14 01:37:29 - INFO - Time taken for Epoch 1:2.32 - F1: 0.3861
2026-02-14 01:37:32 - INFO - Time taken for Epoch 2:2.90 - F1: 0.5881
2026-02-14 01:37:35 - INFO - Time taken for Epoch 3:2.92 - F1: 0.6273
2026-02-14 01:37:38 - INFO - Time taken for Epoch 4:2.98 - F1: 0.6314
2026-02-14 01:37:41 - INFO - Time taken for Epoch 5:2.91 - F1: 0.6667
2026-02-14 01:37:44 - INFO - Time taken for Epoch 6:2.91 - F1: 0.6694
2026-02-14 01:37:46 - INFO - Time taken for Epoch 7:2.91 - F1: 0.6512
2026-02-14 01:37:49 - INFO - Time taken for Epoch 8:2.30 - F1: 0.6508
2026-02-14 01:37:51 - INFO - Time taken for Epoch 9:2.31 - F1: 0.6664
2026-02-14 01:37:53 - INFO - Time taken for Epoch 10:2.30 - F1: 0.6575
2026-02-14 01:37:56 - INFO - Time taken for Epoch 11:2.31 - F1: 0.6566
2026-02-14 01:37:58 - INFO - Time taken for Epoch 12:2.31 - F1: 0.6642
2026-02-14 01:38:00 - INFO - Time taken for Epoch 13:2.31 - F1: 0.6569
2026-02-14 01:38:03 - INFO - Time taken for Epoch 14:2.31 - F1: 0.6527
2026-02-14 01:38:05 - INFO - Time taken for Epoch 15:2.31 - F1: 0.6337
2026-02-14 01:38:07 - INFO - Time taken for Epoch 16:2.32 - F1: 0.6567
2026-02-14 01:38:07 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:38:07 - INFO - Best F1:0.6694 - Best Epoch:5
2026-02-14 01:38:10 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6519, Test ECE: 0.0589
2026-02-14 01:38:10 - INFO - All results: {'f1_macro': 0.6518974625792602, 'ece': np.float64(0.05893837994542616)}
2026-02-14 01:38:10 - INFO - 
Total time taken: 174.06 seconds
2026-02-14 01:38:10 - INFO - Trial 4 finished with value: 0.6518974625792602 and parameters: {'learning_rate': 8.796855938969102e-05, 'weight_decay': 0.00904933552804665, 'batch_size': 16, 'co_train_epochs': 11, 'epoch_patience': 6}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:38:10 - INFO - Using devices: cuda, cuda
2026-02-14 01:38:10 - INFO - Devices: cuda, cuda
2026-02-14 01:38:10 - INFO - Starting log
2026-02-14 01:38:10 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:38:10 - INFO - Learning Rate: 1.2195866448930713e-05
Weight Decay: 0.00015379505943088307
Batch Size: 8
No. Epochs: 16
Epoch Patience: 9
 Accumulation Steps: 8
2026-02-14 01:38:11 - INFO - Generating initial weights
2026-02-14 01:38:17 - INFO - Time taken for Epoch 1:5.87 - F1: 0.0406
2026-02-14 01:38:23 - INFO - Time taken for Epoch 2:5.82 - F1: 0.0406
2026-02-14 01:38:29 - INFO - Time taken for Epoch 3:5.82 - F1: 0.0462
2026-02-14 01:38:34 - INFO - Time taken for Epoch 4:5.84 - F1: 0.1306
2026-02-14 01:38:40 - INFO - Time taken for Epoch 5:5.84 - F1: 0.0825
2026-02-14 01:38:46 - INFO - Time taken for Epoch 6:5.84 - F1: 0.0454
2026-02-14 01:38:52 - INFO - Time taken for Epoch 7:5.84 - F1: 0.0460
2026-02-14 01:38:58 - INFO - Time taken for Epoch 8:5.84 - F1: 0.0460
2026-02-14 01:39:04 - INFO - Time taken for Epoch 9:5.84 - F1: 0.0456
2026-02-14 01:39:09 - INFO - Time taken for Epoch 10:5.83 - F1: 0.0824
2026-02-14 01:39:15 - INFO - Time taken for Epoch 11:5.84 - F1: 0.1998
2026-02-14 01:39:21 - INFO - Time taken for Epoch 12:5.84 - F1: 0.2864
2026-02-14 01:39:27 - INFO - Time taken for Epoch 13:5.84 - F1: 0.3632
2026-02-14 01:39:33 - INFO - Time taken for Epoch 14:5.85 - F1: 0.4179
2026-02-14 01:39:39 - INFO - Time taken for Epoch 15:5.84 - F1: 0.4536
2026-02-14 01:39:44 - INFO - Time taken for Epoch 16:5.84 - F1: 0.4791
2026-02-14 01:39:44 - INFO - Best F1:0.4791 - Best Epoch:16
2026-02-14 01:39:45 - INFO - Starting co-training
2026-02-14 01:39:51 - INFO - Time taken for Epoch 1: 5.49s - F1: 0.03648425
2026-02-14 01:39:57 - INFO - Time taken for Epoch 2: 6.29s - F1: 0.03648425
2026-02-14 01:40:02 - INFO - Time taken for Epoch 3: 5.49s - F1: 0.12496818
2026-02-14 01:40:09 - INFO - Time taken for Epoch 4: 6.33s - F1: 0.14044527
2026-02-14 01:40:15 - INFO - Time taken for Epoch 5: 6.22s - F1: 0.13902141
2026-02-14 01:40:20 - INFO - Time taken for Epoch 6: 5.49s - F1: 0.13409759
2026-02-14 01:40:26 - INFO - Time taken for Epoch 7: 5.50s - F1: 0.19568356
2026-02-14 01:40:37 - INFO - Time taken for Epoch 8: 11.39s - F1: 0.19757585
2026-02-14 01:40:43 - INFO - Time taken for Epoch 9: 6.13s - F1: 0.23052276
2026-02-14 01:40:50 - INFO - Time taken for Epoch 10: 6.11s - F1: 0.26966532
2026-02-14 01:40:56 - INFO - Time taken for Epoch 11: 6.10s - F1: 0.31654108
2026-02-14 01:41:02 - INFO - Time taken for Epoch 12: 6.15s - F1: 0.36736153
2026-02-14 01:41:08 - INFO - Time taken for Epoch 13: 6.12s - F1: 0.38220503
2026-02-14 01:41:18 - INFO - Time taken for Epoch 14: 10.15s - F1: 0.38148702
2026-02-14 01:41:24 - INFO - Time taken for Epoch 15: 5.49s - F1: 0.38263695
2026-02-14 01:41:30 - INFO - Time taken for Epoch 16: 6.15s - F1: 0.35356591
2026-02-14 01:41:31 - INFO - Fine-tuning models
2026-02-14 01:41:34 - INFO - Time taken for Epoch 1:2.75 - F1: 0.4064
2026-02-14 01:41:37 - INFO - Time taken for Epoch 2:3.36 - F1: 0.4013
2026-02-14 01:41:40 - INFO - Time taken for Epoch 3:2.74 - F1: 0.3980
2026-02-14 01:41:43 - INFO - Time taken for Epoch 4:2.74 - F1: 0.4188
2026-02-14 01:41:46 - INFO - Time taken for Epoch 5:3.36 - F1: 0.4332
2026-02-14 01:41:49 - INFO - Time taken for Epoch 6:3.34 - F1: 0.4204
2026-02-14 01:41:52 - INFO - Time taken for Epoch 7:2.74 - F1: 0.4559
2026-02-14 01:41:55 - INFO - Time taken for Epoch 8:3.35 - F1: 0.5035
2026-02-14 01:41:59 - INFO - Time taken for Epoch 9:3.40 - F1: 0.5282
2026-02-14 01:42:02 - INFO - Time taken for Epoch 10:3.41 - F1: 0.5306
2026-02-14 01:42:06 - INFO - Time taken for Epoch 11:3.38 - F1: 0.5487
2026-02-14 01:42:17 - INFO - Time taken for Epoch 12:11.49 - F1: 0.5533
2026-02-14 01:42:21 - INFO - Time taken for Epoch 13:3.94 - F1: 0.5784
2026-02-14 01:42:24 - INFO - Time taken for Epoch 14:3.43 - F1: 0.5705
2026-02-14 01:42:27 - INFO - Time taken for Epoch 15:2.73 - F1: 0.5752
2026-02-14 01:42:30 - INFO - Time taken for Epoch 16:2.73 - F1: 0.5790
2026-02-14 01:42:34 - INFO - Time taken for Epoch 17:3.60 - F1: 0.6009
2026-02-14 01:42:37 - INFO - Time taken for Epoch 18:3.52 - F1: 0.5816
2026-02-14 01:42:40 - INFO - Time taken for Epoch 19:2.73 - F1: 0.5847
2026-02-14 01:42:43 - INFO - Time taken for Epoch 20:2.73 - F1: 0.5876
2026-02-14 01:42:45 - INFO - Time taken for Epoch 21:2.74 - F1: 0.5778
2026-02-14 01:42:48 - INFO - Time taken for Epoch 22:2.75 - F1: 0.5945
2026-02-14 01:42:51 - INFO - Time taken for Epoch 23:2.74 - F1: 0.5770
2026-02-14 01:42:54 - INFO - Time taken for Epoch 24:2.74 - F1: 0.5773
2026-02-14 01:42:56 - INFO - Time taken for Epoch 25:2.74 - F1: 0.5738
2026-02-14 01:42:59 - INFO - Time taken for Epoch 26:2.73 - F1: 0.5750
2026-02-14 01:43:02 - INFO - Time taken for Epoch 27:2.74 - F1: 0.5779
2026-02-14 01:43:02 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:43:02 - INFO - Best F1:0.6009 - Best Epoch:16
2026-02-14 01:43:04 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.5541, Test ECE: 0.1061
2026-02-14 01:43:04 - INFO - All results: {'f1_macro': 0.5541133266874324, 'ece': np.float64(0.10608535258249305)}
2026-02-14 01:43:04 - INFO - 
Total time taken: 294.61 seconds
2026-02-14 01:43:04 - INFO - Trial 5 finished with value: 0.5541133266874324 and parameters: {'learning_rate': 1.2195866448930713e-05, 'weight_decay': 0.00015379505943088307, 'batch_size': 8, 'co_train_epochs': 16, 'epoch_patience': 9}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:43:04 - INFO - Using devices: cuda, cuda
2026-02-14 01:43:04 - INFO - Devices: cuda, cuda
2026-02-14 01:43:04 - INFO - Starting log
2026-02-14 01:43:04 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:43:05 - INFO - Learning Rate: 0.00010717730559578333
Weight Decay: 0.006474977128966193
Batch Size: 16
No. Epochs: 11
Epoch Patience: 10
 Accumulation Steps: 4
2026-02-14 01:43:05 - INFO - Generating initial weights
2026-02-14 01:43:11 - INFO - Time taken for Epoch 1:5.04 - F1: 0.0406
2026-02-14 01:43:16 - INFO - Time taken for Epoch 2:5.01 - F1: 0.0086
2026-02-14 01:43:21 - INFO - Time taken for Epoch 3:5.01 - F1: 0.0365
2026-02-14 01:43:26 - INFO - Time taken for Epoch 4:5.01 - F1: 0.0365
2026-02-14 01:43:31 - INFO - Time taken for Epoch 5:5.02 - F1: 0.1053
2026-02-14 01:43:36 - INFO - Time taken for Epoch 6:5.02 - F1: 0.1702
2026-02-14 01:43:41 - INFO - Time taken for Epoch 7:5.03 - F1: 0.5021
2026-02-14 01:43:46 - INFO - Time taken for Epoch 8:5.02 - F1: 0.4920
2026-02-14 01:43:51 - INFO - Time taken for Epoch 9:5.02 - F1: 0.5779
2026-02-14 01:43:56 - INFO - Time taken for Epoch 10:5.01 - F1: 0.5959
2026-02-14 01:44:01 - INFO - Time taken for Epoch 11:5.01 - F1: 0.6066
2026-02-14 01:44:01 - INFO - Best F1:0.6066 - Best Epoch:11
2026-02-14 01:44:01 - INFO - Starting co-training
2026-02-14 01:44:07 - INFO - Time taken for Epoch 1: 5.55s - F1: 0.14172458
2026-02-14 01:44:13 - INFO - Time taken for Epoch 2: 6.14s - F1: 0.28809048
2026-02-14 01:44:19 - INFO - Time taken for Epoch 3: 6.18s - F1: 0.36375133
2026-02-14 01:44:26 - INFO - Time taken for Epoch 4: 6.16s - F1: 0.38317619
2026-02-14 01:44:32 - INFO - Time taken for Epoch 5: 6.20s - F1: 0.41206973
2026-02-14 01:44:38 - INFO - Time taken for Epoch 6: 6.17s - F1: 0.48324868
2026-02-14 01:44:44 - INFO - Time taken for Epoch 7: 6.18s - F1: 0.42269555
2026-02-14 01:44:50 - INFO - Time taken for Epoch 8: 5.56s - F1: 0.54105391
2026-02-14 01:44:56 - INFO - Time taken for Epoch 9: 6.15s - F1: 0.53034731
2026-02-14 01:45:01 - INFO - Time taken for Epoch 10: 5.54s - F1: 0.51279858
2026-02-14 01:45:07 - INFO - Time taken for Epoch 11: 5.53s - F1: 0.52405897
2026-02-14 01:45:08 - INFO - Fine-tuning models
2026-02-14 01:45:11 - INFO - Time taken for Epoch 1:2.33 - F1: 0.4030
2026-02-14 01:45:14 - INFO - Time taken for Epoch 2:2.93 - F1: 0.5546
2026-02-14 01:45:17 - INFO - Time taken for Epoch 3:3.01 - F1: 0.6427
2026-02-14 01:45:19 - INFO - Time taken for Epoch 4:2.92 - F1: 0.6240
2026-02-14 01:45:22 - INFO - Time taken for Epoch 5:2.31 - F1: 0.6533
2026-02-14 01:45:25 - INFO - Time taken for Epoch 6:2.94 - F1: 0.6591
2026-02-14 01:45:28 - INFO - Time taken for Epoch 7:2.93 - F1: 0.6580
2026-02-14 01:45:30 - INFO - Time taken for Epoch 8:2.31 - F1: 0.6791
2026-02-14 01:45:33 - INFO - Time taken for Epoch 9:3.05 - F1: 0.7599
2026-02-14 01:45:36 - INFO - Time taken for Epoch 10:2.98 - F1: 0.6831
2026-02-14 01:45:38 - INFO - Time taken for Epoch 11:2.31 - F1: 0.7077
2026-02-14 01:45:41 - INFO - Time taken for Epoch 12:2.31 - F1: 0.6735
2026-02-14 01:45:43 - INFO - Time taken for Epoch 13:2.31 - F1: 0.6610
2026-02-14 01:45:45 - INFO - Time taken for Epoch 14:2.32 - F1: 0.6927
2026-02-14 01:45:48 - INFO - Time taken for Epoch 15:2.32 - F1: 0.6590
2026-02-14 01:45:50 - INFO - Time taken for Epoch 16:2.31 - F1: 0.6616
2026-02-14 01:45:52 - INFO - Time taken for Epoch 17:2.31 - F1: 0.6950
2026-02-14 01:45:55 - INFO - Time taken for Epoch 18:2.31 - F1: 0.6874
2026-02-14 01:45:57 - INFO - Time taken for Epoch 19:2.31 - F1: 0.6823
2026-02-14 01:45:57 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:45:57 - INFO - Best F1:0.7599 - Best Epoch:8
2026-02-14 01:45:59 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.7587, Test ECE: 0.0596
2026-02-14 01:45:59 - INFO - All results: {'f1_macro': 0.7587417304166482, 'ece': np.float64(0.05963122145882968)}
2026-02-14 01:45:59 - INFO - 
Total time taken: 174.87 seconds
2026-02-14 01:45:59 - INFO - Trial 6 finished with value: 0.7587417304166482 and parameters: {'learning_rate': 0.00010717730559578333, 'weight_decay': 0.006474977128966193, 'batch_size': 16, 'co_train_epochs': 11, 'epoch_patience': 10}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:45:59 - INFO - Using devices: cuda, cuda
2026-02-14 01:45:59 - INFO - Devices: cuda, cuda
2026-02-14 01:45:59 - INFO - Starting log
2026-02-14 01:45:59 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:46:00 - INFO - Learning Rate: 0.0009678957291242182
Weight Decay: 0.00670204562725923
Batch Size: 16
No. Epochs: 9
Epoch Patience: 6
 Accumulation Steps: 4
2026-02-14 01:46:00 - INFO - Generating initial weights
2026-02-14 01:46:06 - INFO - Time taken for Epoch 1:5.03 - F1: 0.0365
2026-02-14 01:46:11 - INFO - Time taken for Epoch 2:5.00 - F1: 0.0365
2026-02-14 01:46:16 - INFO - Time taken for Epoch 3:5.01 - F1: 0.0365
2026-02-14 01:46:21 - INFO - Time taken for Epoch 4:5.01 - F1: 0.0190
2026-02-14 01:46:26 - INFO - Time taken for Epoch 5:5.01 - F1: 0.0190
2026-02-14 01:46:31 - INFO - Time taken for Epoch 6:5.00 - F1: 0.0365
2026-02-14 01:46:36 - INFO - Time taken for Epoch 7:5.01 - F1: 0.0365
2026-02-14 01:46:41 - INFO - Time taken for Epoch 8:5.01 - F1: 0.0365
2026-02-14 01:46:46 - INFO - Time taken for Epoch 9:5.00 - F1: 0.0365
2026-02-14 01:46:46 - INFO - Best F1:0.0365 - Best Epoch:1
2026-02-14 01:46:46 - INFO - Starting co-training
2026-02-14 01:46:52 - INFO - Time taken for Epoch 1: 5.53s - F1: 0.03648425
2026-02-14 01:46:58 - INFO - Time taken for Epoch 2: 6.07s - F1: 0.03648425
2026-02-14 01:47:04 - INFO - Time taken for Epoch 3: 5.56s - F1: 0.03648425
2026-02-14 01:47:09 - INFO - Time taken for Epoch 4: 5.52s - F1: 0.03648425
2026-02-14 01:47:15 - INFO - Time taken for Epoch 5: 5.52s - F1: 0.03648425
2026-02-14 01:47:20 - INFO - Time taken for Epoch 6: 5.55s - F1: 0.03648425
2026-02-14 01:47:26 - INFO - Time taken for Epoch 7: 5.56s - F1: 0.03648425
2026-02-14 01:47:26 - INFO - Performance not improving for 6 consecutive epochs.
2026-02-14 01:47:27 - INFO - Fine-tuning models
2026-02-14 01:47:30 - INFO - Time taken for Epoch 1:2.33 - F1: 0.0278
2026-02-14 01:47:33 - INFO - Time taken for Epoch 2:2.96 - F1: 0.0190
2026-02-14 01:47:35 - INFO - Time taken for Epoch 3:2.31 - F1: 0.0365
2026-02-14 01:47:38 - INFO - Time taken for Epoch 4:2.92 - F1: 0.0365
2026-02-14 01:47:40 - INFO - Time taken for Epoch 5:2.30 - F1: 0.0365
2026-02-14 01:47:42 - INFO - Time taken for Epoch 6:2.31 - F1: 0.0365
2026-02-14 01:47:45 - INFO - Time taken for Epoch 7:2.30 - F1: 0.0365
2026-02-14 01:47:47 - INFO - Time taken for Epoch 8:2.31 - F1: 0.0365
2026-02-14 01:47:49 - INFO - Time taken for Epoch 9:2.31 - F1: 0.0365
2026-02-14 01:47:52 - INFO - Time taken for Epoch 10:2.31 - F1: 0.0365
2026-02-14 01:47:54 - INFO - Time taken for Epoch 11:2.30 - F1: 0.0365
2026-02-14 01:47:56 - INFO - Time taken for Epoch 12:2.31 - F1: 0.0365
2026-02-14 01:47:59 - INFO - Time taken for Epoch 13:2.30 - F1: 0.0365
2026-02-14 01:47:59 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:47:59 - INFO - Best F1:0.0365 - Best Epoch:2
2026-02-14 01:48:01 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.0367, Test ECE: 0.3448
2026-02-14 01:48:01 - INFO - All results: {'f1_macro': 0.03668159522286202, 'ece': np.float64(0.3448409993073036)}
2026-02-14 01:48:01 - INFO - 
Total time taken: 121.68 seconds
2026-02-14 01:48:01 - INFO - Trial 7 finished with value: 0.03668159522286202 and parameters: {'learning_rate': 0.0009678957291242182, 'weight_decay': 0.00670204562725923, 'batch_size': 16, 'co_train_epochs': 9, 'epoch_patience': 6}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:48:01 - INFO - Using devices: cuda, cuda
2026-02-14 01:48:01 - INFO - Devices: cuda, cuda
2026-02-14 01:48:01 - INFO - Starting log
2026-02-14 01:48:01 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:48:01 - INFO - Learning Rate: 7.243556985881741e-05
Weight Decay: 0.0004537200016910436
Batch Size: 24
No. Epochs: 9
Epoch Patience: 10
 Accumulation Steps: 2
2026-02-14 01:48:02 - INFO - Generating initial weights
2026-02-14 01:48:07 - INFO - Time taken for Epoch 1:4.71 - F1: 0.0406
2026-02-14 01:48:12 - INFO - Time taken for Epoch 2:4.70 - F1: 0.0406
2026-02-14 01:48:16 - INFO - Time taken for Epoch 3:4.70 - F1: 0.0584
2026-02-14 01:48:21 - INFO - Time taken for Epoch 4:4.69 - F1: 0.0365
2026-02-14 01:48:26 - INFO - Time taken for Epoch 5:4.69 - F1: 0.0365
2026-02-14 01:48:30 - INFO - Time taken for Epoch 6:4.69 - F1: 0.2031
2026-02-14 01:48:35 - INFO - Time taken for Epoch 7:4.68 - F1: 0.3197
2026-02-14 01:48:40 - INFO - Time taken for Epoch 8:4.69 - F1: 0.4436
2026-02-14 01:48:44 - INFO - Time taken for Epoch 9:4.69 - F1: 0.4916
2026-02-14 01:48:44 - INFO - Best F1:0.4916 - Best Epoch:9
2026-02-14 01:48:45 - INFO - Starting co-training
2026-02-14 01:48:52 - INFO - Time taken for Epoch 1: 6.60s - F1: 0.22657252
2026-02-14 01:48:59 - INFO - Time taken for Epoch 2: 7.76s - F1: 0.37642667
2026-02-14 01:49:07 - INFO - Time taken for Epoch 3: 7.35s - F1: 0.41348761
2026-02-14 01:49:14 - INFO - Time taken for Epoch 4: 7.16s - F1: 0.54243860
2026-02-14 01:49:21 - INFO - Time taken for Epoch 5: 7.13s - F1: 0.54723310
2026-02-14 01:49:28 - INFO - Time taken for Epoch 6: 7.17s - F1: 0.52166354
2026-02-14 01:49:35 - INFO - Time taken for Epoch 7: 6.60s - F1: 0.55263499
2026-02-14 01:49:43 - INFO - Time taken for Epoch 8: 7.87s - F1: 0.54924969
2026-02-14 01:49:49 - INFO - Time taken for Epoch 9: 6.59s - F1: 0.54861386
2026-02-14 01:49:51 - INFO - Fine-tuning models
2026-02-14 01:49:53 - INFO - Time taken for Epoch 1:2.18 - F1: 0.4972
2026-02-14 01:49:56 - INFO - Time taken for Epoch 2:2.66 - F1: 0.6033
2026-02-14 01:49:58 - INFO - Time taken for Epoch 3:2.73 - F1: 0.6187
2026-02-14 01:50:01 - INFO - Time taken for Epoch 4:2.71 - F1: 0.6232
2026-02-14 01:50:04 - INFO - Time taken for Epoch 5:2.69 - F1: 0.6350
2026-02-14 01:50:06 - INFO - Time taken for Epoch 6:2.80 - F1: 0.6445
2026-02-14 01:50:09 - INFO - Time taken for Epoch 7:2.70 - F1: 0.6836
2026-02-14 01:50:12 - INFO - Time taken for Epoch 8:2.71 - F1: 0.6601
2026-02-14 01:50:14 - INFO - Time taken for Epoch 9:2.17 - F1: 0.6629
2026-02-14 01:50:16 - INFO - Time taken for Epoch 10:2.17 - F1: 0.6925
2026-02-14 01:50:19 - INFO - Time taken for Epoch 11:2.73 - F1: 0.6986
2026-02-14 01:50:22 - INFO - Time taken for Epoch 12:2.73 - F1: 0.6954
2026-02-14 01:50:24 - INFO - Time taken for Epoch 13:2.16 - F1: 0.6873
2026-02-14 01:50:26 - INFO - Time taken for Epoch 14:2.16 - F1: 0.6968
2026-02-14 01:50:28 - INFO - Time taken for Epoch 15:2.16 - F1: 0.6981
2026-02-14 01:50:30 - INFO - Time taken for Epoch 16:2.17 - F1: 0.6917
2026-02-14 01:50:32 - INFO - Time taken for Epoch 17:2.17 - F1: 0.6799
2026-02-14 01:50:35 - INFO - Time taken for Epoch 18:2.17 - F1: 0.6906
2026-02-14 01:50:37 - INFO - Time taken for Epoch 19:2.17 - F1: 0.6956
2026-02-14 01:50:39 - INFO - Time taken for Epoch 20:2.16 - F1: 0.7015
2026-02-14 01:50:42 - INFO - Time taken for Epoch 21:2.72 - F1: 0.7015
2026-02-14 01:50:44 - INFO - Time taken for Epoch 22:2.16 - F1: 0.6956
2026-02-14 01:50:46 - INFO - Time taken for Epoch 23:2.16 - F1: 0.6956
2026-02-14 01:50:48 - INFO - Time taken for Epoch 24:2.17 - F1: 0.6956
2026-02-14 01:50:50 - INFO - Time taken for Epoch 25:2.16 - F1: 0.6993
2026-02-14 01:50:52 - INFO - Time taken for Epoch 26:2.16 - F1: 0.6993
2026-02-14 01:50:55 - INFO - Time taken for Epoch 27:2.16 - F1: 0.6993
2026-02-14 01:50:57 - INFO - Time taken for Epoch 28:2.16 - F1: 0.6993
2026-02-14 01:50:59 - INFO - Time taken for Epoch 29:2.16 - F1: 0.6873
2026-02-14 01:51:01 - INFO - Time taken for Epoch 30:2.16 - F1: 0.6904
2026-02-14 01:51:01 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:51:01 - INFO - Best F1:0.7015 - Best Epoch:19
2026-02-14 01:51:03 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.7574, Test ECE: 0.0466
2026-02-14 01:51:03 - INFO - All results: {'f1_macro': 0.7574025689083311, 'ece': np.float64(0.046595261562829726)}
2026-02-14 01:51:03 - INFO - 
Total time taken: 182.54 seconds
2026-02-14 01:51:04 - INFO - Trial 8 finished with value: 0.7574025689083311 and parameters: {'learning_rate': 7.243556985881741e-05, 'weight_decay': 0.0004537200016910436, 'batch_size': 24, 'co_train_epochs': 9, 'epoch_patience': 10}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:51:04 - INFO - Using devices: cuda, cuda
2026-02-14 01:51:04 - INFO - Devices: cuda, cuda
2026-02-14 01:51:04 - INFO - Starting log
2026-02-14 01:51:04 - INFO - Dataset: humanitarian9, Event: kaikoura_earthquake_2016, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 01:51:04 - INFO - Learning Rate: 0.00011648887456161265
Weight Decay: 0.003432385396348657
Batch Size: 16
No. Epochs: 20
Epoch Patience: 6
 Accumulation Steps: 4
2026-02-14 01:51:04 - INFO - Generating initial weights
2026-02-14 01:51:10 - INFO - Time taken for Epoch 1:5.04 - F1: 0.0406
2026-02-14 01:51:15 - INFO - Time taken for Epoch 2:5.02 - F1: 0.0086
2026-02-14 01:51:20 - INFO - Time taken for Epoch 3:5.04 - F1: 0.0365
2026-02-14 01:51:25 - INFO - Time taken for Epoch 4:5.03 - F1: 0.0365
2026-02-14 01:51:30 - INFO - Time taken for Epoch 5:5.02 - F1: 0.0365
2026-02-14 01:51:35 - INFO - Time taken for Epoch 6:5.02 - F1: 0.1731
2026-02-14 01:51:40 - INFO - Time taken for Epoch 7:5.01 - F1: 0.2377
2026-02-14 01:51:45 - INFO - Time taken for Epoch 8:5.03 - F1: 0.5241
2026-02-14 01:51:50 - INFO - Time taken for Epoch 9:5.02 - F1: 0.4100
2026-02-14 01:51:55 - INFO - Time taken for Epoch 10:5.02 - F1: 0.5069
2026-02-14 01:52:00 - INFO - Time taken for Epoch 11:5.02 - F1: 0.4592
2026-02-14 01:52:05 - INFO - Time taken for Epoch 12:5.02 - F1: 0.5896
2026-02-14 01:52:10 - INFO - Time taken for Epoch 13:5.02 - F1: 0.6600
2026-02-14 01:52:15 - INFO - Time taken for Epoch 14:5.02 - F1: 0.6122
2026-02-14 01:52:20 - INFO - Time taken for Epoch 15:5.03 - F1: 0.6222
2026-02-14 01:52:25 - INFO - Time taken for Epoch 16:5.02 - F1: 0.5897
2026-02-14 01:52:30 - INFO - Time taken for Epoch 17:5.02 - F1: 0.5732
2026-02-14 01:52:35 - INFO - Time taken for Epoch 18:5.04 - F1: 0.6151
2026-02-14 01:52:40 - INFO - Time taken for Epoch 19:5.02 - F1: 0.6077
2026-02-14 01:52:45 - INFO - Time taken for Epoch 20:5.02 - F1: 0.6011
2026-02-14 01:52:45 - INFO - Best F1:0.6600 - Best Epoch:13
2026-02-14 01:52:46 - INFO - Starting co-training
2026-02-14 01:52:51 - INFO - Time taken for Epoch 1: 5.55s - F1: 0.20876135
2026-02-14 01:52:58 - INFO - Time taken for Epoch 2: 6.08s - F1: 0.22053538
2026-02-14 01:53:04 - INFO - Time taken for Epoch 3: 6.11s - F1: 0.25992790
2026-02-14 01:53:10 - INFO - Time taken for Epoch 4: 6.12s - F1: 0.38390299
2026-02-14 01:53:16 - INFO - Time taken for Epoch 5: 6.14s - F1: 0.41889255
2026-02-14 01:53:22 - INFO - Time taken for Epoch 6: 6.13s - F1: 0.36729379
2026-02-14 01:53:28 - INFO - Time taken for Epoch 7: 5.56s - F1: 0.41082411
2026-02-14 01:53:33 - INFO - Time taken for Epoch 8: 5.55s - F1: 0.41928797
2026-02-14 01:53:40 - INFO - Time taken for Epoch 9: 6.41s - F1: 0.40073563
2026-02-14 01:53:45 - INFO - Time taken for Epoch 10: 5.53s - F1: 0.43717554
2026-02-14 01:53:51 - INFO - Time taken for Epoch 11: 6.28s - F1: 0.39933270
2026-02-14 01:53:57 - INFO - Time taken for Epoch 12: 5.54s - F1: 0.44846839
2026-02-14 01:54:03 - INFO - Time taken for Epoch 13: 6.20s - F1: 0.51203321
2026-02-14 01:54:09 - INFO - Time taken for Epoch 14: 6.12s - F1: 0.46898875
2026-02-14 01:54:15 - INFO - Time taken for Epoch 15: 5.58s - F1: 0.43651374
2026-02-14 01:54:20 - INFO - Time taken for Epoch 16: 5.56s - F1: 0.53809211
2026-02-14 01:54:26 - INFO - Time taken for Epoch 17: 6.12s - F1: 0.55565565
2026-02-14 01:54:33 - INFO - Time taken for Epoch 18: 6.20s - F1: 0.47590000
2026-02-14 01:54:38 - INFO - Time taken for Epoch 19: 5.54s - F1: 0.47061593
2026-02-14 01:54:44 - INFO - Time taken for Epoch 20: 5.54s - F1: 0.50652437
2026-02-14 01:54:45 - INFO - Fine-tuning models
2026-02-14 01:54:48 - INFO - Time taken for Epoch 1:2.33 - F1: 0.4191
2026-02-14 01:54:50 - INFO - Time taken for Epoch 2:2.89 - F1: 0.5717
2026-02-14 01:54:53 - INFO - Time taken for Epoch 3:2.92 - F1: 0.6158
2026-02-14 01:54:56 - INFO - Time taken for Epoch 4:2.93 - F1: 0.6122
2026-02-14 01:54:59 - INFO - Time taken for Epoch 5:2.32 - F1: 0.6070
2026-02-14 01:55:01 - INFO - Time taken for Epoch 6:2.32 - F1: 0.6439
2026-02-14 01:55:04 - INFO - Time taken for Epoch 7:2.93 - F1: 0.6632
2026-02-14 01:55:07 - INFO - Time taken for Epoch 8:3.01 - F1: 0.6553
2026-02-14 01:55:09 - INFO - Time taken for Epoch 9:2.31 - F1: 0.6623
2026-02-14 01:55:11 - INFO - Time taken for Epoch 10:2.31 - F1: 0.6595
2026-02-14 01:55:14 - INFO - Time taken for Epoch 11:2.32 - F1: 0.6680
2026-02-14 01:55:17 - INFO - Time taken for Epoch 12:3.03 - F1: 0.6594
2026-02-14 01:55:19 - INFO - Time taken for Epoch 13:2.31 - F1: 0.6416
2026-02-14 01:55:21 - INFO - Time taken for Epoch 14:2.31 - F1: 0.6588
2026-02-14 01:55:24 - INFO - Time taken for Epoch 15:2.32 - F1: 0.6570
2026-02-14 01:55:26 - INFO - Time taken for Epoch 16:2.32 - F1: 0.6252
2026-02-14 01:55:28 - INFO - Time taken for Epoch 17:2.32 - F1: 0.6263
2026-02-14 01:55:31 - INFO - Time taken for Epoch 18:2.31 - F1: 0.6526
2026-02-14 01:55:33 - INFO - Time taken for Epoch 19:2.31 - F1: 0.6560
2026-02-14 01:55:35 - INFO - Time taken for Epoch 20:2.31 - F1: 0.6374
2026-02-14 01:55:38 - INFO - Time taken for Epoch 21:2.31 - F1: 0.6407
2026-02-14 01:55:38 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 01:55:38 - INFO - Best F1:0.6680 - Best Epoch:10
2026-02-14 01:55:40 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6496, Test ECE: 0.0751
2026-02-14 01:55:40 - INFO - All results: {'f1_macro': 0.6496191692311729, 'ece': np.float64(0.07513908188918542)}
2026-02-14 01:55:40 - INFO - 
Total time taken: 276.60 seconds
2026-02-14 01:55:40 - INFO - Trial 9 finished with value: 0.6496191692311729 and parameters: {'learning_rate': 0.00011648887456161265, 'weight_decay': 0.003432385396348657, 'batch_size': 16, 'co_train_epochs': 20, 'epoch_patience': 6}. Best is trial 0 with value: 0.7603710845111459.
2026-02-14 01:55:40 - INFO - 
[BEST TRIAL RESULTS]
2026-02-14 01:55:40 - INFO - F1 Score: 0.7604
2026-02-14 01:55:40 - INFO - Params: {'learning_rate': 0.00011919124313454202, 'weight_decay': 0.0007408419801750387, 'batch_size': 16, 'co_train_epochs': 13, 'epoch_patience': 8}
2026-02-14 01:55:40 - INFO -   learning_rate: 0.00011919124313454202
2026-02-14 01:55:40 - INFO -   weight_decay: 0.0007408419801750387
2026-02-14 01:55:40 - INFO -   batch_size: 16
2026-02-14 01:55:40 - INFO -   co_train_epochs: 13
2026-02-14 01:55:40 - INFO -   epoch_patience: 8
2026-02-14 01:55:40 - INFO - 
Total time taken: 2097.00 seconds
