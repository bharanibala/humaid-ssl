[Optuna] Starting hyperparameter search with 10 trials.
2026-02-12 13:46:42 - INFO - 
[Optuna] Starting hyperparameter search with 10 trials.
2026-02-12 13:46:42 - INFO - A new study created in memory with name: study_humanitarian10_cyclone_idai_2019
Using devices: cuda, cuda
2026-02-12 13:46:42 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 13:46:42 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 13:46:42 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 13:46:42 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
Learning Rate: 0.00013023758003493532
Weight Decay: 0.004671904639631401
Batch Size: 8
No. Epochs: 6
Epoch Patience: 5
 Accumulation Steps: 8
2026-02-12 13:46:45 - INFO - Learning Rate: 0.00013023758003493532
Weight Decay: 0.004671904639631401
Batch Size: 8
No. Epochs: 6
Epoch Patience: 5
 Accumulation Steps: 8
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 13:46:47 - INFO - Generating initial weights
Time taken for Epoch 1:11.09 - F1: 0.0467
2026-02-12 13:47:00 - INFO - Time taken for Epoch 1:11.09 - F1: 0.0467
Time taken for Epoch 2:10.80 - F1: 0.0671
2026-02-12 13:47:11 - INFO - Time taken for Epoch 2:10.80 - F1: 0.0671
Time taken for Epoch 3:10.68 - F1: 0.1167
2026-02-12 13:47:21 - INFO - Time taken for Epoch 3:10.68 - F1: 0.1167
Time taken for Epoch 4:10.40 - F1: 0.1233
2026-02-12 13:47:32 - INFO - Time taken for Epoch 4:10.40 - F1: 0.1233
Time taken for Epoch 5:10.27 - F1: 0.2155
2026-02-12 13:47:42 - INFO - Time taken for Epoch 5:10.27 - F1: 0.2155
Time taken for Epoch 6:10.24 - F1: 0.2655
2026-02-12 13:47:52 - INFO - Time taken for Epoch 6:10.24 - F1: 0.2655
Best F1:0.2655 - Best Epoch:6
2026-02-12 13:47:52 - INFO - Best F1:0.2655 - Best Epoch:6
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 13:47:55 - INFO - Starting co-training
Time taken for Epoch 1: 10.39s - F1: 0.06452703
2026-02-12 13:48:05 - INFO - Time taken for Epoch 1: 10.39s - F1: 0.06452703
Time taken for Epoch 2: 11.35s - F1: 0.06452703
2026-02-12 13:48:17 - INFO - Time taken for Epoch 2: 11.35s - F1: 0.06452703
Time taken for Epoch 3: 10.26s - F1: 0.06452703
2026-02-12 13:48:27 - INFO - Time taken for Epoch 3: 10.26s - F1: 0.06452703
Time taken for Epoch 4: 10.33s - F1: 0.06452703
2026-02-12 13:48:37 - INFO - Time taken for Epoch 4: 10.33s - F1: 0.06452703
Time taken for Epoch 5: 10.35s - F1: 0.06452703
2026-02-12 13:48:48 - INFO - Time taken for Epoch 5: 10.35s - F1: 0.06452703
Time taken for Epoch 6: 10.33s - F1: 0.06452703
2026-02-12 13:48:58 - INFO - Time taken for Epoch 6: 10.33s - F1: 0.06452703
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 13:49:02 - INFO - Fine-tuning models
Time taken for Epoch 1:3.01 - F1: 0.0645
2026-02-12 13:49:05 - INFO - Time taken for Epoch 1:3.01 - F1: 0.0645
Time taken for Epoch 2:3.88 - F1: 0.0645
2026-02-12 13:49:09 - INFO - Time taken for Epoch 2:3.88 - F1: 0.0645
Time taken for Epoch 3:2.77 - F1: 0.0029
2026-02-12 13:49:12 - INFO - Time taken for Epoch 3:2.77 - F1: 0.0029
Time taken for Epoch 4:2.76 - F1: 0.0029
2026-02-12 13:49:15 - INFO - Time taken for Epoch 4:2.76 - F1: 0.0029
Time taken for Epoch 5:2.79 - F1: 0.0137
2026-02-12 13:49:18 - INFO - Time taken for Epoch 5:2.79 - F1: 0.0137
Time taken for Epoch 6:2.80 - F1: 0.0692
2026-02-12 13:49:20 - INFO - Time taken for Epoch 6:2.80 - F1: 0.0692
Time taken for Epoch 7:10.31 - F1: 0.0645
2026-02-12 13:49:31 - INFO - Time taken for Epoch 7:10.31 - F1: 0.0645
Time taken for Epoch 8:2.79 - F1: 0.0645
2026-02-12 13:49:33 - INFO - Time taken for Epoch 8:2.79 - F1: 0.0645
Time taken for Epoch 9:2.77 - F1: 0.0165
2026-02-12 13:49:36 - INFO - Time taken for Epoch 9:2.77 - F1: 0.0165
Time taken for Epoch 10:2.78 - F1: 0.0165
2026-02-12 13:49:39 - INFO - Time taken for Epoch 10:2.78 - F1: 0.0165
Time taken for Epoch 11:2.77 - F1: 0.0165
2026-02-12 13:49:42 - INFO - Time taken for Epoch 11:2.77 - F1: 0.0165
Time taken for Epoch 12:2.77 - F1: 0.0248
2026-02-12 13:49:45 - INFO - Time taken for Epoch 12:2.77 - F1: 0.0248
Time taken for Epoch 13:2.81 - F1: 0.0044
2026-02-12 13:49:47 - INFO - Time taken for Epoch 13:2.81 - F1: 0.0044
Time taken for Epoch 14:2.77 - F1: 0.0044
2026-02-12 13:49:50 - INFO - Time taken for Epoch 14:2.77 - F1: 0.0044
Time taken for Epoch 15:2.77 - F1: 0.0031
2026-02-12 13:49:53 - INFO - Time taken for Epoch 15:2.77 - F1: 0.0031
Time taken for Epoch 16:2.77 - F1: 0.0029
2026-02-12 13:49:56 - INFO - Time taken for Epoch 16:2.77 - F1: 0.0029
Performance not improving for 10 consecutive epochs.
2026-02-12 13:49:56 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0692 - Best Epoch:5
2026-02-12 13:49:56 - INFO - Best F1:0.0692 - Best Epoch:5
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0612, Test ECE: 0.0131
2026-02-12 13:50:04 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0612, Test ECE: 0.0131
All results: {'f1_macro': 0.06122610532106646, 'ece': 0.01310359308823697}
2026-02-12 13:50:04 - INFO - All results: {'f1_macro': 0.06122610532106646, 'ece': 0.01310359308823697}

Total time taken: 201.38 seconds
2026-02-12 13:50:04 - INFO - 
Total time taken: 201.38 seconds
2026-02-12 13:50:04 - INFO - Trial 0 finished with value: 0.06122610532106646 and parameters: {'learning_rate': 0.00013023758003493532, 'weight_decay': 0.004671904639631401, 'batch_size': 8, 'co_train_epochs': 6, 'epoch_patience': 5}. Best is trial 0 with value: 0.06122610532106646.
Using devices: cuda, cuda
2026-02-12 13:50:04 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 13:50:04 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 13:50:04 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 13:50:04 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.0006178488710631032
Weight Decay: 0.00025970844531512444
Batch Size: 16
No. Epochs: 5
Epoch Patience: 8
 Accumulation Steps: 4
2026-02-12 13:50:05 - INFO - Learning Rate: 0.0006178488710631032
Weight Decay: 0.00025970844531512444
Batch Size: 16
No. Epochs: 5
Epoch Patience: 8
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 13:50:08 - INFO - Generating initial weights
Time taken for Epoch 1:9.53 - F1: 0.0198
2026-02-12 13:50:18 - INFO - Time taken for Epoch 1:9.53 - F1: 0.0198
Time taken for Epoch 2:9.34 - F1: 0.0165
2026-02-12 13:50:28 - INFO - Time taken for Epoch 2:9.34 - F1: 0.0165
Time taken for Epoch 3:9.37 - F1: 0.0029
2026-02-12 13:50:37 - INFO - Time taken for Epoch 3:9.37 - F1: 0.0029
Time taken for Epoch 4:9.38 - F1: 0.0198
2026-02-12 13:50:47 - INFO - Time taken for Epoch 4:9.38 - F1: 0.0198
Time taken for Epoch 5:9.38 - F1: 0.0029
2026-02-12 13:50:56 - INFO - Time taken for Epoch 5:9.38 - F1: 0.0029
Best F1:0.0198 - Best Epoch:1
2026-02-12 13:50:56 - INFO - Best F1:0.0198 - Best Epoch:1
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 13:50:58 - INFO - Starting co-training
Time taken for Epoch 1: 10.90s - F1: 0.01977528
2026-02-12 13:51:09 - INFO - Time taken for Epoch 1: 10.90s - F1: 0.01977528
Time taken for Epoch 2: 12.07s - F1: 0.06452703
2026-02-12 13:51:21 - INFO - Time taken for Epoch 2: 12.07s - F1: 0.06452703
Time taken for Epoch 3: 15.35s - F1: 0.06452703
2026-02-12 13:51:37 - INFO - Time taken for Epoch 3: 15.35s - F1: 0.06452703
Time taken for Epoch 4: 10.83s - F1: 0.06452703
2026-02-12 13:51:48 - INFO - Time taken for Epoch 4: 10.83s - F1: 0.06452703
Time taken for Epoch 5: 10.83s - F1: 0.06452703
2026-02-12 13:51:58 - INFO - Time taken for Epoch 5: 10.83s - F1: 0.06452703
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 13:52:03 - INFO - Fine-tuning models
Time taken for Epoch 1:2.78 - F1: 0.0165
2026-02-12 13:52:06 - INFO - Time taken for Epoch 1:2.78 - F1: 0.0165
Time taken for Epoch 2:3.63 - F1: 0.0165
2026-02-12 13:52:09 - INFO - Time taken for Epoch 2:3.63 - F1: 0.0165
Time taken for Epoch 3:2.57 - F1: 0.0218
2026-02-12 13:52:12 - INFO - Time taken for Epoch 3:2.57 - F1: 0.0218
Time taken for Epoch 4:23.51 - F1: 0.0218
2026-02-12 13:52:35 - INFO - Time taken for Epoch 4:23.51 - F1: 0.0218
Time taken for Epoch 5:2.60 - F1: 0.0218
2026-02-12 13:52:38 - INFO - Time taken for Epoch 5:2.60 - F1: 0.0218
Time taken for Epoch 6:2.58 - F1: 0.0218
2026-02-12 13:52:41 - INFO - Time taken for Epoch 6:2.58 - F1: 0.0218
Time taken for Epoch 7:2.57 - F1: 0.0218
2026-02-12 13:52:43 - INFO - Time taken for Epoch 7:2.57 - F1: 0.0218
Time taken for Epoch 8:2.58 - F1: 0.0218
2026-02-12 13:52:46 - INFO - Time taken for Epoch 8:2.58 - F1: 0.0218
Time taken for Epoch 9:2.57 - F1: 0.0218
2026-02-12 13:52:48 - INFO - Time taken for Epoch 9:2.57 - F1: 0.0218
Time taken for Epoch 10:2.58 - F1: 0.0218
2026-02-12 13:52:51 - INFO - Time taken for Epoch 10:2.58 - F1: 0.0218
Time taken for Epoch 11:2.59 - F1: 0.0218
2026-02-12 13:52:54 - INFO - Time taken for Epoch 11:2.59 - F1: 0.0218
Time taken for Epoch 12:2.60 - F1: 0.0218
2026-02-12 13:52:56 - INFO - Time taken for Epoch 12:2.60 - F1: 0.0218
Time taken for Epoch 13:2.59 - F1: 0.0218
2026-02-12 13:52:59 - INFO - Time taken for Epoch 13:2.59 - F1: 0.0218
Performance not improving for 10 consecutive epochs.
2026-02-12 13:52:59 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0218 - Best Epoch:2
2026-02-12 13:52:59 - INFO - Best F1:0.0218 - Best Epoch:2
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0217, Test ECE: 0.2399
2026-02-12 13:53:06 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0217, Test ECE: 0.2399
All results: {'f1_macro': 0.021739130434782608, 'ece': 0.2399385828567867}
2026-02-12 13:53:06 - INFO - All results: {'f1_macro': 0.021739130434782608, 'ece': 0.2399385828567867}

Total time taken: 182.19 seconds
2026-02-12 13:53:06 - INFO - 
Total time taken: 182.19 seconds
2026-02-12 13:53:06 - INFO - Trial 1 finished with value: 0.021739130434782608 and parameters: {'learning_rate': 0.0006178488710631032, 'weight_decay': 0.00025970844531512444, 'batch_size': 16, 'co_train_epochs': 5, 'epoch_patience': 8}. Best is trial 0 with value: 0.06122610532106646.
Using devices: cuda, cuda
2026-02-12 13:53:06 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 13:53:06 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 13:53:06 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 13:53:06 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.0007398056307951448
Weight Decay: 0.002600936296058208
Batch Size: 32
No. Epochs: 20
Epoch Patience: 4
 Accumulation Steps: 2
2026-02-12 13:53:08 - INFO - Learning Rate: 0.0007398056307951448
Weight Decay: 0.002600936296058208
Batch Size: 32
No. Epochs: 20
Epoch Patience: 4
 Accumulation Steps: 2
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 13:53:10 - INFO - Generating initial weights
Time taken for Epoch 1:8.82 - F1: 0.0029
2026-02-12 13:53:20 - INFO - Time taken for Epoch 1:8.82 - F1: 0.0029
Time taken for Epoch 2:8.57 - F1: 0.0160
2026-02-12 13:53:29 - INFO - Time taken for Epoch 2:8.57 - F1: 0.0160
Time taken for Epoch 3:8.58 - F1: 0.0218
2026-02-12 13:53:37 - INFO - Time taken for Epoch 3:8.58 - F1: 0.0218
Time taken for Epoch 4:8.65 - F1: 0.0218
2026-02-12 13:53:46 - INFO - Time taken for Epoch 4:8.65 - F1: 0.0218
Time taken for Epoch 5:8.65 - F1: 0.0218
2026-02-12 13:53:55 - INFO - Time taken for Epoch 5:8.65 - F1: 0.0218
Time taken for Epoch 6:8.64 - F1: 0.0218
2026-02-12 13:54:03 - INFO - Time taken for Epoch 6:8.64 - F1: 0.0218
Time taken for Epoch 7:8.60 - F1: 0.0218
2026-02-12 13:54:12 - INFO - Time taken for Epoch 7:8.60 - F1: 0.0218
Time taken for Epoch 8:8.63 - F1: 0.0218
2026-02-12 13:54:20 - INFO - Time taken for Epoch 8:8.63 - F1: 0.0218
Time taken for Epoch 9:8.60 - F1: 0.0218
2026-02-12 13:54:29 - INFO - Time taken for Epoch 9:8.60 - F1: 0.0218
Time taken for Epoch 10:8.67 - F1: 0.0218
2026-02-12 13:54:38 - INFO - Time taken for Epoch 10:8.67 - F1: 0.0218
Time taken for Epoch 11:8.61 - F1: 0.0218
2026-02-12 13:54:46 - INFO - Time taken for Epoch 11:8.61 - F1: 0.0218
Time taken for Epoch 12:8.63 - F1: 0.0218
2026-02-12 13:54:55 - INFO - Time taken for Epoch 12:8.63 - F1: 0.0218
Time taken for Epoch 13:8.60 - F1: 0.0218
2026-02-12 13:55:04 - INFO - Time taken for Epoch 13:8.60 - F1: 0.0218
Time taken for Epoch 14:8.60 - F1: 0.0218
2026-02-12 13:55:12 - INFO - Time taken for Epoch 14:8.60 - F1: 0.0218
Time taken for Epoch 15:8.61 - F1: 0.0218
2026-02-12 13:55:21 - INFO - Time taken for Epoch 15:8.61 - F1: 0.0218
Time taken for Epoch 16:8.56 - F1: 0.0218
2026-02-12 13:55:29 - INFO - Time taken for Epoch 16:8.56 - F1: 0.0218
Time taken for Epoch 17:8.63 - F1: 0.0218
2026-02-12 13:55:38 - INFO - Time taken for Epoch 17:8.63 - F1: 0.0218
Time taken for Epoch 18:8.59 - F1: 0.0218
2026-02-12 13:55:47 - INFO - Time taken for Epoch 18:8.59 - F1: 0.0218
Time taken for Epoch 19:8.61 - F1: 0.0218
2026-02-12 13:55:55 - INFO - Time taken for Epoch 19:8.61 - F1: 0.0218
Time taken for Epoch 20:8.59 - F1: 0.0218
2026-02-12 13:56:04 - INFO - Time taken for Epoch 20:8.59 - F1: 0.0218
Best F1:0.0218 - Best Epoch:3
2026-02-12 13:56:04 - INFO - Best F1:0.0218 - Best Epoch:3
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 13:56:06 - INFO - Starting co-training
Time taken for Epoch 1: 13.06s - F1: 0.06452703
2026-02-12 13:56:19 - INFO - Time taken for Epoch 1: 13.06s - F1: 0.06452703
Time taken for Epoch 2: 13.88s - F1: 0.06452703
2026-02-12 13:56:33 - INFO - Time taken for Epoch 2: 13.88s - F1: 0.06452703
Time taken for Epoch 3: 12.86s - F1: 0.06452703
2026-02-12 13:56:46 - INFO - Time taken for Epoch 3: 12.86s - F1: 0.06452703
Time taken for Epoch 4: 12.85s - F1: 0.06452703
2026-02-12 13:56:59 - INFO - Time taken for Epoch 4: 12.85s - F1: 0.06452703
Time taken for Epoch 5: 12.84s - F1: 0.06452703
2026-02-12 13:57:12 - INFO - Time taken for Epoch 5: 12.84s - F1: 0.06452703
Performance not improving for 4 consecutive epochs.
Performance not improving for 4 consecutive epochs.
2026-02-12 13:57:12 - INFO - Performance not improving for 4 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 13:57:16 - INFO - Fine-tuning models
Time taken for Epoch 1:2.58 - F1: 0.0165
2026-02-12 13:57:19 - INFO - Time taken for Epoch 1:2.58 - F1: 0.0165
Time taken for Epoch 2:3.49 - F1: 0.0218
2026-02-12 13:57:22 - INFO - Time taken for Epoch 2:3.49 - F1: 0.0218
Time taken for Epoch 3:23.49 - F1: 0.0218
2026-02-12 13:57:46 - INFO - Time taken for Epoch 3:23.49 - F1: 0.0218
Time taken for Epoch 4:2.41 - F1: 0.0645
2026-02-12 13:57:48 - INFO - Time taken for Epoch 4:2.41 - F1: 0.0645
Time taken for Epoch 5:8.07 - F1: 0.0645
2026-02-12 13:57:56 - INFO - Time taken for Epoch 5:8.07 - F1: 0.0645
Time taken for Epoch 6:2.39 - F1: 0.0218
2026-02-12 13:57:59 - INFO - Time taken for Epoch 6:2.39 - F1: 0.0218
Time taken for Epoch 7:2.39 - F1: 0.0218
2026-02-12 13:58:01 - INFO - Time taken for Epoch 7:2.39 - F1: 0.0218
Time taken for Epoch 8:2.39 - F1: 0.0218
2026-02-12 13:58:03 - INFO - Time taken for Epoch 8:2.39 - F1: 0.0218
Time taken for Epoch 9:2.39 - F1: 0.0218
2026-02-12 13:58:06 - INFO - Time taken for Epoch 9:2.39 - F1: 0.0218
Time taken for Epoch 10:2.39 - F1: 0.0218
2026-02-12 13:58:08 - INFO - Time taken for Epoch 10:2.39 - F1: 0.0218
Time taken for Epoch 11:2.39 - F1: 0.0218
2026-02-12 13:58:11 - INFO - Time taken for Epoch 11:2.39 - F1: 0.0218
Time taken for Epoch 12:2.39 - F1: 0.0218
2026-02-12 13:58:13 - INFO - Time taken for Epoch 12:2.39 - F1: 0.0218
Time taken for Epoch 13:2.39 - F1: 0.0218
2026-02-12 13:58:15 - INFO - Time taken for Epoch 13:2.39 - F1: 0.0218
Time taken for Epoch 14:2.39 - F1: 0.0218
2026-02-12 13:58:18 - INFO - Time taken for Epoch 14:2.39 - F1: 0.0218
Performance not improving for 10 consecutive epochs.
2026-02-12 13:58:18 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0645 - Best Epoch:3
2026-02-12 13:58:18 - INFO - Best F1:0.0645 - Best Epoch:3
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0644, Test ECE: 0.0123
2026-02-12 13:58:24 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0644, Test ECE: 0.0123
All results: {'f1_macro': 0.06440382941688425, 'ece': 0.012341493475268805}
2026-02-12 13:58:24 - INFO - All results: {'f1_macro': 0.06440382941688425, 'ece': 0.012341493475268805}

Total time taken: 318.47 seconds
2026-02-12 13:58:24 - INFO - 
Total time taken: 318.47 seconds
2026-02-12 13:58:24 - INFO - Trial 2 finished with value: 0.06440382941688425 and parameters: {'learning_rate': 0.0007398056307951448, 'weight_decay': 0.002600936296058208, 'batch_size': 32, 'co_train_epochs': 20, 'epoch_patience': 4}. Best is trial 2 with value: 0.06440382941688425.
Using devices: cuda, cuda
2026-02-12 13:58:24 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 13:58:24 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 13:58:24 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 13:58:24 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.0005045673711792034
Weight Decay: 0.008302622826213106
Batch Size: 32
No. Epochs: 13
Epoch Patience: 5
 Accumulation Steps: 2
2026-02-12 13:58:26 - INFO - Learning Rate: 0.0005045673711792034
Weight Decay: 0.008302622826213106
Batch Size: 32
No. Epochs: 13
Epoch Patience: 5
 Accumulation Steps: 2
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 13:58:28 - INFO - Generating initial weights
Time taken for Epoch 1:8.74 - F1: 0.0250
2026-02-12 13:58:38 - INFO - Time taken for Epoch 1:8.74 - F1: 0.0250
Time taken for Epoch 2:8.63 - F1: 0.0029
2026-02-12 13:58:47 - INFO - Time taken for Epoch 2:8.63 - F1: 0.0029
Time taken for Epoch 3:8.65 - F1: 0.0165
2026-02-12 13:58:56 - INFO - Time taken for Epoch 3:8.65 - F1: 0.0165
Time taken for Epoch 4:8.56 - F1: 0.0165
2026-02-12 13:59:04 - INFO - Time taken for Epoch 4:8.56 - F1: 0.0165
Time taken for Epoch 5:8.59 - F1: 0.0198
2026-02-12 13:59:13 - INFO - Time taken for Epoch 5:8.59 - F1: 0.0198
Time taken for Epoch 6:8.63 - F1: 0.0044
2026-02-12 13:59:21 - INFO - Time taken for Epoch 6:8.63 - F1: 0.0044
Time taken for Epoch 7:8.57 - F1: 0.0218
2026-02-12 13:59:30 - INFO - Time taken for Epoch 7:8.57 - F1: 0.0218
Time taken for Epoch 8:8.57 - F1: 0.0218
2026-02-12 13:59:38 - INFO - Time taken for Epoch 8:8.57 - F1: 0.0218
Time taken for Epoch 9:8.60 - F1: 0.0218
2026-02-12 13:59:47 - INFO - Time taken for Epoch 9:8.60 - F1: 0.0218
Time taken for Epoch 10:8.56 - F1: 0.0218
2026-02-12 13:59:56 - INFO - Time taken for Epoch 10:8.56 - F1: 0.0218
Time taken for Epoch 11:8.59 - F1: 0.0218
2026-02-12 14:00:04 - INFO - Time taken for Epoch 11:8.59 - F1: 0.0218
Time taken for Epoch 12:8.56 - F1: 0.0218
2026-02-12 14:00:13 - INFO - Time taken for Epoch 12:8.56 - F1: 0.0218
Time taken for Epoch 13:8.68 - F1: 0.0218
2026-02-12 14:00:21 - INFO - Time taken for Epoch 13:8.68 - F1: 0.0218
Best F1:0.0250 - Best Epoch:1
2026-02-12 14:00:21 - INFO - Best F1:0.0250 - Best Epoch:1
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 14:00:24 - INFO - Starting co-training
Time taken for Epoch 1: 12.93s - F1: 0.06452703
2026-02-12 14:00:37 - INFO - Time taken for Epoch 1: 12.93s - F1: 0.06452703
Time taken for Epoch 2: 14.40s - F1: 0.06452703
2026-02-12 14:00:51 - INFO - Time taken for Epoch 2: 14.40s - F1: 0.06452703
Time taken for Epoch 3: 12.88s - F1: 0.06452703
2026-02-12 14:01:04 - INFO - Time taken for Epoch 3: 12.88s - F1: 0.06452703
Time taken for Epoch 4: 12.87s - F1: 0.06452703
2026-02-12 14:01:17 - INFO - Time taken for Epoch 4: 12.87s - F1: 0.06452703
Time taken for Epoch 5: 12.94s - F1: 0.06452703
2026-02-12 14:01:30 - INFO - Time taken for Epoch 5: 12.94s - F1: 0.06452703
Time taken for Epoch 6: 12.92s - F1: 0.06452703
2026-02-12 14:01:43 - INFO - Time taken for Epoch 6: 12.92s - F1: 0.06452703
Performance not improving for 5 consecutive epochs.
Performance not improving for 5 consecutive epochs.
2026-02-12 14:01:43 - INFO - Performance not improving for 5 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 14:01:47 - INFO - Fine-tuning models
Time taken for Epoch 1:2.51 - F1: 0.0218
2026-02-12 14:01:50 - INFO - Time taken for Epoch 1:2.51 - F1: 0.0218
Time taken for Epoch 2:3.79 - F1: 0.0072
2026-02-12 14:01:53 - INFO - Time taken for Epoch 2:3.79 - F1: 0.0072
Time taken for Epoch 3:2.43 - F1: 0.0218
2026-02-12 14:01:56 - INFO - Time taken for Epoch 3:2.43 - F1: 0.0218
Time taken for Epoch 4:2.42 - F1: 0.0218
2026-02-12 14:01:58 - INFO - Time taken for Epoch 4:2.42 - F1: 0.0218
Time taken for Epoch 5:2.39 - F1: 0.0645
2026-02-12 14:02:01 - INFO - Time taken for Epoch 5:2.39 - F1: 0.0645
Time taken for Epoch 6:3.72 - F1: 0.0645
2026-02-12 14:02:04 - INFO - Time taken for Epoch 6:3.72 - F1: 0.0645
Time taken for Epoch 7:2.42 - F1: 0.0645
2026-02-12 14:02:07 - INFO - Time taken for Epoch 7:2.42 - F1: 0.0645
Time taken for Epoch 8:2.41 - F1: 0.0218
2026-02-12 14:02:09 - INFO - Time taken for Epoch 8:2.41 - F1: 0.0218
Time taken for Epoch 9:2.39 - F1: 0.0218
2026-02-12 14:02:12 - INFO - Time taken for Epoch 9:2.39 - F1: 0.0218
Time taken for Epoch 10:2.39 - F1: 0.0218
2026-02-12 14:02:14 - INFO - Time taken for Epoch 10:2.39 - F1: 0.0218
Time taken for Epoch 11:2.39 - F1: 0.0218
2026-02-12 14:02:16 - INFO - Time taken for Epoch 11:2.39 - F1: 0.0218
Time taken for Epoch 12:2.40 - F1: 0.0218
2026-02-12 14:02:19 - INFO - Time taken for Epoch 12:2.40 - F1: 0.0218
Time taken for Epoch 13:2.41 - F1: 0.0218
2026-02-12 14:02:21 - INFO - Time taken for Epoch 13:2.41 - F1: 0.0218
Time taken for Epoch 14:2.41 - F1: 0.0218
2026-02-12 14:02:24 - INFO - Time taken for Epoch 14:2.41 - F1: 0.0218
Time taken for Epoch 15:2.39 - F1: 0.0218
2026-02-12 14:02:26 - INFO - Time taken for Epoch 15:2.39 - F1: 0.0218
Performance not improving for 10 consecutive epochs.
2026-02-12 14:02:26 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0645 - Best Epoch:4
2026-02-12 14:02:26 - INFO - Best F1:0.0645 - Best Epoch:4
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0644, Test ECE: 0.1811
2026-02-12 14:02:32 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0644, Test ECE: 0.1811
All results: {'f1_macro': 0.06440382941688425, 'ece': 0.18109391141917186}
2026-02-12 14:02:32 - INFO - All results: {'f1_macro': 0.06440382941688425, 'ece': 0.18109391141917186}

Total time taken: 247.87 seconds
2026-02-12 14:02:32 - INFO - 
Total time taken: 247.87 seconds
2026-02-12 14:02:32 - INFO - Trial 3 finished with value: 0.06440382941688425 and parameters: {'learning_rate': 0.0005045673711792034, 'weight_decay': 0.008302622826213106, 'batch_size': 32, 'co_train_epochs': 13, 'epoch_patience': 5}. Best is trial 2 with value: 0.06440382941688425.
Using devices: cuda, cuda
2026-02-12 14:02:32 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 14:02:32 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 14:02:32 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 14:02:32 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.0001294988496389101
Weight Decay: 0.00025048159452184055
Batch Size: 32
No. Epochs: 15
Epoch Patience: 3
 Accumulation Steps: 2
2026-02-12 14:02:34 - INFO - Learning Rate: 0.0001294988496389101
Weight Decay: 0.00025048159452184055
Batch Size: 32
No. Epochs: 15
Epoch Patience: 3
 Accumulation Steps: 2
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 14:02:36 - INFO - Generating initial weights
Time taken for Epoch 1:8.68 - F1: 0.0442
2026-02-12 14:02:47 - INFO - Time taken for Epoch 1:8.68 - F1: 0.0442
Time taken for Epoch 2:8.64 - F1: 0.0452
2026-02-12 14:02:55 - INFO - Time taken for Epoch 2:8.64 - F1: 0.0452
Time taken for Epoch 3:8.58 - F1: 0.0901
2026-02-12 14:03:04 - INFO - Time taken for Epoch 3:8.58 - F1: 0.0901
Time taken for Epoch 4:8.65 - F1: 0.2142
2026-02-12 14:03:12 - INFO - Time taken for Epoch 4:8.65 - F1: 0.2142
Time taken for Epoch 5:8.61 - F1: 0.2693
2026-02-12 14:03:21 - INFO - Time taken for Epoch 5:8.61 - F1: 0.2693
Time taken for Epoch 6:8.61 - F1: 0.3316
2026-02-12 14:03:30 - INFO - Time taken for Epoch 6:8.61 - F1: 0.3316
Time taken for Epoch 7:8.64 - F1: 0.3291
2026-02-12 14:03:38 - INFO - Time taken for Epoch 7:8.64 - F1: 0.3291
Time taken for Epoch 8:8.61 - F1: 0.3229
2026-02-12 14:03:47 - INFO - Time taken for Epoch 8:8.61 - F1: 0.3229
Time taken for Epoch 9:8.63 - F1: 0.3552
2026-02-12 14:03:55 - INFO - Time taken for Epoch 9:8.63 - F1: 0.3552
Time taken for Epoch 10:8.58 - F1: 0.3527
2026-02-12 14:04:04 - INFO - Time taken for Epoch 10:8.58 - F1: 0.3527
Time taken for Epoch 11:8.57 - F1: 0.3473
2026-02-12 14:04:13 - INFO - Time taken for Epoch 11:8.57 - F1: 0.3473
Time taken for Epoch 12:8.62 - F1: 0.3766
2026-02-12 14:04:21 - INFO - Time taken for Epoch 12:8.62 - F1: 0.3766
Time taken for Epoch 13:8.58 - F1: 0.3768
2026-02-12 14:04:30 - INFO - Time taken for Epoch 13:8.58 - F1: 0.3768
Time taken for Epoch 14:8.64 - F1: 0.3646
2026-02-12 14:04:38 - INFO - Time taken for Epoch 14:8.64 - F1: 0.3646
Time taken for Epoch 15:8.58 - F1: 0.3746
2026-02-12 14:04:47 - INFO - Time taken for Epoch 15:8.58 - F1: 0.3746
Best F1:0.3768 - Best Epoch:13
2026-02-12 14:04:47 - INFO - Best F1:0.3768 - Best Epoch:13
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 14:04:49 - INFO - Starting co-training
Time taken for Epoch 1: 12.93s - F1: 0.28329509
2026-02-12 14:05:03 - INFO - Time taken for Epoch 1: 12.93s - F1: 0.28329509
Time taken for Epoch 2: 13.94s - F1: 0.28597820
2026-02-12 14:05:17 - INFO - Time taken for Epoch 2: 13.94s - F1: 0.28597820
Time taken for Epoch 3: 21.01s - F1: 0.30408241
2026-02-12 14:05:38 - INFO - Time taken for Epoch 3: 21.01s - F1: 0.30408241
Time taken for Epoch 4: 19.42s - F1: 0.33087201
2026-02-12 14:05:57 - INFO - Time taken for Epoch 4: 19.42s - F1: 0.33087201
Time taken for Epoch 5: 18.93s - F1: 0.34122621
2026-02-12 14:06:16 - INFO - Time taken for Epoch 5: 18.93s - F1: 0.34122621
Time taken for Epoch 6: 36.57s - F1: 0.35357924
2026-02-12 14:06:52 - INFO - Time taken for Epoch 6: 36.57s - F1: 0.35357924
Time taken for Epoch 7: 16.28s - F1: 0.35752191
2026-02-12 14:07:09 - INFO - Time taken for Epoch 7: 16.28s - F1: 0.35752191
Time taken for Epoch 8: 16.68s - F1: 0.31592406
2026-02-12 14:07:25 - INFO - Time taken for Epoch 8: 16.68s - F1: 0.31592406
Time taken for Epoch 9: 12.85s - F1: 0.33255522
2026-02-12 14:07:38 - INFO - Time taken for Epoch 9: 12.85s - F1: 0.33255522
Time taken for Epoch 10: 12.86s - F1: 0.33737035
2026-02-12 14:07:51 - INFO - Time taken for Epoch 10: 12.86s - F1: 0.33737035
Performance not improving for 3 consecutive epochs.
Performance not improving for 3 consecutive epochs.
2026-02-12 14:07:51 - INFO - Performance not improving for 3 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 14:07:55 - INFO - Fine-tuning models
Time taken for Epoch 1:2.44 - F1: 0.3788
2026-02-12 14:07:57 - INFO - Time taken for Epoch 1:2.44 - F1: 0.3788
Time taken for Epoch 2:3.34 - F1: 0.3231
2026-02-12 14:08:01 - INFO - Time taken for Epoch 2:3.34 - F1: 0.3231
Time taken for Epoch 3:2.39 - F1: 0.3935
2026-02-12 14:08:03 - INFO - Time taken for Epoch 3:2.39 - F1: 0.3935
Time taken for Epoch 4:32.29 - F1: 0.4627
2026-02-12 14:08:35 - INFO - Time taken for Epoch 4:32.29 - F1: 0.4627
Time taken for Epoch 5:8.21 - F1: 0.4313
2026-02-12 14:08:43 - INFO - Time taken for Epoch 5:8.21 - F1: 0.4313
Time taken for Epoch 6:2.41 - F1: 0.4364
2026-02-12 14:08:46 - INFO - Time taken for Epoch 6:2.41 - F1: 0.4364
Time taken for Epoch 7:2.40 - F1: 0.4314
2026-02-12 14:08:48 - INFO - Time taken for Epoch 7:2.40 - F1: 0.4314
Time taken for Epoch 8:2.40 - F1: 0.4171
2026-02-12 14:08:51 - INFO - Time taken for Epoch 8:2.40 - F1: 0.4171
Time taken for Epoch 9:2.40 - F1: 0.4438
2026-02-12 14:08:53 - INFO - Time taken for Epoch 9:2.40 - F1: 0.4438
Time taken for Epoch 10:2.40 - F1: 0.4297
2026-02-12 14:08:55 - INFO - Time taken for Epoch 10:2.40 - F1: 0.4297
Time taken for Epoch 11:2.39 - F1: 0.4665
2026-02-12 14:08:58 - INFO - Time taken for Epoch 11:2.39 - F1: 0.4665
Time taken for Epoch 12:8.68 - F1: 0.4697
2026-02-12 14:09:07 - INFO - Time taken for Epoch 12:8.68 - F1: 0.4697
Time taken for Epoch 13:7.19 - F1: 0.4490
2026-02-12 14:09:14 - INFO - Time taken for Epoch 13:7.19 - F1: 0.4490
Time taken for Epoch 14:2.41 - F1: 0.4585
2026-02-12 14:09:16 - INFO - Time taken for Epoch 14:2.41 - F1: 0.4585
Time taken for Epoch 15:2.41 - F1: 0.4411
2026-02-12 14:09:19 - INFO - Time taken for Epoch 15:2.41 - F1: 0.4411
Time taken for Epoch 16:2.41 - F1: 0.4530
2026-02-12 14:09:21 - INFO - Time taken for Epoch 16:2.41 - F1: 0.4530
Time taken for Epoch 17:2.40 - F1: 0.4583
2026-02-12 14:09:23 - INFO - Time taken for Epoch 17:2.40 - F1: 0.4583
Time taken for Epoch 18:2.39 - F1: 0.4587
2026-02-12 14:09:26 - INFO - Time taken for Epoch 18:2.39 - F1: 0.4587
Time taken for Epoch 19:2.40 - F1: 0.4365
2026-02-12 14:09:28 - INFO - Time taken for Epoch 19:2.40 - F1: 0.4365
Time taken for Epoch 20:2.39 - F1: 0.4420
2026-02-12 14:09:31 - INFO - Time taken for Epoch 20:2.39 - F1: 0.4420
Time taken for Epoch 21:2.39 - F1: 0.4620
2026-02-12 14:09:33 - INFO - Time taken for Epoch 21:2.39 - F1: 0.4620
Time taken for Epoch 22:2.40 - F1: 0.4531
2026-02-12 14:09:35 - INFO - Time taken for Epoch 22:2.40 - F1: 0.4531
Performance not improving for 10 consecutive epochs.
2026-02-12 14:09:35 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.4697 - Best Epoch:11
2026-02-12 14:09:35 - INFO - Best F1:0.4697 - Best Epoch:11
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.4546, Test ECE: 0.1629
2026-02-12 14:09:42 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.4546, Test ECE: 0.1629
All results: {'f1_macro': 0.4546221432577712, 'ece': 0.16290261476887666}
2026-02-12 14:09:42 - INFO - All results: {'f1_macro': 0.4546221432577712, 'ece': 0.16290261476887666}

Total time taken: 429.74 seconds
2026-02-12 14:09:42 - INFO - 
Total time taken: 429.74 seconds
2026-02-12 14:09:42 - INFO - Trial 4 finished with value: 0.4546221432577712 and parameters: {'learning_rate': 0.0001294988496389101, 'weight_decay': 0.00025048159452184055, 'batch_size': 32, 'co_train_epochs': 15, 'epoch_patience': 3}. Best is trial 4 with value: 0.4546221432577712.
Using devices: cuda, cuda
2026-02-12 14:09:42 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 14:09:42 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 14:09:42 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 14:09:42 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 1.0780582690136171e-05
Weight Decay: 0.0005846723162521536
Batch Size: 32
No. Epochs: 14
Epoch Patience: 1
 Accumulation Steps: 2
2026-02-12 14:09:44 - INFO - Learning Rate: 1.0780582690136171e-05
Weight Decay: 0.0005846723162521536
Batch Size: 32
No. Epochs: 14
Epoch Patience: 1
 Accumulation Steps: 2
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 14:09:46 - INFO - Generating initial weights
Time taken for Epoch 1:8.80 - F1: 0.0255
2026-02-12 14:09:56 - INFO - Time taken for Epoch 1:8.80 - F1: 0.0255
Time taken for Epoch 2:8.63 - F1: 0.0277
2026-02-12 14:10:05 - INFO - Time taken for Epoch 2:8.63 - F1: 0.0277
Time taken for Epoch 3:8.65 - F1: 0.0291
2026-02-12 14:10:13 - INFO - Time taken for Epoch 3:8.65 - F1: 0.0291
Time taken for Epoch 4:8.60 - F1: 0.0386
2026-02-12 14:10:22 - INFO - Time taken for Epoch 4:8.60 - F1: 0.0386
Time taken for Epoch 5:8.63 - F1: 0.0616
2026-02-12 14:10:31 - INFO - Time taken for Epoch 5:8.63 - F1: 0.0616
Time taken for Epoch 6:8.65 - F1: 0.1029
2026-02-12 14:10:39 - INFO - Time taken for Epoch 6:8.65 - F1: 0.1029
Time taken for Epoch 7:8.59 - F1: 0.1091
2026-02-12 14:10:48 - INFO - Time taken for Epoch 7:8.59 - F1: 0.1091
Time taken for Epoch 8:8.64 - F1: 0.1363
2026-02-12 14:10:56 - INFO - Time taken for Epoch 8:8.64 - F1: 0.1363
Time taken for Epoch 9:8.60 - F1: 0.1444
2026-02-12 14:11:05 - INFO - Time taken for Epoch 9:8.60 - F1: 0.1444
Time taken for Epoch 10:8.68 - F1: 0.1414
2026-02-12 14:11:14 - INFO - Time taken for Epoch 10:8.68 - F1: 0.1414
Time taken for Epoch 11:8.62 - F1: 0.1373
2026-02-12 14:11:22 - INFO - Time taken for Epoch 11:8.62 - F1: 0.1373
Time taken for Epoch 12:8.59 - F1: 0.1382
2026-02-12 14:11:31 - INFO - Time taken for Epoch 12:8.59 - F1: 0.1382
Time taken for Epoch 13:8.67 - F1: 0.1643
2026-02-12 14:11:40 - INFO - Time taken for Epoch 13:8.67 - F1: 0.1643
Time taken for Epoch 14:8.61 - F1: 0.1704
2026-02-12 14:11:48 - INFO - Time taken for Epoch 14:8.61 - F1: 0.1704
Best F1:0.1704 - Best Epoch:14
2026-02-12 14:11:48 - INFO - Best F1:0.1704 - Best Epoch:14
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 14:11:51 - INFO - Starting co-training
Time taken for Epoch 1: 12.93s - F1: 0.06452703
2026-02-12 14:12:04 - INFO - Time taken for Epoch 1: 12.93s - F1: 0.06452703
Time taken for Epoch 2: 14.04s - F1: 0.06452703
2026-02-12 14:12:18 - INFO - Time taken for Epoch 2: 14.04s - F1: 0.06452703
Performance not improving for 1 consecutive epochs.
Performance not improving for 1 consecutive epochs.
2026-02-12 14:12:18 - INFO - Performance not improving for 1 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 14:12:21 - INFO - Fine-tuning models
Time taken for Epoch 1:2.48 - F1: 0.0645
2026-02-12 14:12:24 - INFO - Time taken for Epoch 1:2.48 - F1: 0.0645
Time taken for Epoch 2:3.47 - F1: 0.0645
2026-02-12 14:12:28 - INFO - Time taken for Epoch 2:3.47 - F1: 0.0645
Time taken for Epoch 3:2.39 - F1: 0.0645
2026-02-12 14:12:30 - INFO - Time taken for Epoch 3:2.39 - F1: 0.0645
Time taken for Epoch 4:2.41 - F1: 0.0645
2026-02-12 14:12:32 - INFO - Time taken for Epoch 4:2.41 - F1: 0.0645
Time taken for Epoch 5:2.41 - F1: 0.0645
2026-02-12 14:12:35 - INFO - Time taken for Epoch 5:2.41 - F1: 0.0645
Time taken for Epoch 6:2.39 - F1: 0.0645
2026-02-12 14:12:37 - INFO - Time taken for Epoch 6:2.39 - F1: 0.0645
Time taken for Epoch 7:2.39 - F1: 0.0645
2026-02-12 14:12:40 - INFO - Time taken for Epoch 7:2.39 - F1: 0.0645
Time taken for Epoch 8:2.40 - F1: 0.0686
2026-02-12 14:12:42 - INFO - Time taken for Epoch 8:2.40 - F1: 0.0686
Time taken for Epoch 9:7.21 - F1: 0.1171
2026-02-12 14:12:49 - INFO - Time taken for Epoch 9:7.21 - F1: 0.1171
Time taken for Epoch 10:7.94 - F1: 0.1427
2026-02-12 14:12:57 - INFO - Time taken for Epoch 10:7.94 - F1: 0.1427
Time taken for Epoch 11:8.97 - F1: 0.1544
2026-02-12 14:13:06 - INFO - Time taken for Epoch 11:8.97 - F1: 0.1544
Time taken for Epoch 12:8.89 - F1: 0.1619
2026-02-12 14:13:15 - INFO - Time taken for Epoch 12:8.89 - F1: 0.1619
Time taken for Epoch 13:7.69 - F1: 0.1728
2026-02-12 14:13:23 - INFO - Time taken for Epoch 13:7.69 - F1: 0.1728
Time taken for Epoch 14:9.46 - F1: 0.1913
2026-02-12 14:13:32 - INFO - Time taken for Epoch 14:9.46 - F1: 0.1913
Time taken for Epoch 15:7.62 - F1: 0.2156
2026-02-12 14:13:40 - INFO - Time taken for Epoch 15:7.62 - F1: 0.2156
Time taken for Epoch 16:6.43 - F1: 0.2363
2026-02-12 14:13:46 - INFO - Time taken for Epoch 16:6.43 - F1: 0.2363
Time taken for Epoch 17:6.29 - F1: 0.2523
2026-02-12 14:13:53 - INFO - Time taken for Epoch 17:6.29 - F1: 0.2523
Time taken for Epoch 18:6.76 - F1: 0.2521
2026-02-12 14:13:59 - INFO - Time taken for Epoch 18:6.76 - F1: 0.2521
Time taken for Epoch 19:2.39 - F1: 0.3063
2026-02-12 14:14:02 - INFO - Time taken for Epoch 19:2.39 - F1: 0.3063
Time taken for Epoch 20:10.30 - F1: 0.3222
2026-02-12 14:14:12 - INFO - Time taken for Epoch 20:10.30 - F1: 0.3222
Time taken for Epoch 21:11.44 - F1: 0.3391
2026-02-12 14:14:23 - INFO - Time taken for Epoch 21:11.44 - F1: 0.3391
Time taken for Epoch 22:10.69 - F1: 0.3578
2026-02-12 14:14:34 - INFO - Time taken for Epoch 22:10.69 - F1: 0.3578
Time taken for Epoch 23:7.47 - F1: 0.3504
2026-02-12 14:14:42 - INFO - Time taken for Epoch 23:7.47 - F1: 0.3504
Time taken for Epoch 24:2.43 - F1: 0.3294
2026-02-12 14:14:44 - INFO - Time taken for Epoch 24:2.43 - F1: 0.3294
Time taken for Epoch 25:2.44 - F1: 0.3304
2026-02-12 14:14:46 - INFO - Time taken for Epoch 25:2.44 - F1: 0.3304
Time taken for Epoch 26:2.44 - F1: 0.3334
2026-02-12 14:14:49 - INFO - Time taken for Epoch 26:2.44 - F1: 0.3334
Time taken for Epoch 27:2.42 - F1: 0.3465
2026-02-12 14:14:51 - INFO - Time taken for Epoch 27:2.42 - F1: 0.3465
Time taken for Epoch 28:2.42 - F1: 0.3506
2026-02-12 14:14:54 - INFO - Time taken for Epoch 28:2.42 - F1: 0.3506
Time taken for Epoch 29:2.43 - F1: 0.3490
2026-02-12 14:14:56 - INFO - Time taken for Epoch 29:2.43 - F1: 0.3490
Time taken for Epoch 30:2.42 - F1: 0.3502
2026-02-12 14:14:59 - INFO - Time taken for Epoch 30:2.42 - F1: 0.3502
Time taken for Epoch 31:2.40 - F1: 0.3533
2026-02-12 14:15:01 - INFO - Time taken for Epoch 31:2.40 - F1: 0.3533
Time taken for Epoch 32:2.40 - F1: 0.3583
2026-02-12 14:15:03 - INFO - Time taken for Epoch 32:2.40 - F1: 0.3583
Time taken for Epoch 33:8.34 - F1: 0.3558
2026-02-12 14:15:12 - INFO - Time taken for Epoch 33:8.34 - F1: 0.3558
Time taken for Epoch 34:2.40 - F1: 0.3548
2026-02-12 14:15:14 - INFO - Time taken for Epoch 34:2.40 - F1: 0.3548
Time taken for Epoch 35:2.40 - F1: 0.3623
2026-02-12 14:15:17 - INFO - Time taken for Epoch 35:2.40 - F1: 0.3623
Time taken for Epoch 36:11.08 - F1: 0.3700
2026-02-12 14:15:28 - INFO - Time taken for Epoch 36:11.08 - F1: 0.3700
Time taken for Epoch 37:10.55 - F1: 0.3776
2026-02-12 14:15:38 - INFO - Time taken for Epoch 37:10.55 - F1: 0.3776
Time taken for Epoch 38:10.21 - F1: 0.3716
2026-02-12 14:15:48 - INFO - Time taken for Epoch 38:10.21 - F1: 0.3716
Time taken for Epoch 39:2.39 - F1: 0.4004
2026-02-12 14:15:51 - INFO - Time taken for Epoch 39:2.39 - F1: 0.4004
Time taken for Epoch 40:10.93 - F1: 0.4039
2026-02-12 14:16:02 - INFO - Time taken for Epoch 40:10.93 - F1: 0.4039
Time taken for Epoch 41:10.43 - F1: 0.3931
2026-02-12 14:16:12 - INFO - Time taken for Epoch 41:10.43 - F1: 0.3931
Time taken for Epoch 42:2.41 - F1: 0.3943
2026-02-12 14:16:15 - INFO - Time taken for Epoch 42:2.41 - F1: 0.3943
Time taken for Epoch 43:2.41 - F1: 0.3952
2026-02-12 14:16:17 - INFO - Time taken for Epoch 43:2.41 - F1: 0.3952
Time taken for Epoch 44:2.41 - F1: 0.4167
2026-02-12 14:16:19 - INFO - Time taken for Epoch 44:2.41 - F1: 0.4167
Time taken for Epoch 45:9.48 - F1: 0.4161
2026-02-12 14:16:29 - INFO - Time taken for Epoch 45:9.48 - F1: 0.4161
Time taken for Epoch 46:2.41 - F1: 0.4046
2026-02-12 14:16:31 - INFO - Time taken for Epoch 46:2.41 - F1: 0.4046
Time taken for Epoch 47:2.41 - F1: 0.3940
2026-02-12 14:16:34 - INFO - Time taken for Epoch 47:2.41 - F1: 0.3940
Time taken for Epoch 48:2.41 - F1: 0.3862
2026-02-12 14:16:36 - INFO - Time taken for Epoch 48:2.41 - F1: 0.3862
Time taken for Epoch 49:2.40 - F1: 0.3977
2026-02-12 14:16:38 - INFO - Time taken for Epoch 49:2.40 - F1: 0.3977
Time taken for Epoch 50:2.40 - F1: 0.4130
2026-02-12 14:16:41 - INFO - Time taken for Epoch 50:2.40 - F1: 0.4130
Time taken for Epoch 51:2.39 - F1: 0.3985
2026-02-12 14:16:43 - INFO - Time taken for Epoch 51:2.39 - F1: 0.3985
Time taken for Epoch 52:2.39 - F1: 0.3968
2026-02-12 14:16:46 - INFO - Time taken for Epoch 52:2.39 - F1: 0.3968
Time taken for Epoch 53:2.39 - F1: 0.3881
2026-02-12 14:16:48 - INFO - Time taken for Epoch 53:2.39 - F1: 0.3881
Time taken for Epoch 54:2.39 - F1: 0.3863
2026-02-12 14:16:50 - INFO - Time taken for Epoch 54:2.39 - F1: 0.3863
Performance not improving for 10 consecutive epochs.
2026-02-12 14:16:50 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.4167 - Best Epoch:43
2026-02-12 14:16:50 - INFO - Best F1:0.4167 - Best Epoch:43
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.4176, Test ECE: 0.0810
2026-02-12 14:16:56 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.4176, Test ECE: 0.0810
All results: {'f1_macro': 0.41761756031697567, 'ece': 0.08099428898103735}
2026-02-12 14:16:56 - INFO - All results: {'f1_macro': 0.41761756031697567, 'ece': 0.08099428898103735}

Total time taken: 434.11 seconds
2026-02-12 14:16:56 - INFO - 
Total time taken: 434.11 seconds
2026-02-12 14:16:56 - INFO - Trial 5 finished with value: 0.41761756031697567 and parameters: {'learning_rate': 1.0780582690136171e-05, 'weight_decay': 0.0005846723162521536, 'batch_size': 32, 'co_train_epochs': 14, 'epoch_patience': 1}. Best is trial 4 with value: 0.4546221432577712.
Using devices: cuda, cuda
2026-02-12 14:16:56 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 14:16:56 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 14:16:56 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 14:16:56 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 1.5519500495584526e-05
Weight Decay: 0.0002675675200947054
Batch Size: 16
No. Epochs: 16
Epoch Patience: 10
 Accumulation Steps: 4
2026-02-12 14:16:57 - INFO - Learning Rate: 1.5519500495584526e-05
Weight Decay: 0.0002675675200947054
Batch Size: 16
No. Epochs: 16
Epoch Patience: 10
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 14:16:58 - INFO - Generating initial weights
Time taken for Epoch 1:9.58 - F1: 0.0255
2026-02-12 14:17:09 - INFO - Time taken for Epoch 1:9.58 - F1: 0.0255
Time taken for Epoch 2:9.43 - F1: 0.0290
2026-02-12 14:17:19 - INFO - Time taken for Epoch 2:9.43 - F1: 0.0290
Time taken for Epoch 3:9.42 - F1: 0.0338
2026-02-12 14:17:28 - INFO - Time taken for Epoch 3:9.42 - F1: 0.0338
Time taken for Epoch 4:9.38 - F1: 0.0596
2026-02-12 14:17:37 - INFO - Time taken for Epoch 4:9.38 - F1: 0.0596
Time taken for Epoch 5:9.43 - F1: 0.0999
2026-02-12 14:17:47 - INFO - Time taken for Epoch 5:9.43 - F1: 0.0999
Time taken for Epoch 6:9.40 - F1: 0.1115
2026-02-12 14:17:56 - INFO - Time taken for Epoch 6:9.40 - F1: 0.1115
Time taken for Epoch 7:9.39 - F1: 0.1268
2026-02-12 14:18:06 - INFO - Time taken for Epoch 7:9.39 - F1: 0.1268
Time taken for Epoch 8:9.41 - F1: 0.1310
2026-02-12 14:18:15 - INFO - Time taken for Epoch 8:9.41 - F1: 0.1310
Time taken for Epoch 9:9.41 - F1: 0.1382
2026-02-12 14:18:24 - INFO - Time taken for Epoch 9:9.41 - F1: 0.1382
Time taken for Epoch 10:9.40 - F1: 0.1557
2026-02-12 14:18:34 - INFO - Time taken for Epoch 10:9.40 - F1: 0.1557
Time taken for Epoch 11:9.41 - F1: 0.1792
2026-02-12 14:18:43 - INFO - Time taken for Epoch 11:9.41 - F1: 0.1792
Time taken for Epoch 12:9.44 - F1: 0.1717
2026-02-12 14:18:53 - INFO - Time taken for Epoch 12:9.44 - F1: 0.1717
Time taken for Epoch 13:9.41 - F1: 0.1934
2026-02-12 14:19:02 - INFO - Time taken for Epoch 13:9.41 - F1: 0.1934
Time taken for Epoch 14:9.39 - F1: 0.1989
2026-02-12 14:19:11 - INFO - Time taken for Epoch 14:9.39 - F1: 0.1989
Time taken for Epoch 15:9.42 - F1: 0.2066
2026-02-12 14:19:21 - INFO - Time taken for Epoch 15:9.42 - F1: 0.2066
Time taken for Epoch 16:9.45 - F1: 0.2174
2026-02-12 14:19:30 - INFO - Time taken for Epoch 16:9.45 - F1: 0.2174
Best F1:0.2174 - Best Epoch:16
2026-02-12 14:19:30 - INFO - Best F1:0.2174 - Best Epoch:16
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 14:19:32 - INFO - Starting co-training
Time taken for Epoch 1: 10.89s - F1: 0.06452703
2026-02-12 14:19:43 - INFO - Time taken for Epoch 1: 10.89s - F1: 0.06452703
Time taken for Epoch 2: 11.92s - F1: 0.13782772
2026-02-12 14:19:55 - INFO - Time taken for Epoch 2: 11.92s - F1: 0.13782772
Time taken for Epoch 3: 15.85s - F1: 0.18656493
2026-02-12 14:20:11 - INFO - Time taken for Epoch 3: 15.85s - F1: 0.18656493
Time taken for Epoch 4: 16.11s - F1: 0.21132803
2026-02-12 14:20:27 - INFO - Time taken for Epoch 4: 16.11s - F1: 0.21132803
Time taken for Epoch 5: 24.93s - F1: 0.29391949
2026-02-12 14:20:52 - INFO - Time taken for Epoch 5: 24.93s - F1: 0.29391949
Time taken for Epoch 6: 16.44s - F1: 0.29458121
2026-02-12 14:21:08 - INFO - Time taken for Epoch 6: 16.44s - F1: 0.29458121
Time taken for Epoch 7: 14.61s - F1: 0.30302947
2026-02-12 14:21:23 - INFO - Time taken for Epoch 7: 14.61s - F1: 0.30302947
Time taken for Epoch 8: 15.33s - F1: 0.30136245
2026-02-12 14:21:38 - INFO - Time taken for Epoch 8: 15.33s - F1: 0.30136245
Time taken for Epoch 9: 10.88s - F1: 0.29821344
2026-02-12 14:21:49 - INFO - Time taken for Epoch 9: 10.88s - F1: 0.29821344
Time taken for Epoch 10: 10.89s - F1: 0.30227867
2026-02-12 14:22:00 - INFO - Time taken for Epoch 10: 10.89s - F1: 0.30227867
Time taken for Epoch 11: 10.87s - F1: 0.32864982
2026-02-12 14:22:11 - INFO - Time taken for Epoch 11: 10.87s - F1: 0.32864982
Time taken for Epoch 12: 14.90s - F1: 0.35168895
2026-02-12 14:22:26 - INFO - Time taken for Epoch 12: 14.90s - F1: 0.35168895
Time taken for Epoch 13: 11.94s - F1: 0.34931305
2026-02-12 14:22:38 - INFO - Time taken for Epoch 13: 11.94s - F1: 0.34931305
Time taken for Epoch 14: 10.89s - F1: 0.34962294
2026-02-12 14:22:49 - INFO - Time taken for Epoch 14: 10.89s - F1: 0.34962294
Time taken for Epoch 15: 10.88s - F1: 0.33475047
2026-02-12 14:22:59 - INFO - Time taken for Epoch 15: 10.88s - F1: 0.33475047
Time taken for Epoch 16: 10.82s - F1: 0.34089576
2026-02-12 14:23:10 - INFO - Time taken for Epoch 16: 10.82s - F1: 0.34089576
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 14:23:13 - INFO - Fine-tuning models
Time taken for Epoch 1:2.67 - F1: 0.3355
2026-02-12 14:23:16 - INFO - Time taken for Epoch 1:2.67 - F1: 0.3355
Time taken for Epoch 2:3.49 - F1: 0.3322
2026-02-12 14:23:19 - INFO - Time taken for Epoch 2:3.49 - F1: 0.3322
Time taken for Epoch 3:2.57 - F1: 0.3306
2026-02-12 14:23:22 - INFO - Time taken for Epoch 3:2.57 - F1: 0.3306
Time taken for Epoch 4:2.56 - F1: 0.3350
2026-02-12 14:23:24 - INFO - Time taken for Epoch 4:2.56 - F1: 0.3350
Time taken for Epoch 5:2.57 - F1: 0.3391
2026-02-12 14:23:27 - INFO - Time taken for Epoch 5:2.57 - F1: 0.3391
Time taken for Epoch 6:10.25 - F1: 0.3422
2026-02-12 14:23:37 - INFO - Time taken for Epoch 6:10.25 - F1: 0.3422
Time taken for Epoch 7:9.19 - F1: 0.3443
2026-02-12 14:23:46 - INFO - Time taken for Epoch 7:9.19 - F1: 0.3443
Time taken for Epoch 8:10.74 - F1: 0.3539
2026-02-12 14:23:57 - INFO - Time taken for Epoch 8:10.74 - F1: 0.3539
Time taken for Epoch 9:7.75 - F1: 0.3602
2026-02-12 14:24:05 - INFO - Time taken for Epoch 9:7.75 - F1: 0.3602
Time taken for Epoch 10:6.71 - F1: 0.3632
2026-02-12 14:24:11 - INFO - Time taken for Epoch 10:6.71 - F1: 0.3632
Time taken for Epoch 11:7.03 - F1: 0.3607
2026-02-12 14:24:18 - INFO - Time taken for Epoch 11:7.03 - F1: 0.3607
Time taken for Epoch 12:2.58 - F1: 0.3608
2026-02-12 14:24:21 - INFO - Time taken for Epoch 12:2.58 - F1: 0.3608
Time taken for Epoch 13:2.57 - F1: 0.3861
2026-02-12 14:24:24 - INFO - Time taken for Epoch 13:2.57 - F1: 0.3861
Time taken for Epoch 14:9.69 - F1: 0.4091
2026-02-12 14:24:33 - INFO - Time taken for Epoch 14:9.69 - F1: 0.4091
Time taken for Epoch 15:9.17 - F1: 0.3966
2026-02-12 14:24:42 - INFO - Time taken for Epoch 15:9.17 - F1: 0.3966
Time taken for Epoch 16:2.58 - F1: 0.3947
2026-02-12 14:24:45 - INFO - Time taken for Epoch 16:2.58 - F1: 0.3947
Time taken for Epoch 17:2.57 - F1: 0.3866
2026-02-12 14:24:48 - INFO - Time taken for Epoch 17:2.57 - F1: 0.3866
Time taken for Epoch 18:2.57 - F1: 0.3873
2026-02-12 14:24:50 - INFO - Time taken for Epoch 18:2.57 - F1: 0.3873
Time taken for Epoch 19:2.57 - F1: 0.3921
2026-02-12 14:24:53 - INFO - Time taken for Epoch 19:2.57 - F1: 0.3921
Time taken for Epoch 20:2.59 - F1: 0.3893
2026-02-12 14:24:55 - INFO - Time taken for Epoch 20:2.59 - F1: 0.3893
Time taken for Epoch 21:2.58 - F1: 0.3822
2026-02-12 14:24:58 - INFO - Time taken for Epoch 21:2.58 - F1: 0.3822
Time taken for Epoch 22:2.58 - F1: 0.3827
2026-02-12 14:25:01 - INFO - Time taken for Epoch 22:2.58 - F1: 0.3827
Time taken for Epoch 23:2.58 - F1: 0.3773
2026-02-12 14:25:03 - INFO - Time taken for Epoch 23:2.58 - F1: 0.3773
Time taken for Epoch 24:2.56 - F1: 0.3712
2026-02-12 14:25:06 - INFO - Time taken for Epoch 24:2.56 - F1: 0.3712
Performance not improving for 10 consecutive epochs.
2026-02-12 14:25:06 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.4091 - Best Epoch:13
2026-02-12 14:25:06 - INFO - Best F1:0.4091 - Best Epoch:13
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.3796, Test ECE: 0.0566
2026-02-12 14:25:12 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.3796, Test ECE: 0.0566
All results: {'f1_macro': 0.3796223499512818, 'ece': 0.05658100157096235}
2026-02-12 14:25:12 - INFO - All results: {'f1_macro': 0.3796223499512818, 'ece': 0.05658100157096235}

Total time taken: 495.35 seconds
2026-02-12 14:25:12 - INFO - 
Total time taken: 495.35 seconds
2026-02-12 14:25:12 - INFO - Trial 6 finished with value: 0.3796223499512818 and parameters: {'learning_rate': 1.5519500495584526e-05, 'weight_decay': 0.0002675675200947054, 'batch_size': 16, 'co_train_epochs': 16, 'epoch_patience': 10}. Best is trial 4 with value: 0.4546221432577712.
Using devices: cuda, cuda
2026-02-12 14:25:12 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 14:25:12 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 14:25:12 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 14:25:12 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.0003640901963959067
Weight Decay: 6.933463319996594e-05
Batch Size: 32
No. Epochs: 19
Epoch Patience: 7
 Accumulation Steps: 2
2026-02-12 14:25:12 - INFO - Learning Rate: 0.0003640901963959067
Weight Decay: 6.933463319996594e-05
Batch Size: 32
No. Epochs: 19
Epoch Patience: 7
 Accumulation Steps: 2
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 14:25:14 - INFO - Generating initial weights
Time taken for Epoch 1:8.75 - F1: 0.0156
2026-02-12 14:25:24 - INFO - Time taken for Epoch 1:8.75 - F1: 0.0156
Time taken for Epoch 2:8.65 - F1: 0.0030
2026-02-12 14:25:32 - INFO - Time taken for Epoch 2:8.65 - F1: 0.0030
Time taken for Epoch 3:8.63 - F1: 0.0081
2026-02-12 14:25:41 - INFO - Time taken for Epoch 3:8.63 - F1: 0.0081
Time taken for Epoch 4:8.57 - F1: 0.0199
2026-02-12 14:25:50 - INFO - Time taken for Epoch 4:8.57 - F1: 0.0199
Time taken for Epoch 5:8.65 - F1: 0.0165
2026-02-12 14:25:58 - INFO - Time taken for Epoch 5:8.65 - F1: 0.0165
Time taken for Epoch 6:8.61 - F1: 0.0198
2026-02-12 14:26:07 - INFO - Time taken for Epoch 6:8.61 - F1: 0.0198
Time taken for Epoch 7:8.68 - F1: 0.0029
2026-02-12 14:26:16 - INFO - Time taken for Epoch 7:8.68 - F1: 0.0029
Time taken for Epoch 8:8.66 - F1: 0.0198
2026-02-12 14:26:24 - INFO - Time taken for Epoch 8:8.66 - F1: 0.0198
Time taken for Epoch 9:8.63 - F1: 0.0198
2026-02-12 14:26:33 - INFO - Time taken for Epoch 9:8.63 - F1: 0.0198
Time taken for Epoch 10:8.65 - F1: 0.0165
2026-02-12 14:26:42 - INFO - Time taken for Epoch 10:8.65 - F1: 0.0165
Time taken for Epoch 11:8.57 - F1: 0.0165
2026-02-12 14:26:50 - INFO - Time taken for Epoch 11:8.57 - F1: 0.0165
Time taken for Epoch 12:8.67 - F1: 0.0198
2026-02-12 14:26:59 - INFO - Time taken for Epoch 12:8.67 - F1: 0.0198
Time taken for Epoch 13:8.61 - F1: 0.0198
2026-02-12 14:27:07 - INFO - Time taken for Epoch 13:8.61 - F1: 0.0198
Time taken for Epoch 14:8.63 - F1: 0.0198
2026-02-12 14:27:16 - INFO - Time taken for Epoch 14:8.63 - F1: 0.0198
Time taken for Epoch 15:8.66 - F1: 0.0198
2026-02-12 14:27:25 - INFO - Time taken for Epoch 15:8.66 - F1: 0.0198
Time taken for Epoch 16:8.60 - F1: 0.0198
2026-02-12 14:27:33 - INFO - Time taken for Epoch 16:8.60 - F1: 0.0198
Time taken for Epoch 17:8.65 - F1: 0.0198
2026-02-12 14:27:42 - INFO - Time taken for Epoch 17:8.65 - F1: 0.0198
Time taken for Epoch 18:8.61 - F1: 0.0198
2026-02-12 14:27:51 - INFO - Time taken for Epoch 18:8.61 - F1: 0.0198
Time taken for Epoch 19:8.64 - F1: 0.0198
2026-02-12 14:27:59 - INFO - Time taken for Epoch 19:8.64 - F1: 0.0198
Best F1:0.0199 - Best Epoch:4
2026-02-12 14:27:59 - INFO - Best F1:0.0199 - Best Epoch:4
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 14:28:01 - INFO - Starting co-training
Time taken for Epoch 1: 12.91s - F1: 0.06452703
2026-02-12 14:28:14 - INFO - Time taken for Epoch 1: 12.91s - F1: 0.06452703
Time taken for Epoch 2: 13.96s - F1: 0.06452703
2026-02-12 14:28:28 - INFO - Time taken for Epoch 2: 13.96s - F1: 0.06452703
Time taken for Epoch 3: 12.85s - F1: 0.06452703
2026-02-12 14:28:41 - INFO - Time taken for Epoch 3: 12.85s - F1: 0.06452703
Time taken for Epoch 4: 12.85s - F1: 0.06452703
2026-02-12 14:28:54 - INFO - Time taken for Epoch 4: 12.85s - F1: 0.06452703
Time taken for Epoch 5: 12.87s - F1: 0.06452703
2026-02-12 14:29:06 - INFO - Time taken for Epoch 5: 12.87s - F1: 0.06452703
Time taken for Epoch 6: 12.88s - F1: 0.06452703
2026-02-12 14:29:19 - INFO - Time taken for Epoch 6: 12.88s - F1: 0.06452703
Time taken for Epoch 7: 12.87s - F1: 0.06452703
2026-02-12 14:29:32 - INFO - Time taken for Epoch 7: 12.87s - F1: 0.06452703
Time taken for Epoch 8: 12.88s - F1: 0.06452703
2026-02-12 14:29:45 - INFO - Time taken for Epoch 8: 12.88s - F1: 0.06452703
Performance not improving for 7 consecutive epochs.
Performance not improving for 7 consecutive epochs.
2026-02-12 14:29:45 - INFO - Performance not improving for 7 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 14:29:48 - INFO - Fine-tuning models
Time taken for Epoch 1:2.42 - F1: 0.0645
2026-02-12 14:29:51 - INFO - Time taken for Epoch 1:2.42 - F1: 0.0645
Time taken for Epoch 2:3.57 - F1: 0.0218
2026-02-12 14:29:55 - INFO - Time taken for Epoch 2:3.57 - F1: 0.0218
Time taken for Epoch 3:2.39 - F1: 0.0072
2026-02-12 14:29:57 - INFO - Time taken for Epoch 3:2.39 - F1: 0.0072
Time taken for Epoch 4:2.39 - F1: 0.0072
2026-02-12 14:29:59 - INFO - Time taken for Epoch 4:2.39 - F1: 0.0072
Time taken for Epoch 5:2.39 - F1: 0.0039
2026-02-12 14:30:02 - INFO - Time taken for Epoch 5:2.39 - F1: 0.0039
Time taken for Epoch 6:2.39 - F1: 0.0218
2026-02-12 14:30:04 - INFO - Time taken for Epoch 6:2.39 - F1: 0.0218
Time taken for Epoch 7:2.40 - F1: 0.0645
2026-02-12 14:30:07 - INFO - Time taken for Epoch 7:2.40 - F1: 0.0645
Time taken for Epoch 8:2.41 - F1: 0.0645
2026-02-12 14:30:09 - INFO - Time taken for Epoch 8:2.41 - F1: 0.0645
Time taken for Epoch 9:2.41 - F1: 0.0218
2026-02-12 14:30:11 - INFO - Time taken for Epoch 9:2.41 - F1: 0.0218
Time taken for Epoch 10:2.39 - F1: 0.0218
2026-02-12 14:30:14 - INFO - Time taken for Epoch 10:2.39 - F1: 0.0218
Time taken for Epoch 11:2.39 - F1: 0.0218
2026-02-12 14:30:16 - INFO - Time taken for Epoch 11:2.39 - F1: 0.0218
Performance not improving for 10 consecutive epochs.
2026-02-12 14:30:16 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0645 - Best Epoch:0
2026-02-12 14:30:16 - INFO - Best F1:0.0645 - Best Epoch:0
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0644, Test ECE: 0.0130
2026-02-12 14:30:22 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.0644, Test ECE: 0.0130
All results: {'f1_macro': 0.06440382941688425, 'ece': 0.012975712795771754}
2026-02-12 14:30:22 - INFO - All results: {'f1_macro': 0.06440382941688425, 'ece': 0.012975712795771754}

Total time taken: 310.02 seconds
2026-02-12 14:30:22 - INFO - 
Total time taken: 310.02 seconds
2026-02-12 14:30:22 - INFO - Trial 7 finished with value: 0.06440382941688425 and parameters: {'learning_rate': 0.0003640901963959067, 'weight_decay': 6.933463319996594e-05, 'batch_size': 32, 'co_train_epochs': 19, 'epoch_patience': 7}. Best is trial 4 with value: 0.4546221432577712.
Using devices: cuda, cuda
2026-02-12 14:30:22 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 14:30:22 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 14:30:22 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 14:30:22 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.00016924964705405224
Weight Decay: 0.007055391907708359
Batch Size: 16
No. Epochs: 13
Epoch Patience: 2
 Accumulation Steps: 4
2026-02-12 14:30:22 - INFO - Learning Rate: 0.00016924964705405224
Weight Decay: 0.007055391907708359
Batch Size: 16
No. Epochs: 13
Epoch Patience: 2
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 14:30:24 - INFO - Generating initial weights
Time taken for Epoch 1:9.51 - F1: 0.0272
2026-02-12 14:30:35 - INFO - Time taken for Epoch 1:9.51 - F1: 0.0272
Time taken for Epoch 2:9.41 - F1: 0.0200
2026-02-12 14:30:44 - INFO - Time taken for Epoch 2:9.41 - F1: 0.0200
Time taken for Epoch 3:9.36 - F1: 0.1115
2026-02-12 14:30:53 - INFO - Time taken for Epoch 3:9.36 - F1: 0.1115
Time taken for Epoch 4:9.35 - F1: 0.1917
2026-02-12 14:31:03 - INFO - Time taken for Epoch 4:9.35 - F1: 0.1917
Time taken for Epoch 5:9.37 - F1: 0.2079
2026-02-12 14:31:12 - INFO - Time taken for Epoch 5:9.37 - F1: 0.2079
Time taken for Epoch 6:9.38 - F1: 0.2413
2026-02-12 14:31:21 - INFO - Time taken for Epoch 6:9.38 - F1: 0.2413
Time taken for Epoch 7:9.38 - F1: 0.3350
2026-02-12 14:31:31 - INFO - Time taken for Epoch 7:9.38 - F1: 0.3350
Time taken for Epoch 8:9.47 - F1: 0.3321
2026-02-12 14:31:40 - INFO - Time taken for Epoch 8:9.47 - F1: 0.3321
Time taken for Epoch 9:9.48 - F1: 0.3457
2026-02-12 14:31:50 - INFO - Time taken for Epoch 9:9.48 - F1: 0.3457
Time taken for Epoch 10:9.46 - F1: 0.3635
2026-02-12 14:31:59 - INFO - Time taken for Epoch 10:9.46 - F1: 0.3635
Time taken for Epoch 11:9.35 - F1: 0.3760
2026-02-12 14:32:09 - INFO - Time taken for Epoch 11:9.35 - F1: 0.3760
Time taken for Epoch 12:9.35 - F1: 0.3924
2026-02-12 14:32:18 - INFO - Time taken for Epoch 12:9.35 - F1: 0.3924
Time taken for Epoch 13:9.44 - F1: 0.3970
2026-02-12 14:32:27 - INFO - Time taken for Epoch 13:9.44 - F1: 0.3970
Best F1:0.3970 - Best Epoch:13
2026-02-12 14:32:27 - INFO - Best F1:0.3970 - Best Epoch:13
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 14:32:29 - INFO - Starting co-training
Time taken for Epoch 1: 10.86s - F1: 0.10981899
2026-02-12 14:32:40 - INFO - Time taken for Epoch 1: 10.86s - F1: 0.10981899
Time taken for Epoch 2: 12.04s - F1: 0.21104919
2026-02-12 14:32:52 - INFO - Time taken for Epoch 2: 12.04s - F1: 0.21104919
Time taken for Epoch 3: 16.41s - F1: 0.14250188
2026-02-12 14:33:09 - INFO - Time taken for Epoch 3: 16.41s - F1: 0.14250188
Time taken for Epoch 4: 10.85s - F1: 0.14642256
2026-02-12 14:33:20 - INFO - Time taken for Epoch 4: 10.85s - F1: 0.14642256
Performance not improving for 2 consecutive epochs.
Performance not improving for 2 consecutive epochs.
2026-02-12 14:33:20 - INFO - Performance not improving for 2 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 14:33:22 - INFO - Fine-tuning models
Time taken for Epoch 1:2.67 - F1: 0.1220
2026-02-12 14:33:25 - INFO - Time taken for Epoch 1:2.67 - F1: 0.1220
Time taken for Epoch 2:3.98 - F1: 0.1255
2026-02-12 14:33:29 - INFO - Time taken for Epoch 2:3.98 - F1: 0.1255
Time taken for Epoch 3:7.55 - F1: 0.1575
2026-02-12 14:33:37 - INFO - Time taken for Epoch 3:7.55 - F1: 0.1575
Time taken for Epoch 4:10.72 - F1: 0.1883
2026-02-12 14:33:48 - INFO - Time taken for Epoch 4:10.72 - F1: 0.1883
Time taken for Epoch 5:8.20 - F1: 0.0928
2026-02-12 14:33:56 - INFO - Time taken for Epoch 5:8.20 - F1: 0.0928
Time taken for Epoch 6:2.58 - F1: 0.1942
2026-02-12 14:33:58 - INFO - Time taken for Epoch 6:2.58 - F1: 0.1942
Time taken for Epoch 7:8.15 - F1: 0.2087
2026-02-12 14:34:07 - INFO - Time taken for Epoch 7:8.15 - F1: 0.2087
Time taken for Epoch 8:8.87 - F1: 0.2013
2026-02-12 14:34:15 - INFO - Time taken for Epoch 8:8.87 - F1: 0.2013
Time taken for Epoch 9:2.58 - F1: 0.2043
2026-02-12 14:34:18 - INFO - Time taken for Epoch 9:2.58 - F1: 0.2043
Time taken for Epoch 10:2.57 - F1: 0.2465
2026-02-12 14:34:21 - INFO - Time taken for Epoch 10:2.57 - F1: 0.2465
Time taken for Epoch 11:7.04 - F1: 0.2492
2026-02-12 14:34:28 - INFO - Time taken for Epoch 11:7.04 - F1: 0.2492
Time taken for Epoch 12:7.22 - F1: 0.3012
2026-02-12 14:34:35 - INFO - Time taken for Epoch 12:7.22 - F1: 0.3012
Time taken for Epoch 13:6.37 - F1: 0.3092
2026-02-12 14:34:41 - INFO - Time taken for Epoch 13:6.37 - F1: 0.3092
Time taken for Epoch 14:6.45 - F1: 0.2706
2026-02-12 14:34:48 - INFO - Time taken for Epoch 14:6.45 - F1: 0.2706
Time taken for Epoch 15:2.58 - F1: 0.3151
2026-02-12 14:34:50 - INFO - Time taken for Epoch 15:2.58 - F1: 0.3151
Time taken for Epoch 16:7.18 - F1: 0.3160
2026-02-12 14:34:57 - INFO - Time taken for Epoch 16:7.18 - F1: 0.3160
Time taken for Epoch 17:6.59 - F1: 0.3280
2026-02-12 14:35:04 - INFO - Time taken for Epoch 17:6.59 - F1: 0.3280
Time taken for Epoch 18:6.85 - F1: 0.3360
2026-02-12 14:35:11 - INFO - Time taken for Epoch 18:6.85 - F1: 0.3360
Time taken for Epoch 19:6.82 - F1: 0.2800
2026-02-12 14:35:18 - INFO - Time taken for Epoch 19:6.82 - F1: 0.2800
Time taken for Epoch 20:2.58 - F1: 0.2825
2026-02-12 14:35:20 - INFO - Time taken for Epoch 20:2.58 - F1: 0.2825
Time taken for Epoch 21:2.59 - F1: 0.3040
2026-02-12 14:35:23 - INFO - Time taken for Epoch 21:2.59 - F1: 0.3040
Time taken for Epoch 22:2.61 - F1: 0.2582
2026-02-12 14:35:25 - INFO - Time taken for Epoch 22:2.61 - F1: 0.2582
Time taken for Epoch 23:2.57 - F1: 0.3104
2026-02-12 14:35:28 - INFO - Time taken for Epoch 23:2.57 - F1: 0.3104
Time taken for Epoch 24:2.59 - F1: 0.2806
2026-02-12 14:35:31 - INFO - Time taken for Epoch 24:2.59 - F1: 0.2806
Time taken for Epoch 25:2.57 - F1: 0.2516
2026-02-12 14:35:33 - INFO - Time taken for Epoch 25:2.57 - F1: 0.2516
Time taken for Epoch 26:2.59 - F1: 0.2601
2026-02-12 14:35:36 - INFO - Time taken for Epoch 26:2.59 - F1: 0.2601
Time taken for Epoch 27:2.60 - F1: 0.3256
2026-02-12 14:35:38 - INFO - Time taken for Epoch 27:2.60 - F1: 0.3256
Time taken for Epoch 28:2.61 - F1: 0.3314
2026-02-12 14:35:41 - INFO - Time taken for Epoch 28:2.61 - F1: 0.3314
Performance not improving for 10 consecutive epochs.
2026-02-12 14:35:41 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.3360 - Best Epoch:17
2026-02-12 14:35:41 - INFO - Best F1:0.3360 - Best Epoch:17
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.3411, Test ECE: 0.1938
2026-02-12 14:35:47 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.3411, Test ECE: 0.1938
All results: {'f1_macro': 0.34110050749046583, 'ece': 0.19375299948323826}
2026-02-12 14:35:47 - INFO - All results: {'f1_macro': 0.34110050749046583, 'ece': 0.19375299948323826}

Total time taken: 325.28 seconds
2026-02-12 14:35:47 - INFO - 
Total time taken: 325.28 seconds
2026-02-12 14:35:47 - INFO - Trial 8 finished with value: 0.34110050749046583 and parameters: {'learning_rate': 0.00016924964705405224, 'weight_decay': 0.007055391907708359, 'batch_size': 16, 'co_train_epochs': 13, 'epoch_patience': 2}. Best is trial 4 with value: 0.4546221432577712.
Using devices: cuda, cuda
2026-02-12 14:35:47 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 14:35:47 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 14:35:47 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
2026-02-12 14:35:47 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 25, Seed: 1234, HF Model: GPT-4o, NumShots: 25, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 3.5979971509239296e-05
Weight Decay: 0.0004132943654805911
Batch Size: 16
No. Epochs: 20
Epoch Patience: 6
 Accumulation Steps: 4
2026-02-12 14:35:48 - INFO - Learning Rate: 3.5979971509239296e-05
Weight Decay: 0.0004132943654805911
Batch Size: 16
No. Epochs: 20
Epoch Patience: 6
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 14:35:49 - INFO - Generating initial weights
Time taken for Epoch 1:9.53 - F1: 0.0320
2026-02-12 14:36:00 - INFO - Time taken for Epoch 1:9.53 - F1: 0.0320
Time taken for Epoch 2:9.45 - F1: 0.0475
2026-02-12 14:36:10 - INFO - Time taken for Epoch 2:9.45 - F1: 0.0475
Time taken for Epoch 3:9.41 - F1: 0.0745
2026-02-12 14:36:19 - INFO - Time taken for Epoch 3:9.41 - F1: 0.0745
Time taken for Epoch 4:9.44 - F1: 0.1515
2026-02-12 14:36:28 - INFO - Time taken for Epoch 4:9.44 - F1: 0.1515
Time taken for Epoch 5:9.36 - F1: 0.1721
2026-02-12 14:36:38 - INFO - Time taken for Epoch 5:9.36 - F1: 0.1721
Time taken for Epoch 6:9.35 - F1: 0.1832
2026-02-12 14:36:47 - INFO - Time taken for Epoch 6:9.35 - F1: 0.1832
Time taken for Epoch 7:9.37 - F1: 0.1953
2026-02-12 14:36:57 - INFO - Time taken for Epoch 7:9.37 - F1: 0.1953
Time taken for Epoch 8:9.43 - F1: 0.2139
2026-02-12 14:37:06 - INFO - Time taken for Epoch 8:9.43 - F1: 0.2139
Time taken for Epoch 9:9.35 - F1: 0.2354
2026-02-12 14:37:15 - INFO - Time taken for Epoch 9:9.35 - F1: 0.2354
Time taken for Epoch 10:9.43 - F1: 0.2620
2026-02-12 14:37:25 - INFO - Time taken for Epoch 10:9.43 - F1: 0.2620
Time taken for Epoch 11:9.45 - F1: 0.2744
2026-02-12 14:37:34 - INFO - Time taken for Epoch 11:9.45 - F1: 0.2744
Time taken for Epoch 12:9.34 - F1: 0.2964
2026-02-12 14:37:44 - INFO - Time taken for Epoch 12:9.34 - F1: 0.2964
Time taken for Epoch 13:9.43 - F1: 0.3092
2026-02-12 14:37:53 - INFO - Time taken for Epoch 13:9.43 - F1: 0.3092
Time taken for Epoch 14:9.40 - F1: 0.3180
2026-02-12 14:38:02 - INFO - Time taken for Epoch 14:9.40 - F1: 0.3180
Time taken for Epoch 15:9.34 - F1: 0.3335
2026-02-12 14:38:12 - INFO - Time taken for Epoch 15:9.34 - F1: 0.3335
Time taken for Epoch 16:9.40 - F1: 0.3370
2026-02-12 14:38:21 - INFO - Time taken for Epoch 16:9.40 - F1: 0.3370
Time taken for Epoch 17:9.38 - F1: 0.3297
2026-02-12 14:38:30 - INFO - Time taken for Epoch 17:9.38 - F1: 0.3297
Time taken for Epoch 18:9.37 - F1: 0.3603
2026-02-12 14:38:40 - INFO - Time taken for Epoch 18:9.37 - F1: 0.3603
Time taken for Epoch 19:9.35 - F1: 0.3797
2026-02-12 14:38:49 - INFO - Time taken for Epoch 19:9.35 - F1: 0.3797
Time taken for Epoch 20:9.37 - F1: 0.3664
2026-02-12 14:38:59 - INFO - Time taken for Epoch 20:9.37 - F1: 0.3664
Best F1:0.3797 - Best Epoch:19
2026-02-12 14:38:59 - INFO - Best F1:0.3797 - Best Epoch:19
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 14:39:00 - INFO - Starting co-training
Time taken for Epoch 1: 10.86s - F1: 0.12898211
2026-02-12 14:39:11 - INFO - Time taken for Epoch 1: 10.86s - F1: 0.12898211
Time taken for Epoch 2: 11.91s - F1: 0.22563056
2026-02-12 14:39:23 - INFO - Time taken for Epoch 2: 11.91s - F1: 0.22563056
Time taken for Epoch 3: 22.88s - F1: 0.29639246
2026-02-12 14:39:46 - INFO - Time taken for Epoch 3: 22.88s - F1: 0.29639246
Time taken for Epoch 4: 16.16s - F1: 0.28729837
2026-02-12 14:40:02 - INFO - Time taken for Epoch 4: 16.16s - F1: 0.28729837
Time taken for Epoch 5: 10.96s - F1: 0.29769509
2026-02-12 14:40:13 - INFO - Time taken for Epoch 5: 10.96s - F1: 0.29769509
Time taken for Epoch 6: 17.37s - F1: 0.31674402
2026-02-12 14:40:30 - INFO - Time taken for Epoch 6: 17.37s - F1: 0.31674402
Time taken for Epoch 7: 16.18s - F1: 0.32119165
2026-02-12 14:40:47 - INFO - Time taken for Epoch 7: 16.18s - F1: 0.32119165
Time taken for Epoch 8: 15.99s - F1: 0.32382225
2026-02-12 14:41:03 - INFO - Time taken for Epoch 8: 15.99s - F1: 0.32382225
Time taken for Epoch 9: 16.65s - F1: 0.35040356
2026-02-12 14:41:19 - INFO - Time taken for Epoch 9: 16.65s - F1: 0.35040356
Time taken for Epoch 10: 15.69s - F1: 0.34833957
2026-02-12 14:41:35 - INFO - Time taken for Epoch 10: 15.69s - F1: 0.34833957
Time taken for Epoch 11: 10.84s - F1: 0.33516287
2026-02-12 14:41:46 - INFO - Time taken for Epoch 11: 10.84s - F1: 0.33516287
Time taken for Epoch 12: 10.89s - F1: 0.34600341
2026-02-12 14:41:57 - INFO - Time taken for Epoch 12: 10.89s - F1: 0.34600341
Time taken for Epoch 13: 10.90s - F1: 0.36252360
2026-02-12 14:42:08 - INFO - Time taken for Epoch 13: 10.90s - F1: 0.36252360
Time taken for Epoch 14: 15.98s - F1: 0.35960039
2026-02-12 14:42:24 - INFO - Time taken for Epoch 14: 15.98s - F1: 0.35960039
Time taken for Epoch 15: 10.90s - F1: 0.35509550
2026-02-12 14:42:34 - INFO - Time taken for Epoch 15: 10.90s - F1: 0.35509550
Time taken for Epoch 16: 10.83s - F1: 0.35394302
2026-02-12 14:42:45 - INFO - Time taken for Epoch 16: 10.83s - F1: 0.35394302
Time taken for Epoch 17: 10.87s - F1: 0.34571280
2026-02-12 14:42:56 - INFO - Time taken for Epoch 17: 10.87s - F1: 0.34571280
Time taken for Epoch 18: 10.89s - F1: 0.37444566
2026-02-12 14:43:07 - INFO - Time taken for Epoch 18: 10.89s - F1: 0.37444566
Time taken for Epoch 19: 16.41s - F1: 0.40121894
2026-02-12 14:43:23 - INFO - Time taken for Epoch 19: 16.41s - F1: 0.40121894
Time taken for Epoch 20: 15.81s - F1: 0.41616054
2026-02-12 14:43:39 - INFO - Time taken for Epoch 20: 15.81s - F1: 0.41616054
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Fine-tuning models
2026-02-12 14:43:46 - INFO - Fine-tuning models
Time taken for Epoch 1:2.75 - F1: 0.4528
2026-02-12 14:43:49 - INFO - Time taken for Epoch 1:2.75 - F1: 0.4528
Time taken for Epoch 2:3.71 - F1: 0.4287
2026-02-12 14:43:53 - INFO - Time taken for Epoch 2:3.71 - F1: 0.4287
Time taken for Epoch 3:2.58 - F1: 0.4217
2026-02-12 14:43:56 - INFO - Time taken for Epoch 3:2.58 - F1: 0.4217
Time taken for Epoch 4:2.57 - F1: 0.4281
2026-02-12 14:43:58 - INFO - Time taken for Epoch 4:2.57 - F1: 0.4281
Time taken for Epoch 5:2.57 - F1: 0.4361
2026-02-12 14:44:01 - INFO - Time taken for Epoch 5:2.57 - F1: 0.4361
Time taken for Epoch 6:2.59 - F1: 0.4744
2026-02-12 14:44:03 - INFO - Time taken for Epoch 6:2.59 - F1: 0.4744
Time taken for Epoch 7:8.67 - F1: 0.4825
2026-02-12 14:44:12 - INFO - Time taken for Epoch 7:8.67 - F1: 0.4825
Time taken for Epoch 8:10.85 - F1: 0.5041
2026-02-12 14:44:23 - INFO - Time taken for Epoch 8:10.85 - F1: 0.5041
Time taken for Epoch 9:7.07 - F1: 0.5076
2026-02-12 14:44:30 - INFO - Time taken for Epoch 9:7.07 - F1: 0.5076
Time taken for Epoch 10:7.64 - F1: 0.5085
2026-02-12 14:44:38 - INFO - Time taken for Epoch 10:7.64 - F1: 0.5085
Time taken for Epoch 11:6.44 - F1: 0.5046
2026-02-12 14:44:44 - INFO - Time taken for Epoch 11:6.44 - F1: 0.5046
Time taken for Epoch 12:2.59 - F1: 0.4882
2026-02-12 14:44:47 - INFO - Time taken for Epoch 12:2.59 - F1: 0.4882
Time taken for Epoch 13:2.56 - F1: 0.4947
2026-02-12 14:44:49 - INFO - Time taken for Epoch 13:2.56 - F1: 0.4947
Time taken for Epoch 14:2.56 - F1: 0.4966
2026-02-12 14:44:52 - INFO - Time taken for Epoch 14:2.56 - F1: 0.4966
Time taken for Epoch 15:2.56 - F1: 0.4989
2026-02-12 14:44:54 - INFO - Time taken for Epoch 15:2.56 - F1: 0.4989
Time taken for Epoch 16:2.57 - F1: 0.4984
2026-02-12 14:44:57 - INFO - Time taken for Epoch 16:2.57 - F1: 0.4984
Time taken for Epoch 17:2.58 - F1: 0.4957
2026-02-12 14:44:59 - INFO - Time taken for Epoch 17:2.58 - F1: 0.4957
Time taken for Epoch 18:2.57 - F1: 0.4757
2026-02-12 14:45:02 - INFO - Time taken for Epoch 18:2.57 - F1: 0.4757
Time taken for Epoch 19:2.57 - F1: 0.4971
2026-02-12 14:45:05 - INFO - Time taken for Epoch 19:2.57 - F1: 0.4971
Time taken for Epoch 20:2.57 - F1: 0.4774
2026-02-12 14:45:07 - INFO - Time taken for Epoch 20:2.57 - F1: 0.4774
Performance not improving for 10 consecutive epochs.
2026-02-12 14:45:07 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.5085 - Best Epoch:9
2026-02-12 14:45:07 - INFO - Best F1:0.5085 - Best Epoch:9
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label25-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label25-set1_gpt4o_25_shot_bert-tweet_25_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.4924, Test ECE: 0.1183
2026-02-12 14:45:13 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 25, N: 25 Test SEED: 1234 F1: 0.4924, Test ECE: 0.1183
All results: {'f1_macro': 0.4923687362111446, 'ece': 0.11828779615700932}
2026-02-12 14:45:13 - INFO - All results: {'f1_macro': 0.4923687362111446, 'ece': 0.11828779615700932}

Total time taken: 566.26 seconds
2026-02-12 14:45:13 - INFO - 
Total time taken: 566.26 seconds
2026-02-12 14:45:13 - INFO - Trial 9 finished with value: 0.4923687362111446 and parameters: {'learning_rate': 3.5979971509239296e-05, 'weight_decay': 0.0004132943654805911, 'batch_size': 16, 'co_train_epochs': 20, 'epoch_patience': 6}. Best is trial 9 with value: 0.4923687362111446.

[BEST TRIAL RESULTS]
2026-02-12 14:45:13 - INFO - 
[BEST TRIAL RESULTS]
F1 Score: 0.4924
2026-02-12 14:45:13 - INFO - F1 Score: 0.4924
Params: {'learning_rate': 3.5979971509239296e-05, 'weight_decay': 0.0004132943654805911, 'batch_size': 16, 'co_train_epochs': 20, 'epoch_patience': 6}
2026-02-12 14:45:13 - INFO - Params: {'learning_rate': 3.5979971509239296e-05, 'weight_decay': 0.0004132943654805911, 'batch_size': 16, 'co_train_epochs': 20, 'epoch_patience': 6}
  learning_rate: 3.5979971509239296e-05
2026-02-12 14:45:13 - INFO -   learning_rate: 3.5979971509239296e-05
  weight_decay: 0.0004132943654805911
2026-02-12 14:45:13 - INFO -   weight_decay: 0.0004132943654805911
  batch_size: 16
2026-02-12 14:45:13 - INFO -   batch_size: 16
  co_train_epochs: 20
2026-02-12 14:45:13 - INFO -   co_train_epochs: 20
  epoch_patience: 6
2026-02-12 14:45:13 - INFO -   epoch_patience: 6

Total time taken: 24881.13 seconds
2026-02-12 14:45:13 - INFO - 
Total time taken: 24881.13 seconds