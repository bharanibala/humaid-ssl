2026-02-14 05:50:56 - INFO - 
[Optuna] Starting hyperparameter search with 10 trials.
2026-02-14 05:50:56 - INFO - A new study created in memory with name: study_humanitarian9_hurricane_florence_2018
2026-02-14 05:50:56 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 05:50:56 - INFO - Devices: cuda:1, cuda:1
2026-02-14 05:50:56 - INFO - Starting log
2026-02-14 05:50:56 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 05:50:57 - INFO - Learning Rate: 2.7004300110080383e-05
Weight Decay: 0.001201440267881677
Batch Size: 64
No. Epochs: 17
Epoch Patience: 8
 Accumulation Steps: 1
2026-02-14 05:50:58 - INFO - Generating initial weights
2026-02-14 05:51:19 - INFO - Time taken for Epoch 1:18.73 - F1: 0.0386
2026-02-14 05:51:38 - INFO - Time taken for Epoch 2:18.37 - F1: 0.0386
2026-02-14 05:51:56 - INFO - Time taken for Epoch 3:18.30 - F1: 0.0890
2026-02-14 05:52:14 - INFO - Time taken for Epoch 4:18.34 - F1: 0.1773
2026-02-14 05:52:33 - INFO - Time taken for Epoch 5:18.34 - F1: 0.3429
2026-02-14 05:52:51 - INFO - Time taken for Epoch 6:18.33 - F1: 0.3558
2026-02-14 05:53:09 - INFO - Time taken for Epoch 7:18.40 - F1: 0.3885
2026-02-14 05:53:28 - INFO - Time taken for Epoch 8:18.34 - F1: 0.4322
2026-02-14 05:53:46 - INFO - Time taken for Epoch 9:18.43 - F1: 0.4679
2026-02-14 05:54:05 - INFO - Time taken for Epoch 10:18.40 - F1: 0.4798
2026-02-14 05:54:23 - INFO - Time taken for Epoch 11:18.42 - F1: 0.4786
2026-02-14 05:54:42 - INFO - Time taken for Epoch 12:18.44 - F1: 0.4920
2026-02-14 05:55:00 - INFO - Time taken for Epoch 13:18.37 - F1: 0.5026
2026-02-14 05:55:18 - INFO - Time taken for Epoch 14:18.40 - F1: 0.5057
2026-02-14 05:55:37 - INFO - Time taken for Epoch 15:18.44 - F1: 0.5091
2026-02-14 05:55:55 - INFO - Time taken for Epoch 16:18.46 - F1: 0.5097
2026-02-14 05:56:14 - INFO - Time taken for Epoch 17:18.47 - F1: 0.5120
2026-02-14 05:56:14 - INFO - Best F1:0.5120 - Best Epoch:17
2026-02-14 05:56:15 - INFO - Starting co-training
2026-02-14 05:56:59 - INFO - Time taken for Epoch 1: 43.82s - F1: 0.57599736
2026-02-14 05:57:44 - INFO - Time taken for Epoch 2: 44.31s - F1: 0.60478242
2026-02-14 05:58:28 - INFO - Time taken for Epoch 3: 44.32s - F1: 0.61397778
2026-02-14 05:59:12 - INFO - Time taken for Epoch 4: 44.45s - F1: 0.60866522
2026-02-14 05:59:55 - INFO - Time taken for Epoch 5: 43.16s - F1: 0.62238767
2026-02-14 06:00:41 - INFO - Time taken for Epoch 6: 45.44s - F1: 0.65983938
2026-02-14 06:01:25 - INFO - Time taken for Epoch 7: 44.56s - F1: 0.63734842
2026-02-14 06:02:09 - INFO - Time taken for Epoch 8: 43.48s - F1: 0.64176109
2026-02-14 06:02:53 - INFO - Time taken for Epoch 9: 43.70s - F1: 0.64354817
2026-02-14 06:03:36 - INFO - Time taken for Epoch 10: 43.22s - F1: 0.65647030
2026-02-14 06:04:19 - INFO - Time taken for Epoch 11: 43.07s - F1: 0.66320847
2026-02-14 06:05:04 - INFO - Time taken for Epoch 12: 44.86s - F1: 0.65047619
2026-02-14 06:05:48 - INFO - Time taken for Epoch 13: 43.74s - F1: 0.64667155
2026-02-14 06:06:30 - INFO - Time taken for Epoch 14: 42.72s - F1: 0.66571951
2026-02-14 06:07:14 - INFO - Time taken for Epoch 15: 43.82s - F1: 0.67109282
2026-02-14 06:07:59 - INFO - Time taken for Epoch 16: 44.52s - F1: 0.65710320
2026-02-14 06:08:42 - INFO - Time taken for Epoch 17: 43.46s - F1: 0.65745389
2026-02-14 06:08:45 - INFO - Fine-tuning models
2026-02-14 06:08:50 - INFO - Time taken for Epoch 1:4.68 - F1: 0.6600
2026-02-14 06:08:55 - INFO - Time taken for Epoch 2:5.57 - F1: 0.6648
2026-02-14 06:09:01 - INFO - Time taken for Epoch 3:5.64 - F1: 0.6705
2026-02-14 06:09:07 - INFO - Time taken for Epoch 4:5.62 - F1: 0.6670
2026-02-14 06:09:11 - INFO - Time taken for Epoch 5:4.56 - F1: 0.6709
2026-02-14 06:09:17 - INFO - Time taken for Epoch 6:5.61 - F1: 0.6896
2026-02-14 06:09:22 - INFO - Time taken for Epoch 7:5.63 - F1: 0.6823
2026-02-14 06:09:27 - INFO - Time taken for Epoch 8:4.58 - F1: 0.6859
2026-02-14 06:09:32 - INFO - Time taken for Epoch 9:4.60 - F1: 0.6979
2026-02-14 06:09:38 - INFO - Time taken for Epoch 10:6.37 - F1: 0.6927
2026-02-14 06:09:43 - INFO - Time taken for Epoch 11:4.68 - F1: 0.6907
2026-02-14 06:09:47 - INFO - Time taken for Epoch 12:4.67 - F1: 0.6865
2026-02-14 06:09:52 - INFO - Time taken for Epoch 13:4.67 - F1: 0.6873
2026-02-14 06:09:57 - INFO - Time taken for Epoch 14:4.65 - F1: 0.6931
2026-02-14 06:10:01 - INFO - Time taken for Epoch 15:4.64 - F1: 0.6824
2026-02-14 06:10:06 - INFO - Time taken for Epoch 16:4.64 - F1: 0.6793
2026-02-14 06:10:11 - INFO - Time taken for Epoch 17:4.64 - F1: 0.6811
2026-02-14 06:10:15 - INFO - Time taken for Epoch 18:4.63 - F1: 0.6791
2026-02-14 06:10:20 - INFO - Time taken for Epoch 19:4.61 - F1: 0.6752
2026-02-14 06:10:20 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 06:10:20 - INFO - Best F1:0.6979 - Best Epoch:8
2026-02-14 06:10:27 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6845, Test ECE: 0.0438
2026-02-14 06:10:27 - INFO - All results: {'f1_macro': 0.6844554508877491, 'ece': np.float64(0.04378735341918171)}
2026-02-14 06:10:27 - INFO - 
Total time taken: 1170.79 seconds
2026-02-14 06:10:27 - INFO - Trial 0 finished with value: 0.6844554508877491 and parameters: {'learning_rate': 2.7004300110080383e-05, 'weight_decay': 0.001201440267881677, 'batch_size': 64, 'co_train_epochs': 17, 'epoch_patience': 8}. Best is trial 0 with value: 0.6844554508877491.
2026-02-14 06:10:27 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 06:10:27 - INFO - Devices: cuda:1, cuda:1
2026-02-14 06:10:27 - INFO - Starting log
2026-02-14 06:10:27 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 06:10:27 - INFO - Learning Rate: 0.0007380198946250391
Weight Decay: 0.00011024446871851017
Batch Size: 16
No. Epochs: 17
Epoch Patience: 9
 Accumulation Steps: 4
2026-02-14 06:10:28 - INFO - Generating initial weights
2026-02-14 06:10:53 - INFO - Time taken for Epoch 1:22.69 - F1: 0.0109
2026-02-14 06:11:16 - INFO - Time taken for Epoch 2:22.31 - F1: 0.0321
2026-02-14 06:11:38 - INFO - Time taken for Epoch 3:22.90 - F1: 0.0155
2026-02-14 06:12:02 - INFO - Time taken for Epoch 4:23.41 - F1: 0.0155
2026-02-14 06:12:25 - INFO - Time taken for Epoch 5:23.41 - F1: 0.0155
2026-02-14 06:12:49 - INFO - Time taken for Epoch 6:23.24 - F1: 0.0155
2026-02-14 06:13:12 - INFO - Time taken for Epoch 7:23.01 - F1: 0.0155
2026-02-14 06:13:34 - INFO - Time taken for Epoch 8:22.75 - F1: 0.0155
2026-02-14 06:13:57 - INFO - Time taken for Epoch 9:22.66 - F1: 0.0155
2026-02-14 06:14:20 - INFO - Time taken for Epoch 10:23.38 - F1: 0.0155
2026-02-14 06:14:43 - INFO - Time taken for Epoch 11:22.74 - F1: 0.0155
2026-02-14 06:15:06 - INFO - Time taken for Epoch 12:23.02 - F1: 0.0155
2026-02-14 06:15:29 - INFO - Time taken for Epoch 13:22.64 - F1: 0.0155
2026-02-14 06:15:51 - INFO - Time taken for Epoch 14:22.66 - F1: 0.0155
2026-02-14 06:16:14 - INFO - Time taken for Epoch 15:22.92 - F1: 0.0155
2026-02-14 06:16:37 - INFO - Time taken for Epoch 16:22.88 - F1: 0.0155
2026-02-14 06:17:00 - INFO - Time taken for Epoch 17:22.85 - F1: 0.0155
2026-02-14 06:17:00 - INFO - Best F1:0.0321 - Best Epoch:2
2026-02-14 06:17:01 - INFO - Starting co-training
2026-02-14 06:17:34 - INFO - Time taken for Epoch 1: 32.23s - F1: 0.03212851
2026-02-14 06:18:07 - INFO - Time taken for Epoch 2: 33.28s - F1: 0.03212851
2026-02-14 06:18:39 - INFO - Time taken for Epoch 3: 32.06s - F1: 0.04247539
2026-02-14 06:19:13 - INFO - Time taken for Epoch 4: 33.38s - F1: 0.04247539
2026-02-14 06:19:46 - INFO - Time taken for Epoch 5: 32.91s - F1: 0.04247539
2026-02-14 06:20:19 - INFO - Time taken for Epoch 6: 33.17s - F1: 0.04247539
2026-02-14 06:20:51 - INFO - Time taken for Epoch 7: 32.05s - F1: 0.04247539
2026-02-14 06:21:23 - INFO - Time taken for Epoch 8: 32.00s - F1: 0.04247539
2026-02-14 06:21:55 - INFO - Time taken for Epoch 9: 32.04s - F1: 0.04247539
2026-02-14 06:22:27 - INFO - Time taken for Epoch 10: 31.96s - F1: 0.04247539
2026-02-14 06:22:59 - INFO - Time taken for Epoch 11: 32.22s - F1: 0.04247539
2026-02-14 06:23:31 - INFO - Time taken for Epoch 12: 32.48s - F1: 0.04247539
2026-02-14 06:23:31 - INFO - Performance not improving for 9 consecutive epochs.
2026-02-14 06:23:34 - INFO - Fine-tuning models
2026-02-14 06:23:40 - INFO - Time taken for Epoch 1:6.10 - F1: 0.0205
2026-02-14 06:23:47 - INFO - Time taken for Epoch 2:7.02 - F1: 0.0017
2026-02-14 06:23:53 - INFO - Time taken for Epoch 3:6.04 - F1: 0.0100
2026-02-14 06:23:59 - INFO - Time taken for Epoch 4:6.04 - F1: 0.0155
2026-02-14 06:24:05 - INFO - Time taken for Epoch 5:6.03 - F1: 0.0155
2026-02-14 06:24:11 - INFO - Time taken for Epoch 6:5.94 - F1: 0.0155
2026-02-14 06:24:17 - INFO - Time taken for Epoch 7:6.02 - F1: 0.0155
2026-02-14 06:24:23 - INFO - Time taken for Epoch 8:5.98 - F1: 0.0155
2026-02-14 06:24:29 - INFO - Time taken for Epoch 9:5.99 - F1: 0.0155
2026-02-14 06:24:35 - INFO - Time taken for Epoch 10:5.99 - F1: 0.0155
2026-02-14 06:24:41 - INFO - Time taken for Epoch 11:6.01 - F1: 0.0155
2026-02-14 06:24:41 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 06:24:41 - INFO - Best F1:0.0205 - Best Epoch:0
2026-02-14 06:24:50 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.0205, Test ECE: 0.1755
2026-02-14 06:24:50 - INFO - All results: {'f1_macro': 0.020482809070958303, 'ece': np.float64(0.17549878755084553)}
2026-02-14 06:24:50 - INFO - 
Total time taken: 862.72 seconds
2026-02-14 06:24:50 - INFO - Trial 1 finished with value: 0.020482809070958303 and parameters: {'learning_rate': 0.0007380198946250391, 'weight_decay': 0.00011024446871851017, 'batch_size': 16, 'co_train_epochs': 17, 'epoch_patience': 9}. Best is trial 0 with value: 0.6844554508877491.
2026-02-14 06:24:50 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 06:24:50 - INFO - Devices: cuda:1, cuda:1
2026-02-14 06:24:50 - INFO - Starting log
2026-02-14 06:24:50 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 06:24:50 - INFO - Learning Rate: 2.9578528648397695e-05
Weight Decay: 6.227982089651509e-05
Batch Size: 16
No. Epochs: 17
Epoch Patience: 9
 Accumulation Steps: 4
2026-02-14 06:24:51 - INFO - Generating initial weights
2026-02-14 06:25:17 - INFO - Time taken for Epoch 1:23.42 - F1: 0.0477
2026-02-14 06:25:41 - INFO - Time taken for Epoch 2:23.53 - F1: 0.0877
2026-02-14 06:26:04 - INFO - Time taken for Epoch 3:23.40 - F1: 0.1650
2026-02-14 06:26:28 - INFO - Time taken for Epoch 4:23.51 - F1: 0.3448
2026-02-14 06:26:51 - INFO - Time taken for Epoch 5:23.44 - F1: 0.3645
2026-02-14 06:27:15 - INFO - Time taken for Epoch 6:23.75 - F1: 0.4259
2026-02-14 06:27:38 - INFO - Time taken for Epoch 7:23.64 - F1: 0.4786
2026-02-14 06:28:02 - INFO - Time taken for Epoch 8:23.58 - F1: 0.4804
2026-02-14 06:28:25 - INFO - Time taken for Epoch 9:23.43 - F1: 0.5047
2026-02-14 06:28:48 - INFO - Time taken for Epoch 10:23.05 - F1: 0.5488
2026-02-14 06:29:11 - INFO - Time taken for Epoch 11:23.08 - F1: 0.5651
2026-02-14 06:29:35 - INFO - Time taken for Epoch 12:23.75 - F1: 0.5864
2026-02-14 06:29:59 - INFO - Time taken for Epoch 13:23.58 - F1: 0.5744
2026-02-14 06:30:23 - INFO - Time taken for Epoch 14:23.78 - F1: 0.6040
2026-02-14 06:30:46 - INFO - Time taken for Epoch 15:23.76 - F1: 0.6126
2026-02-14 06:31:10 - INFO - Time taken for Epoch 16:23.42 - F1: 0.6234
2026-02-14 06:31:33 - INFO - Time taken for Epoch 17:23.10 - F1: 0.6410
2026-02-14 06:31:33 - INFO - Best F1:0.6410 - Best Epoch:17
2026-02-14 06:31:35 - INFO - Starting co-training
2026-02-14 06:32:07 - INFO - Time taken for Epoch 1: 32.50s - F1: 0.43786912
2026-02-14 06:32:41 - INFO - Time taken for Epoch 2: 33.52s - F1: 0.56725752
2026-02-14 06:33:22 - INFO - Time taken for Epoch 3: 40.85s - F1: 0.58376080
2026-02-14 06:33:59 - INFO - Time taken for Epoch 4: 36.86s - F1: 0.60888947
2026-02-14 06:34:35 - INFO - Time taken for Epoch 5: 36.85s - F1: 0.60789438
2026-02-14 06:35:08 - INFO - Time taken for Epoch 6: 32.15s - F1: 0.61822493
2026-02-14 06:35:41 - INFO - Time taken for Epoch 7: 33.67s - F1: 0.63408315
2026-02-14 06:36:25 - INFO - Time taken for Epoch 8: 43.32s - F1: 0.65217175
2026-02-14 06:37:05 - INFO - Time taken for Epoch 9: 40.06s - F1: 0.65038699
2026-02-14 06:37:37 - INFO - Time taken for Epoch 10: 32.15s - F1: 0.64126365
2026-02-14 06:38:09 - INFO - Time taken for Epoch 11: 32.54s - F1: 0.65390088
2026-02-14 06:38:42 - INFO - Time taken for Epoch 12: 33.04s - F1: 0.64679540
2026-02-14 06:39:15 - INFO - Time taken for Epoch 13: 32.23s - F1: 0.65345747
2026-02-14 06:39:47 - INFO - Time taken for Epoch 14: 32.12s - F1: 0.65084240
2026-02-14 06:40:19 - INFO - Time taken for Epoch 15: 32.11s - F1: 0.64008864
2026-02-14 06:40:51 - INFO - Time taken for Epoch 16: 32.60s - F1: 0.66722628
2026-02-14 06:41:25 - INFO - Time taken for Epoch 17: 34.07s - F1: 0.64779777
2026-02-14 06:41:28 - INFO - Fine-tuning models
2026-02-14 06:41:34 - INFO - Time taken for Epoch 1:5.89 - F1: 0.6540
2026-02-14 06:41:41 - INFO - Time taken for Epoch 2:6.84 - F1: 0.6854
2026-02-14 06:41:48 - INFO - Time taken for Epoch 3:6.99 - F1: 0.6680
2026-02-14 06:41:54 - INFO - Time taken for Epoch 4:5.83 - F1: 0.6595
2026-02-14 06:41:59 - INFO - Time taken for Epoch 5:5.84 - F1: 0.6627
2026-02-14 06:42:05 - INFO - Time taken for Epoch 6:5.84 - F1: 0.6630
2026-02-14 06:42:11 - INFO - Time taken for Epoch 7:5.84 - F1: 0.6608
2026-02-14 06:42:17 - INFO - Time taken for Epoch 8:5.84 - F1: 0.6999
2026-02-14 06:42:24 - INFO - Time taken for Epoch 9:7.02 - F1: 0.6888
2026-02-14 06:42:30 - INFO - Time taken for Epoch 10:5.97 - F1: 0.6714
2026-02-14 06:42:36 - INFO - Time taken for Epoch 11:5.91 - F1: 0.6762
2026-02-14 06:42:42 - INFO - Time taken for Epoch 12:5.95 - F1: 0.6834
2026-02-14 06:42:48 - INFO - Time taken for Epoch 13:5.98 - F1: 0.6790
2026-02-14 06:42:54 - INFO - Time taken for Epoch 14:5.97 - F1: 0.6820
2026-02-14 06:43:00 - INFO - Time taken for Epoch 15:5.94 - F1: 0.6907
2026-02-14 06:43:06 - INFO - Time taken for Epoch 16:5.96 - F1: 0.6941
2026-02-14 06:43:12 - INFO - Time taken for Epoch 17:5.89 - F1: 0.6873
2026-02-14 06:43:17 - INFO - Time taken for Epoch 18:5.88 - F1: 0.6880
2026-02-14 06:43:17 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 06:43:17 - INFO - Best F1:0.6999 - Best Epoch:7
2026-02-14 06:43:25 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6847, Test ECE: 0.0426
2026-02-14 06:43:25 - INFO - All results: {'f1_macro': 0.6847170754710359, 'ece': np.float64(0.04257998108191417)}
2026-02-14 06:43:25 - INFO - 
Total time taken: 1115.74 seconds
2026-02-14 06:43:25 - INFO - Trial 2 finished with value: 0.6847170754710359 and parameters: {'learning_rate': 2.9578528648397695e-05, 'weight_decay': 6.227982089651509e-05, 'batch_size': 16, 'co_train_epochs': 17, 'epoch_patience': 9}. Best is trial 2 with value: 0.6847170754710359.
2026-02-14 06:43:25 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 06:43:25 - INFO - Devices: cuda:1, cuda:1
2026-02-14 06:43:25 - INFO - Starting log
2026-02-14 06:43:25 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 06:43:26 - INFO - Learning Rate: 2.1182757941987233e-05
Weight Decay: 0.0005049187902768126
Batch Size: 8
No. Epochs: 15
Epoch Patience: 8
 Accumulation Steps: 8
2026-02-14 06:43:27 - INFO - Generating initial weights
2026-02-14 06:43:59 - INFO - Time taken for Epoch 1:29.82 - F1: 0.0385
2026-02-14 06:44:30 - INFO - Time taken for Epoch 2:30.51 - F1: 0.0407
2026-02-14 06:44:59 - INFO - Time taken for Epoch 3:29.23 - F1: 0.0785
2026-02-14 06:45:28 - INFO - Time taken for Epoch 4:29.17 - F1: 0.1762
2026-02-14 06:45:58 - INFO - Time taken for Epoch 5:29.85 - F1: 0.3235
2026-02-14 06:46:28 - INFO - Time taken for Epoch 6:30.20 - F1: 0.3372
2026-02-14 06:46:58 - INFO - Time taken for Epoch 7:29.47 - F1: 0.3723
2026-02-14 06:47:27 - INFO - Time taken for Epoch 8:29.60 - F1: 0.4408
2026-02-14 06:47:57 - INFO - Time taken for Epoch 9:29.87 - F1: 0.4738
2026-02-14 06:48:27 - INFO - Time taken for Epoch 10:30.20 - F1: 0.4718
2026-02-14 06:48:57 - INFO - Time taken for Epoch 11:30.16 - F1: 0.5187
2026-02-14 06:49:27 - INFO - Time taken for Epoch 12:29.54 - F1: 0.5283
2026-02-14 06:49:57 - INFO - Time taken for Epoch 13:29.95 - F1: 0.5549
2026-02-14 06:50:27 - INFO - Time taken for Epoch 14:29.85 - F1: 0.5725
2026-02-14 06:50:57 - INFO - Time taken for Epoch 15:30.26 - F1: 0.5658
2026-02-14 06:50:57 - INFO - Best F1:0.5725 - Best Epoch:14
2026-02-14 06:50:58 - INFO - Starting co-training
2026-02-14 06:51:34 - INFO - Time taken for Epoch 1: 35.24s - F1: 0.28483450
2026-02-14 06:52:10 - INFO - Time taken for Epoch 2: 35.78s - F1: 0.49676416
2026-02-14 06:52:49 - INFO - Time taken for Epoch 3: 39.81s - F1: 0.57771255
2026-02-14 06:53:31 - INFO - Time taken for Epoch 4: 41.09s - F1: 0.58405751
2026-02-14 06:54:10 - INFO - Time taken for Epoch 5: 39.58s - F1: 0.59553448
2026-02-14 06:54:51 - INFO - Time taken for Epoch 6: 40.56s - F1: 0.59323519
2026-02-14 06:55:25 - INFO - Time taken for Epoch 7: 34.13s - F1: 0.61678400
2026-02-14 06:56:01 - INFO - Time taken for Epoch 8: 35.96s - F1: 0.62908755
2026-02-14 06:56:41 - INFO - Time taken for Epoch 9: 39.73s - F1: 0.62219315
2026-02-14 06:57:15 - INFO - Time taken for Epoch 10: 34.64s - F1: 0.62598850
2026-02-14 06:57:50 - INFO - Time taken for Epoch 11: 34.68s - F1: 0.63803210
2026-02-14 06:58:25 - INFO - Time taken for Epoch 12: 35.26s - F1: 0.62403585
2026-02-14 06:58:59 - INFO - Time taken for Epoch 13: 33.89s - F1: 0.61794471
2026-02-14 06:59:32 - INFO - Time taken for Epoch 14: 33.38s - F1: 0.63279284
2026-02-14 07:00:06 - INFO - Time taken for Epoch 15: 33.86s - F1: 0.62952744
2026-02-14 07:00:09 - INFO - Fine-tuning models
2026-02-14 07:00:17 - INFO - Time taken for Epoch 1:7.66 - F1: 0.6353
2026-02-14 07:00:25 - INFO - Time taken for Epoch 2:8.65 - F1: 0.6460
2026-02-14 07:00:34 - INFO - Time taken for Epoch 3:8.72 - F1: 0.6670
2026-02-14 07:00:43 - INFO - Time taken for Epoch 4:8.60 - F1: 0.6535
2026-02-14 07:00:50 - INFO - Time taken for Epoch 5:7.45 - F1: 0.6522
2026-02-14 07:00:58 - INFO - Time taken for Epoch 6:7.54 - F1: 0.6499
2026-02-14 07:01:05 - INFO - Time taken for Epoch 7:7.67 - F1: 0.6580
2026-02-14 07:01:13 - INFO - Time taken for Epoch 8:7.58 - F1: 0.6604
2026-02-14 07:01:20 - INFO - Time taken for Epoch 9:7.69 - F1: 0.6686
2026-02-14 07:01:29 - INFO - Time taken for Epoch 10:8.58 - F1: 0.6658
2026-02-14 07:01:37 - INFO - Time taken for Epoch 11:7.54 - F1: 0.6625
2026-02-14 07:01:44 - INFO - Time taken for Epoch 12:7.61 - F1: 0.6685
2026-02-14 07:01:52 - INFO - Time taken for Epoch 13:7.52 - F1: 0.6712
2026-02-14 07:02:01 - INFO - Time taken for Epoch 14:8.92 - F1: 0.6680
2026-02-14 07:02:08 - INFO - Time taken for Epoch 15:7.62 - F1: 0.6660
2026-02-14 07:02:16 - INFO - Time taken for Epoch 16:7.57 - F1: 0.6643
2026-02-14 07:02:23 - INFO - Time taken for Epoch 17:7.60 - F1: 0.6837
2026-02-14 07:02:32 - INFO - Time taken for Epoch 18:8.79 - F1: 0.6692
2026-02-14 07:02:40 - INFO - Time taken for Epoch 19:7.55 - F1: 0.6786
2026-02-14 07:02:47 - INFO - Time taken for Epoch 20:7.63 - F1: 0.6856
2026-02-14 07:02:56 - INFO - Time taken for Epoch 21:8.78 - F1: 0.6938
2026-02-14 07:03:12 - INFO - Time taken for Epoch 22:15.75 - F1: 0.6786
2026-02-14 07:03:19 - INFO - Time taken for Epoch 23:7.40 - F1: 0.6761
2026-02-14 07:03:27 - INFO - Time taken for Epoch 24:7.41 - F1: 0.6863
2026-02-14 07:03:34 - INFO - Time taken for Epoch 25:7.40 - F1: 0.6880
2026-02-14 07:03:42 - INFO - Time taken for Epoch 26:7.47 - F1: 0.6930
2026-02-14 07:03:49 - INFO - Time taken for Epoch 27:7.39 - F1: 0.6941
2026-02-14 07:03:58 - INFO - Time taken for Epoch 28:8.73 - F1: 0.6867
2026-02-14 07:04:05 - INFO - Time taken for Epoch 29:7.38 - F1: 0.6835
2026-02-14 07:04:12 - INFO - Time taken for Epoch 30:7.40 - F1: 0.6838
2026-02-14 07:04:20 - INFO - Time taken for Epoch 31:7.42 - F1: 0.6787
2026-02-14 07:04:27 - INFO - Time taken for Epoch 32:7.43 - F1: 0.6802
2026-02-14 07:04:35 - INFO - Time taken for Epoch 33:7.42 - F1: 0.6866
2026-02-14 07:04:42 - INFO - Time taken for Epoch 34:7.45 - F1: 0.6844
2026-02-14 07:04:50 - INFO - Time taken for Epoch 35:7.62 - F1: 0.6874
2026-02-14 07:04:57 - INFO - Time taken for Epoch 36:7.61 - F1: 0.6848
2026-02-14 07:05:05 - INFO - Time taken for Epoch 37:7.59 - F1: 0.6822
2026-02-14 07:05:05 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 07:05:05 - INFO - Best F1:0.6941 - Best Epoch:26
2026-02-14 07:05:16 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6820, Test ECE: 0.0345
2026-02-14 07:05:16 - INFO - All results: {'f1_macro': 0.6820053911257578, 'ece': np.float64(0.03445895903538927)}
2026-02-14 07:05:16 - INFO - 
Total time taken: 1310.20 seconds
2026-02-14 07:05:16 - INFO - Trial 3 finished with value: 0.6820053911257578 and parameters: {'learning_rate': 2.1182757941987233e-05, 'weight_decay': 0.0005049187902768126, 'batch_size': 8, 'co_train_epochs': 15, 'epoch_patience': 8}. Best is trial 2 with value: 0.6847170754710359.
2026-02-14 07:05:16 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 07:05:16 - INFO - Devices: cuda:1, cuda:1
2026-02-14 07:05:16 - INFO - Starting log
2026-02-14 07:05:16 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 07:05:16 - INFO - Learning Rate: 4.776882501356624e-05
Weight Decay: 0.0003781448005293796
Batch Size: 8
No. Epochs: 13
Epoch Patience: 10
 Accumulation Steps: 8
2026-02-14 07:05:18 - INFO - Generating initial weights
2026-02-14 07:05:50 - INFO - Time taken for Epoch 1:29.47 - F1: 0.0385
2026-02-14 07:06:19 - INFO - Time taken for Epoch 2:29.82 - F1: 0.0735
2026-02-14 07:06:49 - INFO - Time taken for Epoch 3:29.26 - F1: 0.1708
2026-02-14 07:07:17 - INFO - Time taken for Epoch 4:28.60 - F1: 0.3431
2026-02-14 07:07:47 - INFO - Time taken for Epoch 5:29.27 - F1: 0.4178
2026-02-14 07:08:16 - INFO - Time taken for Epoch 6:29.08 - F1: 0.4460
2026-02-14 07:08:45 - INFO - Time taken for Epoch 7:28.97 - F1: 0.5063
2026-02-14 07:09:15 - INFO - Time taken for Epoch 8:29.92 - F1: 0.5298
2026-02-14 07:09:44 - INFO - Time taken for Epoch 9:29.47 - F1: 0.5922
2026-02-14 07:10:14 - INFO - Time taken for Epoch 10:29.51 - F1: 0.5513
2026-02-14 07:10:44 - INFO - Time taken for Epoch 11:30.22 - F1: 0.6113
2026-02-14 07:11:13 - INFO - Time taken for Epoch 12:29.14 - F1: 0.5947
2026-02-14 07:11:43 - INFO - Time taken for Epoch 13:29.85 - F1: 0.6117
2026-02-14 07:11:43 - INFO - Best F1:0.6117 - Best Epoch:13
2026-02-14 07:11:44 - INFO - Starting co-training
2026-02-14 07:12:19 - INFO - Time taken for Epoch 1: 34.53s - F1: 0.40261829
2026-02-14 07:12:55 - INFO - Time taken for Epoch 2: 35.88s - F1: 0.56217743
2026-02-14 07:13:34 - INFO - Time taken for Epoch 3: 38.77s - F1: 0.57352075
2026-02-14 07:14:16 - INFO - Time taken for Epoch 4: 42.32s - F1: 0.59091593
2026-02-14 07:15:00 - INFO - Time taken for Epoch 5: 44.05s - F1: 0.60148092
2026-02-14 07:15:41 - INFO - Time taken for Epoch 6: 41.15s - F1: 0.60102794
2026-02-14 07:16:15 - INFO - Time taken for Epoch 7: 33.81s - F1: 0.64542865
2026-02-14 07:16:51 - INFO - Time taken for Epoch 8: 35.88s - F1: 0.65162394
2026-02-14 07:17:29 - INFO - Time taken for Epoch 9: 38.56s - F1: 0.61151311
2026-02-14 07:18:03 - INFO - Time taken for Epoch 10: 33.56s - F1: 0.63686853
2026-02-14 07:18:37 - INFO - Time taken for Epoch 11: 33.85s - F1: 0.63086919
2026-02-14 07:19:12 - INFO - Time taken for Epoch 12: 34.83s - F1: 0.63773583
2026-02-14 07:19:46 - INFO - Time taken for Epoch 13: 34.69s - F1: 0.64582358
2026-02-14 07:19:49 - INFO - Fine-tuning models
2026-02-14 07:19:57 - INFO - Time taken for Epoch 1:7.91 - F1: 0.6356
2026-02-14 07:20:06 - INFO - Time taken for Epoch 2:8.86 - F1: 0.6378
2026-02-14 07:20:15 - INFO - Time taken for Epoch 3:8.88 - F1: 0.6341
2026-02-14 07:20:22 - INFO - Time taken for Epoch 4:7.80 - F1: 0.6423
2026-02-14 07:20:31 - INFO - Time taken for Epoch 5:9.01 - F1: 0.6507
2026-02-14 07:20:46 - INFO - Time taken for Epoch 6:14.19 - F1: 0.6628
2026-02-14 07:20:55 - INFO - Time taken for Epoch 7:8.93 - F1: 0.6604
2026-02-14 07:21:02 - INFO - Time taken for Epoch 8:7.82 - F1: 0.6653
2026-02-14 07:21:11 - INFO - Time taken for Epoch 9:8.73 - F1: 0.6881
2026-02-14 07:21:21 - INFO - Time taken for Epoch 10:9.96 - F1: 0.6979
2026-02-14 07:21:30 - INFO - Time taken for Epoch 11:8.77 - F1: 0.6743
2026-02-14 07:21:37 - INFO - Time taken for Epoch 12:7.63 - F1: 0.6855
2026-02-14 07:21:45 - INFO - Time taken for Epoch 13:7.63 - F1: 0.6798
2026-02-14 07:21:53 - INFO - Time taken for Epoch 14:7.62 - F1: 0.6767
2026-02-14 07:22:00 - INFO - Time taken for Epoch 15:7.48 - F1: 0.6947
2026-02-14 07:22:08 - INFO - Time taken for Epoch 16:7.49 - F1: 0.6979
2026-02-14 07:22:15 - INFO - Time taken for Epoch 17:7.45 - F1: 0.6968
2026-02-14 07:22:22 - INFO - Time taken for Epoch 18:7.37 - F1: 0.6950
2026-02-14 07:22:30 - INFO - Time taken for Epoch 19:7.40 - F1: 0.6963
2026-02-14 07:22:37 - INFO - Time taken for Epoch 20:7.43 - F1: 0.6960
2026-02-14 07:22:37 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 07:22:37 - INFO - Best F1:0.6979 - Best Epoch:9
2026-02-14 07:22:47 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6564, Test ECE: 0.0450
2026-02-14 07:22:47 - INFO - All results: {'f1_macro': 0.6563775347163108, 'ece': np.float64(0.044987000398920195)}
2026-02-14 07:22:47 - INFO - 
Total time taken: 1050.96 seconds
2026-02-14 07:22:47 - INFO - Trial 4 finished with value: 0.6563775347163108 and parameters: {'learning_rate': 4.776882501356624e-05, 'weight_decay': 0.0003781448005293796, 'batch_size': 8, 'co_train_epochs': 13, 'epoch_patience': 10}. Best is trial 2 with value: 0.6847170754710359.
2026-02-14 07:22:47 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 07:22:47 - INFO - Devices: cuda:1, cuda:1
2026-02-14 07:22:47 - INFO - Starting log
2026-02-14 07:22:47 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 07:22:47 - INFO - Learning Rate: 9.411635304983026e-05
Weight Decay: 2.1014676912595488e-05
Batch Size: 8
No. Epochs: 8
Epoch Patience: 5
 Accumulation Steps: 8
2026-02-14 07:22:48 - INFO - Generating initial weights
2026-02-14 07:23:21 - INFO - Time taken for Epoch 1:30.06 - F1: 0.0419
2026-02-14 07:23:51 - INFO - Time taken for Epoch 2:30.18 - F1: 0.0994
2026-02-14 07:24:21 - INFO - Time taken for Epoch 3:30.16 - F1: 0.1875
2026-02-14 07:24:51 - INFO - Time taken for Epoch 4:30.19 - F1: 0.3138
2026-02-14 07:25:22 - INFO - Time taken for Epoch 5:30.18 - F1: 0.3629
2026-02-14 07:25:51 - INFO - Time taken for Epoch 6:29.78 - F1: 0.4436
2026-02-14 07:26:21 - INFO - Time taken for Epoch 7:29.90 - F1: 0.5483
2026-02-14 07:26:51 - INFO - Time taken for Epoch 8:30.09 - F1: 0.5826
2026-02-14 07:26:51 - INFO - Best F1:0.5826 - Best Epoch:8
2026-02-14 07:26:53 - INFO - Starting co-training
2026-02-14 07:27:27 - INFO - Time taken for Epoch 1: 34.45s - F1: 0.37873168
2026-02-14 07:28:03 - INFO - Time taken for Epoch 2: 35.72s - F1: 0.55418760
2026-02-14 07:28:44 - INFO - Time taken for Epoch 3: 40.92s - F1: 0.58671656
2026-02-14 07:29:24 - INFO - Time taken for Epoch 4: 39.65s - F1: 0.56676838
2026-02-14 07:29:59 - INFO - Time taken for Epoch 5: 34.91s - F1: 0.58215230
2026-02-14 07:30:34 - INFO - Time taken for Epoch 6: 35.39s - F1: 0.60437134
2026-02-14 07:31:11 - INFO - Time taken for Epoch 7: 36.95s - F1: 0.58524249
2026-02-14 07:31:46 - INFO - Time taken for Epoch 8: 34.71s - F1: 0.60548031
2026-02-14 07:31:49 - INFO - Fine-tuning models
2026-02-14 07:31:57 - INFO - Time taken for Epoch 1:7.82 - F1: 0.5756
2026-02-14 07:32:06 - INFO - Time taken for Epoch 2:8.85 - F1: 0.6146
2026-02-14 07:32:15 - INFO - Time taken for Epoch 3:8.93 - F1: 0.5391
2026-02-14 07:32:23 - INFO - Time taken for Epoch 4:7.79 - F1: 0.6051
2026-02-14 07:32:31 - INFO - Time taken for Epoch 5:7.80 - F1: 0.6064
2026-02-14 07:32:38 - INFO - Time taken for Epoch 6:7.54 - F1: 0.6142
2026-02-14 07:32:46 - INFO - Time taken for Epoch 7:7.62 - F1: 0.6205
2026-02-14 07:32:55 - INFO - Time taken for Epoch 8:8.81 - F1: 0.6344
2026-02-14 07:33:04 - INFO - Time taken for Epoch 9:8.91 - F1: 0.6288
2026-02-14 07:33:11 - INFO - Time taken for Epoch 10:7.66 - F1: 0.6404
2026-02-14 07:33:20 - INFO - Time taken for Epoch 11:8.79 - F1: 0.6365
2026-02-14 07:33:28 - INFO - Time taken for Epoch 12:7.71 - F1: 0.6292
2026-02-14 07:33:36 - INFO - Time taken for Epoch 13:7.79 - F1: 0.6412
2026-02-14 07:33:44 - INFO - Time taken for Epoch 14:8.93 - F1: 0.6396
2026-02-14 07:33:52 - INFO - Time taken for Epoch 15:7.68 - F1: 0.6344
2026-02-14 07:34:00 - INFO - Time taken for Epoch 16:7.85 - F1: 0.6302
2026-02-14 07:34:08 - INFO - Time taken for Epoch 17:7.74 - F1: 0.6265
2026-02-14 07:34:15 - INFO - Time taken for Epoch 18:7.74 - F1: 0.6266
2026-02-14 07:34:23 - INFO - Time taken for Epoch 19:7.77 - F1: 0.6388
2026-02-14 07:34:31 - INFO - Time taken for Epoch 20:7.80 - F1: 0.6291
2026-02-14 07:34:39 - INFO - Time taken for Epoch 21:7.66 - F1: 0.6220
2026-02-14 07:34:46 - INFO - Time taken for Epoch 22:7.75 - F1: 0.6256
2026-02-14 07:34:54 - INFO - Time taken for Epoch 23:7.69 - F1: 0.6428
2026-02-14 07:35:03 - INFO - Time taken for Epoch 24:8.90 - F1: 0.6488
2026-02-14 07:35:12 - INFO - Time taken for Epoch 25:8.91 - F1: 0.6532
2026-02-14 07:35:21 - INFO - Time taken for Epoch 26:8.83 - F1: 0.6426
2026-02-14 07:35:28 - INFO - Time taken for Epoch 27:7.61 - F1: 0.6357
2026-02-14 07:35:36 - INFO - Time taken for Epoch 28:7.62 - F1: 0.6406
2026-02-14 07:35:44 - INFO - Time taken for Epoch 29:7.79 - F1: 0.6374
2026-02-14 07:35:51 - INFO - Time taken for Epoch 30:7.57 - F1: 0.6364
2026-02-14 07:35:59 - INFO - Time taken for Epoch 31:7.61 - F1: 0.6362
2026-02-14 07:36:07 - INFO - Time taken for Epoch 32:7.74 - F1: 0.6447
2026-02-14 07:36:14 - INFO - Time taken for Epoch 33:7.71 - F1: 0.6338
2026-02-14 07:36:22 - INFO - Time taken for Epoch 34:7.66 - F1: 0.6398
2026-02-14 07:36:30 - INFO - Time taken for Epoch 35:7.65 - F1: 0.6364
2026-02-14 07:36:30 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 07:36:30 - INFO - Best F1:0.6532 - Best Epoch:24
2026-02-14 07:36:39 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6324, Test ECE: 0.0871
2026-02-14 07:36:39 - INFO - All results: {'f1_macro': 0.6323943355457451, 'ece': np.float64(0.08705150720863743)}
2026-02-14 07:36:39 - INFO - 
Total time taken: 832.54 seconds
2026-02-14 07:36:39 - INFO - Trial 5 finished with value: 0.6323943355457451 and parameters: {'learning_rate': 9.411635304983026e-05, 'weight_decay': 2.1014676912595488e-05, 'batch_size': 8, 'co_train_epochs': 8, 'epoch_patience': 5}. Best is trial 2 with value: 0.6847170754710359.
2026-02-14 07:36:39 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 07:36:39 - INFO - Devices: cuda:1, cuda:1
2026-02-14 07:36:39 - INFO - Starting log
2026-02-14 07:36:39 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 07:36:40 - INFO - Learning Rate: 0.00020392515684661172
Weight Decay: 1.0599492711686551e-05
Batch Size: 64
No. Epochs: 10
Epoch Patience: 8
 Accumulation Steps: 1
2026-02-14 07:36:41 - INFO - Generating initial weights
2026-02-14 07:37:02 - INFO - Time taken for Epoch 1:18.68 - F1: 0.0321
2026-02-14 07:37:20 - INFO - Time taken for Epoch 2:18.52 - F1: 0.0328
2026-02-14 07:37:39 - INFO - Time taken for Epoch 3:18.44 - F1: 0.0482
2026-02-14 07:37:57 - INFO - Time taken for Epoch 4:18.37 - F1: 0.0100
2026-02-14 07:38:16 - INFO - Time taken for Epoch 5:18.51 - F1: 0.0413
2026-02-14 07:38:34 - INFO - Time taken for Epoch 6:18.47 - F1: 0.0100
2026-02-14 07:38:53 - INFO - Time taken for Epoch 7:18.39 - F1: 0.0135
2026-02-14 07:39:11 - INFO - Time taken for Epoch 8:18.37 - F1: 0.0390
2026-02-14 07:39:29 - INFO - Time taken for Epoch 9:18.33 - F1: 0.0418
2026-02-14 07:39:48 - INFO - Time taken for Epoch 10:18.43 - F1: 0.0403
2026-02-14 07:39:48 - INFO - Best F1:0.0482 - Best Epoch:3
2026-02-14 07:39:49 - INFO - Starting co-training
2026-02-14 07:40:33 - INFO - Time taken for Epoch 1: 43.84s - F1: 0.58317764
2026-02-14 07:41:18 - INFO - Time taken for Epoch 2: 45.02s - F1: 0.58734119
2026-02-14 07:42:03 - INFO - Time taken for Epoch 3: 44.86s - F1: 0.61075013
2026-02-14 07:42:48 - INFO - Time taken for Epoch 4: 45.01s - F1: 0.60410991
2026-02-14 07:43:32 - INFO - Time taken for Epoch 5: 43.81s - F1: 0.61607117
2026-02-14 07:44:17 - INFO - Time taken for Epoch 6: 44.60s - F1: 0.63530803
2026-02-14 07:45:01 - INFO - Time taken for Epoch 7: 44.10s - F1: 0.60656242
2026-02-14 07:45:44 - INFO - Time taken for Epoch 8: 43.10s - F1: 0.61637307
2026-02-14 07:46:27 - INFO - Time taken for Epoch 9: 43.10s - F1: 0.58622813
2026-02-14 07:47:11 - INFO - Time taken for Epoch 10: 43.82s - F1: 0.59390693
2026-02-14 07:47:13 - INFO - Fine-tuning models
2026-02-14 07:47:18 - INFO - Time taken for Epoch 1:4.73 - F1: 0.6275
2026-02-14 07:47:24 - INFO - Time taken for Epoch 2:5.69 - F1: 0.6056
2026-02-14 07:47:28 - INFO - Time taken for Epoch 3:4.61 - F1: 0.6191
2026-02-14 07:47:33 - INFO - Time taken for Epoch 4:4.65 - F1: 0.6175
2026-02-14 07:47:38 - INFO - Time taken for Epoch 5:4.59 - F1: 0.6097
2026-02-14 07:47:42 - INFO - Time taken for Epoch 6:4.57 - F1: 0.6016
2026-02-14 07:47:47 - INFO - Time taken for Epoch 7:4.57 - F1: 0.6192
2026-02-14 07:47:51 - INFO - Time taken for Epoch 8:4.58 - F1: 0.6643
2026-02-14 07:48:01 - INFO - Time taken for Epoch 9:9.96 - F1: 0.6728
2026-02-14 07:48:07 - INFO - Time taken for Epoch 10:5.74 - F1: 0.6356
2026-02-14 07:48:12 - INFO - Time taken for Epoch 11:4.62 - F1: 0.6407
2026-02-14 07:48:16 - INFO - Time taken for Epoch 12:4.61 - F1: 0.6162
2026-02-14 07:48:21 - INFO - Time taken for Epoch 13:4.62 - F1: 0.6314
2026-02-14 07:48:26 - INFO - Time taken for Epoch 14:4.57 - F1: 0.6600
2026-02-14 07:48:30 - INFO - Time taken for Epoch 15:4.55 - F1: 0.6873
2026-02-14 07:48:37 - INFO - Time taken for Epoch 16:6.98 - F1: 0.6895
2026-02-14 07:48:43 - INFO - Time taken for Epoch 17:5.71 - F1: 0.6944
2026-02-14 07:48:49 - INFO - Time taken for Epoch 18:5.84 - F1: 0.6865
2026-02-14 07:48:53 - INFO - Time taken for Epoch 19:4.55 - F1: 0.6732
2026-02-14 07:48:58 - INFO - Time taken for Epoch 20:4.55 - F1: 0.6774
2026-02-14 07:49:02 - INFO - Time taken for Epoch 21:4.54 - F1: 0.6680
2026-02-14 07:49:07 - INFO - Time taken for Epoch 22:4.58 - F1: 0.6711
2026-02-14 07:49:11 - INFO - Time taken for Epoch 23:4.63 - F1: 0.6837
2026-02-14 07:49:16 - INFO - Time taken for Epoch 24:4.61 - F1: 0.6759
2026-02-14 07:49:21 - INFO - Time taken for Epoch 25:4.60 - F1: 0.6675
2026-02-14 07:49:25 - INFO - Time taken for Epoch 26:4.61 - F1: 0.6602
2026-02-14 07:49:30 - INFO - Time taken for Epoch 27:4.62 - F1: 0.6574
2026-02-14 07:49:30 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 07:49:30 - INFO - Best F1:0.6944 - Best Epoch:16
2026-02-14 07:49:37 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6747, Test ECE: 0.0702
2026-02-14 07:49:37 - INFO - All results: {'f1_macro': 0.6747320927051214, 'ece': np.float64(0.07018851695956001)}
2026-02-14 07:49:37 - INFO - 
Total time taken: 777.67 seconds
2026-02-14 07:49:37 - INFO - Trial 6 finished with value: 0.6747320927051214 and parameters: {'learning_rate': 0.00020392515684661172, 'weight_decay': 1.0599492711686551e-05, 'batch_size': 64, 'co_train_epochs': 10, 'epoch_patience': 8}. Best is trial 2 with value: 0.6847170754710359.
2026-02-14 07:49:37 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 07:49:37 - INFO - Devices: cuda:1, cuda:1
2026-02-14 07:49:37 - INFO - Starting log
2026-02-14 07:49:37 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 07:49:37 - INFO - Learning Rate: 4.162638478953669e-05
Weight Decay: 2.1311967340062503e-05
Batch Size: 32
No. Epochs: 19
Epoch Patience: 8
 Accumulation Steps: 2
2026-02-14 07:49:39 - INFO - Generating initial weights
2026-02-14 07:50:01 - INFO - Time taken for Epoch 1:20.62 - F1: 0.0387
2026-02-14 07:50:22 - INFO - Time taken for Epoch 2:20.21 - F1: 0.0691
2026-02-14 07:50:42 - INFO - Time taken for Epoch 3:20.47 - F1: 0.1524
2026-02-14 07:51:03 - INFO - Time taken for Epoch 4:20.35 - F1: 0.3428
2026-02-14 07:51:23 - INFO - Time taken for Epoch 5:20.20 - F1: 0.3885
2026-02-14 07:51:43 - INFO - Time taken for Epoch 6:20.31 - F1: 0.4546
2026-02-14 07:52:03 - INFO - Time taken for Epoch 7:20.27 - F1: 0.4717
2026-02-14 07:52:23 - INFO - Time taken for Epoch 8:20.04 - F1: 0.5002
2026-02-14 07:52:44 - INFO - Time taken for Epoch 9:20.44 - F1: 0.5335
2026-02-14 07:53:04 - INFO - Time taken for Epoch 10:20.55 - F1: 0.5437
2026-02-14 07:53:25 - INFO - Time taken for Epoch 11:20.46 - F1: 0.5905
2026-02-14 07:53:45 - INFO - Time taken for Epoch 12:20.38 - F1: 0.5795
2026-02-14 07:54:06 - INFO - Time taken for Epoch 13:20.45 - F1: 0.5920
2026-02-14 07:54:26 - INFO - Time taken for Epoch 14:20.40 - F1: 0.6105
2026-02-14 07:54:47 - INFO - Time taken for Epoch 15:20.63 - F1: 0.5920
2026-02-14 07:55:07 - INFO - Time taken for Epoch 16:20.24 - F1: 0.6027
2026-02-14 07:55:27 - INFO - Time taken for Epoch 17:20.19 - F1: 0.5957
2026-02-14 07:55:47 - INFO - Time taken for Epoch 18:20.14 - F1: 0.6054
2026-02-14 07:56:07 - INFO - Time taken for Epoch 19:20.30 - F1: 0.6143
2026-02-14 07:56:08 - INFO - Best F1:0.6143 - Best Epoch:19
2026-02-14 07:56:09 - INFO - Starting co-training
2026-02-14 07:56:44 - INFO - Time taken for Epoch 1: 34.99s - F1: 0.55832323
2026-02-14 07:57:20 - INFO - Time taken for Epoch 2: 36.20s - F1: 0.58763557
2026-02-14 07:58:00 - INFO - Time taken for Epoch 3: 39.61s - F1: 0.63057341
2026-02-14 07:58:43 - INFO - Time taken for Epoch 4: 42.74s - F1: 0.62206538
2026-02-14 07:59:19 - INFO - Time taken for Epoch 5: 36.24s - F1: 0.63599047
2026-02-14 07:59:56 - INFO - Time taken for Epoch 6: 37.20s - F1: 0.63012522
2026-02-14 08:00:32 - INFO - Time taken for Epoch 7: 35.98s - F1: 0.63793149
2026-02-14 08:01:09 - INFO - Time taken for Epoch 8: 37.10s - F1: 0.63997647
2026-02-14 08:01:49 - INFO - Time taken for Epoch 9: 39.62s - F1: 0.63809472
2026-02-14 08:02:25 - INFO - Time taken for Epoch 10: 35.67s - F1: 0.64468478
2026-02-14 08:03:01 - INFO - Time taken for Epoch 11: 36.58s - F1: 0.64962799
2026-02-14 08:03:41 - INFO - Time taken for Epoch 12: 40.40s - F1: 0.66380630
2026-02-14 08:04:23 - INFO - Time taken for Epoch 13: 41.75s - F1: 0.66459040
2026-02-14 08:05:03 - INFO - Time taken for Epoch 14: 39.50s - F1: 0.66256359
2026-02-14 08:05:38 - INFO - Time taken for Epoch 15: 35.42s - F1: 0.66104756
2026-02-14 08:06:14 - INFO - Time taken for Epoch 16: 35.68s - F1: 0.68923858
2026-02-14 08:06:51 - INFO - Time taken for Epoch 17: 37.38s - F1: 0.65985030
2026-02-14 08:07:27 - INFO - Time taken for Epoch 18: 35.95s - F1: 0.69768614
2026-02-14 08:08:04 - INFO - Time taken for Epoch 19: 36.85s - F1: 0.66185152
2026-02-14 08:08:07 - INFO - Fine-tuning models
2026-02-14 08:08:12 - INFO - Time taken for Epoch 1:5.25 - F1: 0.6780
2026-02-14 08:08:18 - INFO - Time taken for Epoch 2:6.20 - F1: 0.6693
2026-02-14 08:08:24 - INFO - Time taken for Epoch 3:5.19 - F1: 0.6591
2026-02-14 08:08:29 - INFO - Time taken for Epoch 4:5.22 - F1: 0.6621
2026-02-14 08:08:34 - INFO - Time taken for Epoch 5:5.20 - F1: 0.6559
2026-02-14 08:08:39 - INFO - Time taken for Epoch 6:5.20 - F1: 0.6784
2026-02-14 08:08:46 - INFO - Time taken for Epoch 7:6.29 - F1: 0.6725
2026-02-14 08:08:51 - INFO - Time taken for Epoch 8:5.14 - F1: 0.6832
2026-02-14 08:09:00 - INFO - Time taken for Epoch 9:9.69 - F1: 0.6946
2026-02-14 08:09:07 - INFO - Time taken for Epoch 10:6.34 - F1: 0.6925
2026-02-14 08:09:12 - INFO - Time taken for Epoch 11:5.20 - F1: 0.6836
2026-02-14 08:09:17 - INFO - Time taken for Epoch 12:5.18 - F1: 0.6842
2026-02-14 08:09:22 - INFO - Time taken for Epoch 13:5.18 - F1: 0.6841
2026-02-14 08:09:27 - INFO - Time taken for Epoch 14:5.18 - F1: 0.6924
2026-02-14 08:09:33 - INFO - Time taken for Epoch 15:5.18 - F1: 0.6968
2026-02-14 08:09:41 - INFO - Time taken for Epoch 16:8.64 - F1: 0.6934
2026-02-14 08:09:46 - INFO - Time taken for Epoch 17:5.17 - F1: 0.6910
2026-02-14 08:09:52 - INFO - Time taken for Epoch 18:5.11 - F1: 0.6917
2026-02-14 08:09:57 - INFO - Time taken for Epoch 19:5.13 - F1: 0.6931
2026-02-14 08:10:02 - INFO - Time taken for Epoch 20:5.18 - F1: 0.6852
2026-02-14 08:10:07 - INFO - Time taken for Epoch 21:5.16 - F1: 0.6846
2026-02-14 08:10:12 - INFO - Time taken for Epoch 22:5.15 - F1: 0.6848
2026-02-14 08:10:17 - INFO - Time taken for Epoch 23:5.16 - F1: 0.6831
2026-02-14 08:10:22 - INFO - Time taken for Epoch 24:5.13 - F1: 0.6846
2026-02-14 08:10:28 - INFO - Time taken for Epoch 25:5.11 - F1: 0.6874
2026-02-14 08:10:28 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 08:10:28 - INFO - Best F1:0.6968 - Best Epoch:14
2026-02-14 08:10:35 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.6976, Test ECE: 0.0492
2026-02-14 08:10:35 - INFO - All results: {'f1_macro': 0.6975817063679635, 'ece': np.float64(0.049159450698148616)}
2026-02-14 08:10:35 - INFO - 
Total time taken: 1258.06 seconds
2026-02-14 08:10:35 - INFO - Trial 7 finished with value: 0.6975817063679635 and parameters: {'learning_rate': 4.162638478953669e-05, 'weight_decay': 2.1311967340062503e-05, 'batch_size': 32, 'co_train_epochs': 19, 'epoch_patience': 8}. Best is trial 7 with value: 0.6975817063679635.
2026-02-14 08:10:35 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 08:10:35 - INFO - Devices: cuda:1, cuda:1
2026-02-14 08:10:35 - INFO - Starting log
2026-02-14 08:10:35 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 08:10:35 - INFO - Learning Rate: 0.0002872951777205938
Weight Decay: 4.510941854435667e-05
Batch Size: 64
No. Epochs: 11
Epoch Patience: 9
 Accumulation Steps: 1
2026-02-14 08:10:37 - INFO - Generating initial weights
2026-02-14 08:10:58 - INFO - Time taken for Epoch 1:18.78 - F1: 0.0321
2026-02-14 08:11:16 - INFO - Time taken for Epoch 2:18.55 - F1: 0.0205
2026-02-14 08:11:35 - INFO - Time taken for Epoch 3:18.37 - F1: 0.0155
2026-02-14 08:11:53 - INFO - Time taken for Epoch 4:18.35 - F1: 0.0155
2026-02-14 08:12:11 - INFO - Time taken for Epoch 5:18.43 - F1: 0.0155
2026-02-14 08:12:30 - INFO - Time taken for Epoch 6:18.54 - F1: 0.0155
2026-02-14 08:12:49 - INFO - Time taken for Epoch 7:18.63 - F1: 0.0155
2026-02-14 08:13:07 - INFO - Time taken for Epoch 8:18.47 - F1: 0.0155
2026-02-14 08:13:26 - INFO - Time taken for Epoch 9:18.57 - F1: 0.0155
2026-02-14 08:13:44 - INFO - Time taken for Epoch 10:18.45 - F1: 0.0155
2026-02-14 08:14:03 - INFO - Time taken for Epoch 11:18.52 - F1: 0.0155
2026-02-14 08:14:03 - INFO - Best F1:0.0321 - Best Epoch:1
2026-02-14 08:14:04 - INFO - Starting co-training
2026-02-14 08:14:48 - INFO - Time taken for Epoch 1: 44.12s - F1: 0.03212851
2026-02-14 08:15:33 - INFO - Time taken for Epoch 2: 45.04s - F1: 0.03212851
2026-02-14 08:16:17 - INFO - Time taken for Epoch 3: 43.37s - F1: 0.03212851
2026-02-14 08:17:01 - INFO - Time taken for Epoch 4: 44.08s - F1: 0.03212851
2026-02-14 08:17:45 - INFO - Time taken for Epoch 5: 43.74s - F1: 0.04247539
2026-02-14 08:18:30 - INFO - Time taken for Epoch 6: 45.20s - F1: 0.04247539
2026-02-14 08:19:14 - INFO - Time taken for Epoch 7: 43.85s - F1: 0.04247539
2026-02-14 08:19:57 - INFO - Time taken for Epoch 8: 43.84s - F1: 0.04247539
2026-02-14 08:20:42 - INFO - Time taken for Epoch 9: 44.07s - F1: 0.04247539
2026-02-14 08:21:25 - INFO - Time taken for Epoch 10: 43.99s - F1: 0.04247539
2026-02-14 08:22:09 - INFO - Time taken for Epoch 11: 43.49s - F1: 0.04247539
2026-02-14 08:22:12 - INFO - Fine-tuning models
2026-02-14 08:22:17 - INFO - Time taken for Epoch 1:4.67 - F1: 0.0425
2026-02-14 08:22:22 - INFO - Time taken for Epoch 2:5.56 - F1: 0.0205
2026-02-14 08:22:27 - INFO - Time taken for Epoch 3:4.61 - F1: 0.0205
2026-02-14 08:22:32 - INFO - Time taken for Epoch 4:4.61 - F1: 0.0155
2026-02-14 08:22:36 - INFO - Time taken for Epoch 5:4.60 - F1: 0.0155
2026-02-14 08:22:41 - INFO - Time taken for Epoch 6:4.59 - F1: 0.0155
2026-02-14 08:22:45 - INFO - Time taken for Epoch 7:4.60 - F1: 0.0155
2026-02-14 08:22:50 - INFO - Time taken for Epoch 8:4.61 - F1: 0.0155
2026-02-14 08:22:55 - INFO - Time taken for Epoch 9:4.66 - F1: 0.0155
2026-02-14 08:22:59 - INFO - Time taken for Epoch 10:4.65 - F1: 0.0155
2026-02-14 08:23:04 - INFO - Time taken for Epoch 11:4.67 - F1: 0.0155
2026-02-14 08:23:04 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 08:23:04 - INFO - Best F1:0.0425 - Best Epoch:0
2026-02-14 08:23:11 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.0424, Test ECE: 0.4142
2026-02-14 08:23:11 - INFO - All results: {'f1_macro': 0.042445313631754314, 'ece': np.float64(0.41415250498282147)}
2026-02-14 08:23:11 - INFO - 
Total time taken: 756.45 seconds
2026-02-14 08:23:11 - INFO - Trial 8 finished with value: 0.042445313631754314 and parameters: {'learning_rate': 0.0002872951777205938, 'weight_decay': 4.510941854435667e-05, 'batch_size': 64, 'co_train_epochs': 11, 'epoch_patience': 9}. Best is trial 7 with value: 0.6975817063679635.
2026-02-14 08:23:11 - INFO - Using devices: cuda:1, cuda:1
2026-02-14 08:23:11 - INFO - Devices: cuda:1, cuda:1
2026-02-14 08:23:11 - INFO - Starting log
2026-02-14 08:23:11 - INFO - Dataset: humanitarian9, Event: hurricane_florence_2018, N: 50, Seed: 1234, HF Model: GPT-4o, NumShots: 50, PLM: bert-tweet
2026-02-14 08:23:12 - INFO - Learning Rate: 0.00044068021116376946
Weight Decay: 0.00020159179141193858
Batch Size: 16
No. Epochs: 10
Epoch Patience: 5
 Accumulation Steps: 4
2026-02-14 08:23:13 - INFO - Generating initial weights
2026-02-14 08:23:40 - INFO - Time taken for Epoch 1:23.94 - F1: 0.0205
2026-02-14 08:24:03 - INFO - Time taken for Epoch 2:23.58 - F1: 0.0100
2026-02-14 08:24:27 - INFO - Time taken for Epoch 3:23.33 - F1: 0.0155
2026-02-14 08:24:51 - INFO - Time taken for Epoch 4:23.95 - F1: 0.0155
2026-02-14 08:25:14 - INFO - Time taken for Epoch 5:23.80 - F1: 0.0155
2026-02-14 08:25:38 - INFO - Time taken for Epoch 6:23.86 - F1: 0.0155
2026-02-14 08:26:02 - INFO - Time taken for Epoch 7:23.67 - F1: 0.0155
2026-02-14 08:26:25 - INFO - Time taken for Epoch 8:23.58 - F1: 0.0155
2026-02-14 08:26:49 - INFO - Time taken for Epoch 9:23.81 - F1: 0.0155
2026-02-14 08:27:13 - INFO - Time taken for Epoch 10:23.71 - F1: 0.0155
2026-02-14 08:27:13 - INFO - Best F1:0.0205 - Best Epoch:1
2026-02-14 08:27:15 - INFO - Starting co-training
2026-02-14 08:27:48 - INFO - Time taken for Epoch 1: 33.34s - F1: 0.03212851
2026-02-14 08:28:22 - INFO - Time taken for Epoch 2: 34.04s - F1: 0.03212851
2026-02-14 08:28:55 - INFO - Time taken for Epoch 3: 33.31s - F1: 0.03852235
2026-02-14 08:29:30 - INFO - Time taken for Epoch 4: 34.13s - F1: 0.03212851
2026-02-14 08:30:03 - INFO - Time taken for Epoch 5: 33.31s - F1: 0.03852235
2026-02-14 08:30:35 - INFO - Time taken for Epoch 6: 32.37s - F1: 0.03852235
2026-02-14 08:31:08 - INFO - Time taken for Epoch 7: 32.76s - F1: 0.03852235
2026-02-14 08:31:42 - INFO - Time taken for Epoch 8: 33.47s - F1: 0.03852235
2026-02-14 08:31:42 - INFO - Performance not improving for 5 consecutive epochs.
2026-02-14 08:31:44 - INFO - Fine-tuning models
2026-02-14 08:31:50 - INFO - Time taken for Epoch 1:6.10 - F1: 0.0385
2026-02-14 08:31:57 - INFO - Time taken for Epoch 2:7.09 - F1: 0.0109
2026-02-14 08:32:03 - INFO - Time taken for Epoch 3:5.96 - F1: 0.0100
2026-02-14 08:32:09 - INFO - Time taken for Epoch 4:5.97 - F1: 0.0155
2026-02-14 08:32:15 - INFO - Time taken for Epoch 5:6.00 - F1: 0.0155
2026-02-14 08:32:21 - INFO - Time taken for Epoch 6:6.03 - F1: 0.0155
2026-02-14 08:32:27 - INFO - Time taken for Epoch 7:5.99 - F1: 0.0155
2026-02-14 08:32:33 - INFO - Time taken for Epoch 8:6.00 - F1: 0.0155
2026-02-14 08:32:39 - INFO - Time taken for Epoch 9:6.03 - F1: 0.0155
2026-02-14 08:32:45 - INFO - Time taken for Epoch 10:5.89 - F1: 0.0155
2026-02-14 08:32:51 - INFO - Time taken for Epoch 11:5.93 - F1: 0.0155
2026-02-14 08:32:51 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-14 08:32:51 - INFO - Best F1:0.0385 - Best Epoch:0
2026-02-14 08:32:59 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 50, N: 50 Test SEED: 1234 F1: 0.0384, Test ECE: 0.2210
2026-02-14 08:32:59 - INFO - All results: {'f1_macro': 0.03837037037037037, 'ece': np.float64(0.22096899065348913)}
2026-02-14 08:32:59 - INFO - 
Total time taken: 587.87 seconds
2026-02-14 08:32:59 - INFO - Trial 9 finished with value: 0.03837037037037037 and parameters: {'learning_rate': 0.00044068021116376946, 'weight_decay': 0.00020159179141193858, 'batch_size': 16, 'co_train_epochs': 10, 'epoch_patience': 5}. Best is trial 7 with value: 0.6975817063679635.
2026-02-14 08:32:59 - INFO - 
[BEST TRIAL RESULTS]
2026-02-14 08:32:59 - INFO - F1 Score: 0.6976
2026-02-14 08:32:59 - INFO - Params: {'learning_rate': 4.162638478953669e-05, 'weight_decay': 2.1311967340062503e-05, 'batch_size': 32, 'co_train_epochs': 19, 'epoch_patience': 8}
2026-02-14 08:32:59 - INFO -   learning_rate: 4.162638478953669e-05
2026-02-14 08:32:59 - INFO -   weight_decay: 2.1311967340062503e-05
2026-02-14 08:32:59 - INFO -   batch_size: 32
2026-02-14 08:32:59 - INFO -   co_train_epochs: 19
2026-02-14 08:32:59 - INFO -   epoch_patience: 8
2026-02-14 08:32:59 - INFO - 
Total time taken: 9723.38 seconds
