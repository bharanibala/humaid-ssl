2026-02-12 22:35:21 - INFO - 
[Optuna] Starting hyperparameter search with 10 trials.
2026-02-12 22:35:21 - INFO - A new study created in memory with name: study_humanitarian9_hurricane_dorian_2019
2026-02-12 22:35:21 - INFO - Using devices: cuda, cuda
2026-02-12 22:35:21 - INFO - Devices: cuda, cuda
2026-02-12 22:35:21 - INFO - Starting log
2026-02-12 22:35:21 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 22:35:22 - INFO - Learning Rate: 0.0002631498416119128
Weight Decay: 1.2840651389845943e-05
Batch Size: 24
No. Epochs: 15
Epoch Patience: 7
 Accumulation Steps: 2
2026-02-12 22:35:23 - INFO - Generating initial weights
2026-02-12 22:35:39 - INFO - Time taken for Epoch 1:14.15 - F1: 0.0276
2026-02-12 22:35:53 - INFO - Time taken for Epoch 2:14.02 - F1: 0.1531
2026-02-12 22:36:07 - INFO - Time taken for Epoch 3:14.03 - F1: 0.2926
2026-02-12 22:36:21 - INFO - Time taken for Epoch 4:14.06 - F1: 0.3871
2026-02-12 22:36:35 - INFO - Time taken for Epoch 5:14.01 - F1: 0.4072
2026-02-12 22:36:49 - INFO - Time taken for Epoch 6:14.05 - F1: 0.4229
2026-02-12 22:37:03 - INFO - Time taken for Epoch 7:14.07 - F1: 0.4448
2026-02-12 22:37:17 - INFO - Time taken for Epoch 8:14.05 - F1: 0.4408
2026-02-12 22:37:31 - INFO - Time taken for Epoch 9:14.02 - F1: 0.4488
2026-02-12 22:37:45 - INFO - Time taken for Epoch 10:14.06 - F1: 0.4522
2026-02-12 22:37:59 - INFO - Time taken for Epoch 11:14.06 - F1: 0.4496
2026-02-12 22:38:13 - INFO - Time taken for Epoch 12:14.05 - F1: 0.4475
2026-02-12 22:38:27 - INFO - Time taken for Epoch 13:14.06 - F1: 0.4542
2026-02-12 22:38:41 - INFO - Time taken for Epoch 14:14.05 - F1: 0.4584
2026-02-12 22:38:55 - INFO - Time taken for Epoch 15:14.06 - F1: 0.4569
2026-02-12 22:38:55 - INFO - Best F1:0.4584 - Best Epoch:14
2026-02-12 22:38:56 - INFO - Starting co-training
2026-02-12 22:39:26 - INFO - Time taken for Epoch 1: 30.25s - F1: 0.33449773
2026-02-12 22:39:57 - INFO - Time taken for Epoch 2: 30.89s - F1: 0.39194643
2026-02-12 22:40:28 - INFO - Time taken for Epoch 3: 30.81s - F1: 0.37603658
2026-02-12 22:40:58 - INFO - Time taken for Epoch 4: 30.18s - F1: 0.32536422
2026-02-12 22:41:29 - INFO - Time taken for Epoch 5: 30.26s - F1: 0.17631827
2026-02-12 22:41:59 - INFO - Time taken for Epoch 6: 30.16s - F1: 0.14871964
2026-02-12 22:42:29 - INFO - Time taken for Epoch 7: 30.16s - F1: 0.22669625
2026-02-12 22:42:59 - INFO - Time taken for Epoch 8: 30.23s - F1: 0.03396410
2026-02-12 22:43:29 - INFO - Time taken for Epoch 9: 30.16s - F1: 0.03832374
2026-02-12 22:43:29 - INFO - Performance not improving for 7 consecutive epochs.
2026-02-12 22:43:31 - INFO - Fine-tuning models
2026-02-12 22:43:33 - INFO - Time taken for Epoch 1:2.14 - F1: 0.3556
2026-02-12 22:43:36 - INFO - Time taken for Epoch 2:2.75 - F1: 0.3597
2026-02-12 22:43:39 - INFO - Time taken for Epoch 3:2.96 - F1: 0.3512
2026-02-12 22:43:41 - INFO - Time taken for Epoch 4:2.13 - F1: 0.3404
2026-02-12 22:43:43 - INFO - Time taken for Epoch 5:2.13 - F1: 0.3187
2026-02-12 22:43:45 - INFO - Time taken for Epoch 6:2.12 - F1: 0.2864
2026-02-12 22:43:47 - INFO - Time taken for Epoch 7:2.13 - F1: 0.3039
2026-02-12 22:43:50 - INFO - Time taken for Epoch 8:2.13 - F1: 0.3969
2026-02-12 22:43:52 - INFO - Time taken for Epoch 9:2.80 - F1: 0.4157
2026-02-12 22:43:55 - INFO - Time taken for Epoch 10:2.77 - F1: 0.4245
2026-02-12 22:43:58 - INFO - Time taken for Epoch 11:2.75 - F1: 0.4164
2026-02-12 22:44:00 - INFO - Time taken for Epoch 12:2.13 - F1: 0.4118
2026-02-12 22:44:02 - INFO - Time taken for Epoch 13:2.13 - F1: 0.4037
2026-02-12 22:44:04 - INFO - Time taken for Epoch 14:2.13 - F1: 0.4171
2026-02-12 22:44:06 - INFO - Time taken for Epoch 15:2.13 - F1: 0.3837
2026-02-12 22:44:09 - INFO - Time taken for Epoch 16:2.14 - F1: 0.4275
2026-02-12 22:44:16 - INFO - Time taken for Epoch 17:7.74 - F1: 0.4388
2026-02-12 22:44:19 - INFO - Time taken for Epoch 18:2.78 - F1: 0.4765
2026-02-12 22:44:22 - INFO - Time taken for Epoch 19:2.84 - F1: 0.4784
2026-02-12 22:44:25 - INFO - Time taken for Epoch 20:2.93 - F1: 0.4337
2026-02-12 22:44:27 - INFO - Time taken for Epoch 21:2.12 - F1: 0.4293
2026-02-12 22:44:29 - INFO - Time taken for Epoch 22:2.13 - F1: 0.4320
2026-02-12 22:44:31 - INFO - Time taken for Epoch 23:2.13 - F1: 0.4242
2026-02-12 22:44:33 - INFO - Time taken for Epoch 24:2.14 - F1: 0.4751
2026-02-12 22:44:36 - INFO - Time taken for Epoch 25:2.13 - F1: 0.4398
2026-02-12 22:44:38 - INFO - Time taken for Epoch 26:2.13 - F1: 0.4353
2026-02-12 22:44:40 - INFO - Time taken for Epoch 27:2.13 - F1: 0.4223
2026-02-12 22:44:42 - INFO - Time taken for Epoch 28:2.13 - F1: 0.5076
2026-02-12 22:44:45 - INFO - Time taken for Epoch 29:2.83 - F1: 0.4935
2026-02-12 22:44:47 - INFO - Time taken for Epoch 30:2.13 - F1: 0.4684
2026-02-12 22:44:49 - INFO - Time taken for Epoch 31:2.13 - F1: 0.4602
2026-02-12 22:44:51 - INFO - Time taken for Epoch 32:2.13 - F1: 0.4938
2026-02-12 22:44:55 - INFO - Time taken for Epoch 33:4.11 - F1: 0.4841
2026-02-12 22:44:57 - INFO - Time taken for Epoch 34:2.13 - F1: 0.4911
2026-02-12 22:44:59 - INFO - Time taken for Epoch 35:2.13 - F1: 0.4726
2026-02-12 22:45:02 - INFO - Time taken for Epoch 36:2.13 - F1: 0.4951
2026-02-12 22:45:04 - INFO - Time taken for Epoch 37:2.13 - F1: 0.5309
2026-02-12 22:45:07 - INFO - Time taken for Epoch 38:2.85 - F1: 0.5361
2026-02-12 22:45:09 - INFO - Time taken for Epoch 39:2.80 - F1: 0.4491
2026-02-12 22:45:12 - INFO - Time taken for Epoch 40:2.13 - F1: 0.4515
2026-02-12 22:45:14 - INFO - Time taken for Epoch 41:2.13 - F1: 0.5127
2026-02-12 22:45:16 - INFO - Time taken for Epoch 42:2.14 - F1: 0.5044
2026-02-12 22:45:18 - INFO - Time taken for Epoch 43:2.13 - F1: 0.4947
2026-02-12 22:45:20 - INFO - Time taken for Epoch 44:2.13 - F1: 0.5008
2026-02-12 22:45:22 - INFO - Time taken for Epoch 45:2.13 - F1: 0.4993
2026-02-12 22:45:24 - INFO - Time taken for Epoch 46:2.13 - F1: 0.4954
2026-02-12 22:45:26 - INFO - Time taken for Epoch 47:2.13 - F1: 0.4977
2026-02-12 22:45:29 - INFO - Time taken for Epoch 48:2.13 - F1: 0.5049
2026-02-12 22:45:29 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 22:45:29 - INFO - Best F1:0.5361 - Best Epoch:37
2026-02-12 22:45:34 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.5115, Test ECE: 0.1511
2026-02-12 22:45:34 - INFO - All results: {'f1_macro': 0.511549368591413, 'ece': np.float64(0.15114821875047937)}
2026-02-12 22:45:34 - INFO - 
Total time taken: 612.27 seconds
2026-02-12 22:45:34 - INFO - Trial 0 finished with value: 0.511549368591413 and parameters: {'learning_rate': 0.0002631498416119128, 'weight_decay': 1.2840651389845943e-05, 'batch_size': 24, 'co_train_epochs': 15, 'epoch_patience': 7}. Best is trial 0 with value: 0.511549368591413.
2026-02-12 22:45:34 - INFO - Using devices: cuda, cuda
2026-02-12 22:45:34 - INFO - Devices: cuda, cuda
2026-02-12 22:45:34 - INFO - Starting log
2026-02-12 22:45:34 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 22:45:34 - INFO - Learning Rate: 0.00025427939097043533
Weight Decay: 0.0034318535692698725
Batch Size: 8
No. Epochs: 7
Epoch Patience: 7
 Accumulation Steps: 8
2026-02-12 22:45:34 - INFO - Generating initial weights
2026-02-12 22:45:53 - INFO - Time taken for Epoch 1:17.38 - F1: 0.0276
2026-02-12 22:46:11 - INFO - Time taken for Epoch 2:17.33 - F1: 0.0403
2026-02-12 22:46:28 - INFO - Time taken for Epoch 3:17.32 - F1: 0.2221
2026-02-12 22:46:45 - INFO - Time taken for Epoch 4:17.35 - F1: 0.3637
2026-02-12 22:47:03 - INFO - Time taken for Epoch 5:17.31 - F1: 0.3576
2026-02-12 22:47:20 - INFO - Time taken for Epoch 6:17.34 - F1: 0.3669
2026-02-12 22:47:37 - INFO - Time taken for Epoch 7:17.32 - F1: 0.4493
2026-02-12 22:47:37 - INFO - Best F1:0.4493 - Best Epoch:7
2026-02-12 22:47:38 - INFO - Starting co-training
2026-02-12 22:48:03 - INFO - Time taken for Epoch 1: 25.04s - F1: 0.02286448
2026-02-12 22:48:29 - INFO - Time taken for Epoch 2: 25.56s - F1: 0.03396410
2026-02-12 22:48:54 - INFO - Time taken for Epoch 3: 25.72s - F1: 0.03396410
2026-02-12 22:49:19 - INFO - Time taken for Epoch 4: 24.99s - F1: 0.03396410
2026-02-12 22:49:44 - INFO - Time taken for Epoch 5: 24.99s - F1: 0.02286448
2026-02-12 22:50:09 - INFO - Time taken for Epoch 6: 24.99s - F1: 0.02286448
2026-02-12 22:50:34 - INFO - Time taken for Epoch 7: 24.97s - F1: 0.02286448
2026-02-12 22:50:36 - INFO - Fine-tuning models
2026-02-12 22:50:38 - INFO - Time taken for Epoch 1:2.70 - F1: 0.0340
2026-02-12 22:50:42 - INFO - Time taken for Epoch 2:3.34 - F1: 0.0340
2026-02-12 22:50:45 - INFO - Time taken for Epoch 3:2.70 - F1: 0.0340
2026-02-12 22:50:47 - INFO - Time taken for Epoch 4:2.70 - F1: 0.0276
2026-02-12 22:50:50 - INFO - Time taken for Epoch 5:2.69 - F1: 0.0354
2026-02-12 22:50:53 - INFO - Time taken for Epoch 6:3.36 - F1: 0.0276
2026-02-12 22:50:56 - INFO - Time taken for Epoch 7:2.69 - F1: 0.0276
2026-02-12 22:50:59 - INFO - Time taken for Epoch 8:2.68 - F1: 0.0276
2026-02-12 22:51:01 - INFO - Time taken for Epoch 9:2.70 - F1: 0.0017
2026-02-12 22:51:04 - INFO - Time taken for Epoch 10:2.68 - F1: 0.0276
2026-02-12 22:51:07 - INFO - Time taken for Epoch 11:2.69 - F1: 0.0276
2026-02-12 22:51:09 - INFO - Time taken for Epoch 12:2.69 - F1: 0.0276
2026-02-12 22:51:12 - INFO - Time taken for Epoch 13:2.70 - F1: 0.0276
2026-02-12 22:51:15 - INFO - Time taken for Epoch 14:2.69 - F1: 0.0276
2026-02-12 22:51:17 - INFO - Time taken for Epoch 15:2.69 - F1: 0.0276
2026-02-12 22:51:17 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 22:51:17 - INFO - Best F1:0.0354 - Best Epoch:4
2026-02-12 22:51:23 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.0354, Test ECE: 0.0806
2026-02-12 22:51:23 - INFO - All results: {'f1_macro': 0.03542673107890499, 'ece': np.float64(0.08061665264934065)}
2026-02-12 22:51:23 - INFO - 
Total time taken: 349.75 seconds
2026-02-12 22:51:23 - INFO - Trial 1 finished with value: 0.03542673107890499 and parameters: {'learning_rate': 0.00025427939097043533, 'weight_decay': 0.0034318535692698725, 'batch_size': 8, 'co_train_epochs': 7, 'epoch_patience': 7}. Best is trial 0 with value: 0.511549368591413.
2026-02-12 22:51:23 - INFO - Using devices: cuda, cuda
2026-02-12 22:51:23 - INFO - Devices: cuda, cuda
2026-02-12 22:51:23 - INFO - Starting log
2026-02-12 22:51:23 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 22:51:24 - INFO - Learning Rate: 1.9466058572624896e-05
Weight Decay: 0.007404966152878768
Batch Size: 8
No. Epochs: 7
Epoch Patience: 5
 Accumulation Steps: 8
2026-02-12 22:51:24 - INFO - Generating initial weights
2026-02-12 22:51:43 - INFO - Time taken for Epoch 1:17.38 - F1: 0.0609
2026-02-12 22:52:00 - INFO - Time taken for Epoch 2:17.32 - F1: 0.0797
2026-02-12 22:52:18 - INFO - Time taken for Epoch 3:17.33 - F1: 0.0399
2026-02-12 22:52:35 - INFO - Time taken for Epoch 4:17.33 - F1: 0.0277
2026-02-12 22:52:52 - INFO - Time taken for Epoch 5:17.34 - F1: 0.0276
2026-02-12 22:53:10 - INFO - Time taken for Epoch 6:17.32 - F1: 0.0276
2026-02-12 22:53:27 - INFO - Time taken for Epoch 7:17.32 - F1: 0.0276
2026-02-12 22:53:27 - INFO - Best F1:0.0797 - Best Epoch:2
2026-02-12 22:53:28 - INFO - Starting co-training
2026-02-12 22:53:53 - INFO - Time taken for Epoch 1: 25.00s - F1: 0.27156832
2026-02-12 22:54:18 - INFO - Time taken for Epoch 2: 25.49s - F1: 0.36978762
2026-02-12 22:54:44 - INFO - Time taken for Epoch 3: 25.70s - F1: 0.37282454
2026-02-12 22:55:09 - INFO - Time taken for Epoch 4: 25.61s - F1: 0.42556598
2026-02-12 22:55:35 - INFO - Time taken for Epoch 5: 25.57s - F1: 0.43346166
2026-02-12 22:56:01 - INFO - Time taken for Epoch 6: 25.71s - F1: 0.43377820
2026-02-12 22:56:26 - INFO - Time taken for Epoch 7: 25.54s - F1: 0.44200913
2026-02-12 22:56:28 - INFO - Fine-tuning models
2026-02-12 22:56:31 - INFO - Time taken for Epoch 1:2.71 - F1: 0.4454
2026-02-12 22:56:34 - INFO - Time taken for Epoch 2:3.49 - F1: 0.4510
2026-02-12 22:56:38 - INFO - Time taken for Epoch 3:3.43 - F1: 0.4445
2026-02-12 22:56:41 - INFO - Time taken for Epoch 4:2.71 - F1: 0.4410
2026-02-12 22:56:43 - INFO - Time taken for Epoch 5:2.72 - F1: 0.4490
2026-02-12 22:56:46 - INFO - Time taken for Epoch 6:2.69 - F1: 0.4463
2026-02-12 22:56:49 - INFO - Time taken for Epoch 7:2.70 - F1: 0.4476
2026-02-12 22:56:51 - INFO - Time taken for Epoch 8:2.69 - F1: 0.4498
2026-02-12 22:56:54 - INFO - Time taken for Epoch 9:2.70 - F1: 0.4445
2026-02-12 22:56:57 - INFO - Time taken for Epoch 10:2.70 - F1: 0.4409
2026-02-12 22:57:00 - INFO - Time taken for Epoch 11:2.70 - F1: 0.4405
2026-02-12 22:57:02 - INFO - Time taken for Epoch 12:2.69 - F1: 0.4478
2026-02-12 22:57:02 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 22:57:02 - INFO - Best F1:0.4510 - Best Epoch:1
2026-02-12 22:57:08 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.4494, Test ECE: 0.0743
2026-02-12 22:57:11 - INFO - All results: {'f1_macro': 0.4494424656408277, 'ece': np.float64(0.07431898406393014)}
2026-02-12 22:57:11 - INFO - 
Total time taken: 347.86 seconds
2026-02-12 22:57:11 - INFO - Trial 2 finished with value: 0.4494424656408277 and parameters: {'learning_rate': 1.9466058572624896e-05, 'weight_decay': 0.007404966152878768, 'batch_size': 8, 'co_train_epochs': 7, 'epoch_patience': 5}. Best is trial 0 with value: 0.511549368591413.
2026-02-12 22:57:11 - INFO - Using devices: cuda, cuda
2026-02-12 22:57:11 - INFO - Devices: cuda, cuda
2026-02-12 22:57:11 - INFO - Starting log
2026-02-12 22:57:11 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 22:57:12 - INFO - Learning Rate: 1.0151433819246381e-05
Weight Decay: 0.0009821424933852043
Batch Size: 24
No. Epochs: 7
Epoch Patience: 4
 Accumulation Steps: 2
2026-02-12 22:57:12 - INFO - Generating initial weights
2026-02-12 22:57:28 - INFO - Time taken for Epoch 1:14.11 - F1: 0.0527
2026-02-12 22:57:42 - INFO - Time taken for Epoch 2:14.08 - F1: 0.0497
2026-02-12 22:57:56 - INFO - Time taken for Epoch 3:14.08 - F1: 0.0541
2026-02-12 22:58:10 - INFO - Time taken for Epoch 4:14.07 - F1: 0.0503
2026-02-12 22:58:24 - INFO - Time taken for Epoch 5:14.07 - F1: 0.0587
2026-02-12 22:58:38 - INFO - Time taken for Epoch 6:14.11 - F1: 0.0665
2026-02-12 22:58:52 - INFO - Time taken for Epoch 7:14.10 - F1: 0.0653
2026-02-12 22:58:52 - INFO - Best F1:0.0665 - Best Epoch:6
2026-02-12 22:58:53 - INFO - Starting co-training
2026-02-12 22:59:23 - INFO - Time taken for Epoch 1: 30.25s - F1: 0.34470444
2026-02-12 22:59:54 - INFO - Time taken for Epoch 2: 30.74s - F1: 0.39046693
2026-02-12 23:00:25 - INFO - Time taken for Epoch 3: 30.80s - F1: 0.43560428
2026-02-12 23:00:56 - INFO - Time taken for Epoch 4: 30.82s - F1: 0.44555738
2026-02-12 23:01:26 - INFO - Time taken for Epoch 5: 30.95s - F1: 0.46538296
2026-02-12 23:01:57 - INFO - Time taken for Epoch 6: 30.81s - F1: 0.45980666
2026-02-12 23:02:28 - INFO - Time taken for Epoch 7: 30.23s - F1: 0.45355601
2026-02-12 23:02:29 - INFO - Fine-tuning models
2026-02-12 23:02:31 - INFO - Time taken for Epoch 1:2.15 - F1: 0.4696
2026-02-12 23:02:34 - INFO - Time taken for Epoch 2:2.79 - F1: 0.4683
2026-02-12 23:02:36 - INFO - Time taken for Epoch 3:2.13 - F1: 0.4636
2026-02-12 23:02:38 - INFO - Time taken for Epoch 4:2.14 - F1: 0.4619
2026-02-12 23:02:40 - INFO - Time taken for Epoch 5:2.13 - F1: 0.4583
2026-02-12 23:02:42 - INFO - Time taken for Epoch 6:2.14 - F1: 0.4567
2026-02-12 23:02:45 - INFO - Time taken for Epoch 7:2.14 - F1: 0.4584
2026-02-12 23:02:47 - INFO - Time taken for Epoch 8:2.14 - F1: 0.4627
2026-02-12 23:02:49 - INFO - Time taken for Epoch 9:2.14 - F1: 0.4628
2026-02-12 23:02:51 - INFO - Time taken for Epoch 10:2.14 - F1: 0.4600
2026-02-12 23:02:53 - INFO - Time taken for Epoch 11:2.14 - F1: 0.4580
2026-02-12 23:02:53 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 23:02:53 - INFO - Best F1:0.4696 - Best Epoch:0
2026-02-12 23:02:58 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.4765, Test ECE: 0.0277
2026-02-12 23:02:58 - INFO - All results: {'f1_macro': 0.47650750492676497, 'ece': np.float64(0.02766636547580638)}
2026-02-12 23:02:58 - INFO - 
Total time taken: 347.02 seconds
2026-02-12 23:02:58 - INFO - Trial 3 finished with value: 0.47650750492676497 and parameters: {'learning_rate': 1.0151433819246381e-05, 'weight_decay': 0.0009821424933852043, 'batch_size': 24, 'co_train_epochs': 7, 'epoch_patience': 4}. Best is trial 0 with value: 0.511549368591413.
2026-02-12 23:02:58 - INFO - Using devices: cuda, cuda
2026-02-12 23:02:58 - INFO - Devices: cuda, cuda
2026-02-12 23:02:58 - INFO - Starting log
2026-02-12 23:02:58 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 23:02:59 - INFO - Learning Rate: 0.00016627536921495778
Weight Decay: 0.0012132029388931516
Batch Size: 24
No. Epochs: 5
Epoch Patience: 7
 Accumulation Steps: 2
2026-02-12 23:02:59 - INFO - Generating initial weights
2026-02-12 23:03:15 - INFO - Time taken for Epoch 1:14.13 - F1: 0.0276
2026-02-12 23:03:29 - INFO - Time taken for Epoch 2:14.10 - F1: 0.1760
2026-02-12 23:03:43 - INFO - Time taken for Epoch 3:14.10 - F1: 0.3037
2026-02-12 23:03:57 - INFO - Time taken for Epoch 4:14.11 - F1: 0.3722
2026-02-12 23:04:11 - INFO - Time taken for Epoch 5:14.11 - F1: 0.4010
2026-02-12 23:04:11 - INFO - Best F1:0.4010 - Best Epoch:5
2026-02-12 23:04:12 - INFO - Starting co-training
2026-02-12 23:04:42 - INFO - Time taken for Epoch 1: 30.27s - F1: 0.41354762
2026-02-12 23:05:13 - INFO - Time taken for Epoch 2: 30.84s - F1: 0.43211409
2026-02-12 23:05:45 - INFO - Time taken for Epoch 3: 31.45s - F1: 0.44020235
2026-02-12 23:06:21 - INFO - Time taken for Epoch 4: 36.37s - F1: 0.43136226
2026-02-12 23:06:51 - INFO - Time taken for Epoch 5: 30.24s - F1: 0.43314174
2026-02-12 23:06:53 - INFO - Fine-tuning models
2026-02-12 23:06:55 - INFO - Time taken for Epoch 1:2.15 - F1: 0.4292
2026-02-12 23:06:58 - INFO - Time taken for Epoch 2:3.07 - F1: 0.4119
2026-02-12 23:07:00 - INFO - Time taken for Epoch 3:2.13 - F1: 0.4092
2026-02-12 23:07:02 - INFO - Time taken for Epoch 4:2.13 - F1: 0.4282
2026-02-12 23:07:04 - INFO - Time taken for Epoch 5:2.14 - F1: 0.4583
2026-02-12 23:07:07 - INFO - Time taken for Epoch 6:2.95 - F1: 0.4608
2026-02-12 23:07:11 - INFO - Time taken for Epoch 7:3.63 - F1: 0.4744
2026-02-12 23:07:14 - INFO - Time taken for Epoch 8:2.96 - F1: 0.4566
2026-02-12 23:07:16 - INFO - Time taken for Epoch 9:2.13 - F1: 0.4377
2026-02-12 23:07:18 - INFO - Time taken for Epoch 10:2.13 - F1: 0.4343
2026-02-12 23:07:20 - INFO - Time taken for Epoch 11:2.14 - F1: 0.4446
2026-02-12 23:07:22 - INFO - Time taken for Epoch 12:2.14 - F1: 0.4828
2026-02-12 23:07:26 - INFO - Time taken for Epoch 13:3.23 - F1: 0.4952
2026-02-12 23:07:29 - INFO - Time taken for Epoch 14:2.86 - F1: 0.4951
2026-02-12 23:07:31 - INFO - Time taken for Epoch 15:2.14 - F1: 0.5093
2026-02-12 23:07:39 - INFO - Time taken for Epoch 16:8.59 - F1: 0.5131
2026-02-12 23:07:42 - INFO - Time taken for Epoch 17:2.78 - F1: 0.5092
2026-02-12 23:07:44 - INFO - Time taken for Epoch 18:2.13 - F1: 0.5135
2026-02-12 23:07:47 - INFO - Time taken for Epoch 19:2.81 - F1: 0.5101
2026-02-12 23:07:49 - INFO - Time taken for Epoch 20:2.13 - F1: 0.5263
2026-02-12 23:07:52 - INFO - Time taken for Epoch 21:2.86 - F1: 0.5093
2026-02-12 23:07:54 - INFO - Time taken for Epoch 22:2.13 - F1: 0.5084
2026-02-12 23:07:56 - INFO - Time taken for Epoch 23:2.13 - F1: 0.5085
2026-02-12 23:07:58 - INFO - Time taken for Epoch 24:2.14 - F1: 0.5121
2026-02-12 23:08:00 - INFO - Time taken for Epoch 25:2.14 - F1: 0.5086
2026-02-12 23:08:03 - INFO - Time taken for Epoch 26:2.13 - F1: 0.5154
2026-02-12 23:08:05 - INFO - Time taken for Epoch 27:2.13 - F1: 0.5143
2026-02-12 23:08:07 - INFO - Time taken for Epoch 28:2.14 - F1: 0.5085
2026-02-12 23:08:09 - INFO - Time taken for Epoch 29:2.14 - F1: 0.5009
2026-02-12 23:08:11 - INFO - Time taken for Epoch 30:2.14 - F1: 0.5023
2026-02-12 23:08:11 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 23:08:11 - INFO - Best F1:0.5263 - Best Epoch:19
2026-02-12 23:08:16 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.5061, Test ECE: 0.1554
2026-02-12 23:08:16 - INFO - All results: {'f1_macro': 0.5061241906732176, 'ece': np.float64(0.1554372452733055)}
2026-02-12 23:08:16 - INFO - 
Total time taken: 317.98 seconds
2026-02-12 23:08:16 - INFO - Trial 4 finished with value: 0.5061241906732176 and parameters: {'learning_rate': 0.00016627536921495778, 'weight_decay': 0.0012132029388931516, 'batch_size': 24, 'co_train_epochs': 5, 'epoch_patience': 7}. Best is trial 0 with value: 0.511549368591413.
2026-02-12 23:08:16 - INFO - Using devices: cuda, cuda
2026-02-12 23:08:16 - INFO - Devices: cuda, cuda
2026-02-12 23:08:16 - INFO - Starting log
2026-02-12 23:08:16 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 23:08:17 - INFO - Learning Rate: 0.00019574204750513014
Weight Decay: 0.00031601995049860475
Batch Size: 24
No. Epochs: 13
Epoch Patience: 7
 Accumulation Steps: 2
2026-02-12 23:08:17 - INFO - Generating initial weights
2026-02-12 23:08:33 - INFO - Time taken for Epoch 1:14.11 - F1: 0.0276
2026-02-12 23:08:47 - INFO - Time taken for Epoch 2:14.11 - F1: 0.1937
2026-02-12 23:09:01 - INFO - Time taken for Epoch 3:14.12 - F1: 0.3562
2026-02-12 23:09:15 - INFO - Time taken for Epoch 4:14.09 - F1: 0.4066
2026-02-12 23:09:29 - INFO - Time taken for Epoch 5:14.09 - F1: 0.4176
2026-02-12 23:09:43 - INFO - Time taken for Epoch 6:14.10 - F1: 0.4088
2026-02-12 23:09:57 - INFO - Time taken for Epoch 7:14.10 - F1: 0.4366
2026-02-12 23:10:11 - INFO - Time taken for Epoch 8:14.07 - F1: 0.4321
2026-02-12 23:10:25 - INFO - Time taken for Epoch 9:14.06 - F1: 0.4343
2026-02-12 23:10:39 - INFO - Time taken for Epoch 10:14.09 - F1: 0.4546
2026-02-12 23:10:54 - INFO - Time taken for Epoch 11:14.09 - F1: 0.4535
2026-02-12 23:11:08 - INFO - Time taken for Epoch 12:14.07 - F1: 0.4518
2026-02-12 23:11:22 - INFO - Time taken for Epoch 13:14.12 - F1: 0.4514
2026-02-12 23:11:22 - INFO - Best F1:0.4546 - Best Epoch:10
2026-02-12 23:11:22 - INFO - Starting co-training
2026-02-12 23:11:53 - INFO - Time taken for Epoch 1: 30.28s - F1: 0.44683437
2026-02-12 23:12:24 - INFO - Time taken for Epoch 2: 30.77s - F1: 0.43604709
2026-02-12 23:12:54 - INFO - Time taken for Epoch 3: 30.28s - F1: 0.43460654
2026-02-12 23:13:24 - INFO - Time taken for Epoch 4: 30.23s - F1: 0.39758909
2026-02-12 23:13:54 - INFO - Time taken for Epoch 5: 30.23s - F1: 0.42181113
2026-02-12 23:14:25 - INFO - Time taken for Epoch 6: 30.24s - F1: 0.42956706
2026-02-12 23:14:55 - INFO - Time taken for Epoch 7: 30.18s - F1: 0.49054691
2026-02-12 23:15:26 - INFO - Time taken for Epoch 8: 30.85s - F1: 0.47561741
2026-02-12 23:15:56 - INFO - Time taken for Epoch 9: 30.24s - F1: 0.43770744
2026-02-12 23:16:26 - INFO - Time taken for Epoch 10: 30.30s - F1: 0.43812860
2026-02-12 23:16:56 - INFO - Time taken for Epoch 11: 30.20s - F1: 0.47542495
2026-02-12 23:17:27 - INFO - Time taken for Epoch 12: 30.23s - F1: 0.50573723
2026-02-12 23:17:57 - INFO - Time taken for Epoch 13: 30.84s - F1: 0.45918768
2026-02-12 23:17:59 - INFO - Fine-tuning models
2026-02-12 23:18:01 - INFO - Time taken for Epoch 1:2.15 - F1: 0.4581
2026-02-12 23:18:04 - INFO - Time taken for Epoch 2:2.75 - F1: 0.4900
2026-02-12 23:18:07 - INFO - Time taken for Epoch 3:2.77 - F1: 0.5050
2026-02-12 23:18:10 - INFO - Time taken for Epoch 4:3.02 - F1: 0.5027
2026-02-12 23:18:12 - INFO - Time taken for Epoch 5:2.13 - F1: 0.5086
2026-02-12 23:18:15 - INFO - Time taken for Epoch 6:2.99 - F1: 0.5032
2026-02-12 23:18:17 - INFO - Time taken for Epoch 7:2.13 - F1: 0.4990
2026-02-12 23:18:19 - INFO - Time taken for Epoch 8:2.13 - F1: 0.4822
2026-02-12 23:18:21 - INFO - Time taken for Epoch 9:2.13 - F1: 0.4829
2026-02-12 23:18:23 - INFO - Time taken for Epoch 10:2.13 - F1: 0.4869
2026-02-12 23:18:25 - INFO - Time taken for Epoch 11:2.13 - F1: 0.4945
2026-02-12 23:18:27 - INFO - Time taken for Epoch 12:2.13 - F1: 0.4902
2026-02-12 23:18:30 - INFO - Time taken for Epoch 13:2.13 - F1: 0.4902
2026-02-12 23:18:32 - INFO - Time taken for Epoch 14:2.13 - F1: 0.4882
2026-02-12 23:18:34 - INFO - Time taken for Epoch 15:2.13 - F1: 0.4886
2026-02-12 23:18:34 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 23:18:34 - INFO - Best F1:0.5086 - Best Epoch:4
2026-02-12 23:18:39 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.5260, Test ECE: 0.1357
2026-02-12 23:18:39 - INFO - All results: {'f1_macro': 0.5259927139402655, 'ece': np.float64(0.13573144083788286)}
2026-02-12 23:18:39 - INFO - 
Total time taken: 622.54 seconds
2026-02-12 23:18:39 - INFO - Trial 5 finished with value: 0.5259927139402655 and parameters: {'learning_rate': 0.00019574204750513014, 'weight_decay': 0.00031601995049860475, 'batch_size': 24, 'co_train_epochs': 13, 'epoch_patience': 7}. Best is trial 5 with value: 0.5259927139402655.
2026-02-12 23:18:39 - INFO - Using devices: cuda, cuda
2026-02-12 23:18:39 - INFO - Devices: cuda, cuda
2026-02-12 23:18:39 - INFO - Starting log
2026-02-12 23:18:39 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 23:18:39 - INFO - Learning Rate: 6.815085197501968e-05
Weight Decay: 1.5465586479193072e-05
Batch Size: 8
No. Epochs: 19
Epoch Patience: 4
 Accumulation Steps: 8
2026-02-12 23:18:40 - INFO - Generating initial weights
2026-02-12 23:18:58 - INFO - Time taken for Epoch 1:17.37 - F1: 0.0277
2026-02-12 23:19:16 - INFO - Time taken for Epoch 2:17.38 - F1: 0.0276
2026-02-12 23:19:33 - INFO - Time taken for Epoch 3:17.36 - F1: 0.0276
2026-02-12 23:19:51 - INFO - Time taken for Epoch 4:17.36 - F1: 0.0276
2026-02-12 23:20:08 - INFO - Time taken for Epoch 5:17.37 - F1: 0.0594
2026-02-12 23:20:25 - INFO - Time taken for Epoch 6:17.35 - F1: 0.2106
2026-02-12 23:20:43 - INFO - Time taken for Epoch 7:17.36 - F1: 0.2713
2026-02-12 23:21:00 - INFO - Time taken for Epoch 8:17.36 - F1: 0.3238
2026-02-12 23:21:17 - INFO - Time taken for Epoch 9:17.35 - F1: 0.3574
2026-02-12 23:21:35 - INFO - Time taken for Epoch 10:17.37 - F1: 0.3611
2026-02-12 23:21:52 - INFO - Time taken for Epoch 11:17.36 - F1: 0.3702
2026-02-12 23:22:09 - INFO - Time taken for Epoch 12:17.34 - F1: 0.4004
2026-02-12 23:22:27 - INFO - Time taken for Epoch 13:17.36 - F1: 0.4117
2026-02-12 23:22:44 - INFO - Time taken for Epoch 14:17.40 - F1: 0.4174
2026-02-12 23:23:02 - INFO - Time taken for Epoch 15:17.38 - F1: 0.4135
2026-02-12 23:23:19 - INFO - Time taken for Epoch 16:17.38 - F1: 0.4183
2026-02-12 23:23:36 - INFO - Time taken for Epoch 17:17.37 - F1: 0.4191
2026-02-12 23:23:54 - INFO - Time taken for Epoch 18:17.36 - F1: 0.4205
2026-02-12 23:24:11 - INFO - Time taken for Epoch 19:17.38 - F1: 0.4207
2026-02-12 23:24:11 - INFO - Best F1:0.4207 - Best Epoch:19
2026-02-12 23:24:12 - INFO - Starting co-training
2026-02-12 23:24:37 - INFO - Time taken for Epoch 1: 25.01s - F1: 0.38331079
2026-02-12 23:25:03 - INFO - Time taken for Epoch 2: 25.65s - F1: 0.42695155
2026-02-12 23:25:28 - INFO - Time taken for Epoch 3: 25.62s - F1: 0.41728508
2026-02-12 23:25:53 - INFO - Time taken for Epoch 4: 25.00s - F1: 0.45140977
2026-02-12 23:26:19 - INFO - Time taken for Epoch 5: 25.65s - F1: 0.44007611
2026-02-12 23:26:44 - INFO - Time taken for Epoch 6: 25.02s - F1: 0.42875841
2026-02-12 23:27:09 - INFO - Time taken for Epoch 7: 24.99s - F1: 0.43127322
2026-02-12 23:27:34 - INFO - Time taken for Epoch 8: 25.00s - F1: 0.43718088
2026-02-12 23:27:34 - INFO - Performance not improving for 4 consecutive epochs.
2026-02-12 23:27:36 - INFO - Fine-tuning models
2026-02-12 23:27:39 - INFO - Time taken for Epoch 1:2.72 - F1: 0.4455
2026-02-12 23:27:42 - INFO - Time taken for Epoch 2:3.34 - F1: 0.4445
2026-02-12 23:27:45 - INFO - Time taken for Epoch 3:2.70 - F1: 0.4429
2026-02-12 23:27:48 - INFO - Time taken for Epoch 4:2.69 - F1: 0.4431
2026-02-12 23:27:50 - INFO - Time taken for Epoch 5:2.69 - F1: 0.4576
2026-02-12 23:27:54 - INFO - Time taken for Epoch 6:3.43 - F1: 0.4696
2026-02-12 23:27:57 - INFO - Time taken for Epoch 7:3.35 - F1: 0.4739
2026-02-12 23:28:00 - INFO - Time taken for Epoch 8:3.36 - F1: 0.5090
2026-02-12 23:28:04 - INFO - Time taken for Epoch 9:3.37 - F1: 0.5055
2026-02-12 23:28:06 - INFO - Time taken for Epoch 10:2.69 - F1: 0.5203
2026-02-12 23:28:10 - INFO - Time taken for Epoch 11:3.37 - F1: 0.4949
2026-02-12 23:28:12 - INFO - Time taken for Epoch 12:2.70 - F1: 0.4780
2026-02-12 23:28:15 - INFO - Time taken for Epoch 13:2.70 - F1: 0.4860
2026-02-12 23:28:18 - INFO - Time taken for Epoch 14:2.70 - F1: 0.4956
2026-02-12 23:28:23 - INFO - Time taken for Epoch 15:4.75 - F1: 0.4961
2026-02-12 23:28:25 - INFO - Time taken for Epoch 16:2.69 - F1: 0.5101
2026-02-12 23:28:28 - INFO - Time taken for Epoch 17:2.70 - F1: 0.5114
2026-02-12 23:28:31 - INFO - Time taken for Epoch 18:2.70 - F1: 0.5084
2026-02-12 23:28:33 - INFO - Time taken for Epoch 19:2.70 - F1: 0.5154
2026-02-12 23:28:36 - INFO - Time taken for Epoch 20:2.72 - F1: 0.5482
2026-02-12 23:28:40 - INFO - Time taken for Epoch 21:3.39 - F1: 0.5351
2026-02-12 23:28:42 - INFO - Time taken for Epoch 22:2.71 - F1: 0.5306
2026-02-12 23:28:45 - INFO - Time taken for Epoch 23:2.70 - F1: 0.5315
2026-02-12 23:28:48 - INFO - Time taken for Epoch 24:2.70 - F1: 0.5213
2026-02-12 23:28:50 - INFO - Time taken for Epoch 25:2.70 - F1: 0.5285
2026-02-12 23:28:53 - INFO - Time taken for Epoch 26:2.70 - F1: 0.5345
2026-02-12 23:28:56 - INFO - Time taken for Epoch 27:2.70 - F1: 0.5380
2026-02-12 23:28:58 - INFO - Time taken for Epoch 28:2.69 - F1: 0.5351
2026-02-12 23:29:01 - INFO - Time taken for Epoch 29:2.70 - F1: 0.5423
2026-02-12 23:29:04 - INFO - Time taken for Epoch 30:2.70 - F1: 0.5391
2026-02-12 23:29:04 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 23:29:04 - INFO - Best F1:0.5482 - Best Epoch:19
2026-02-12 23:29:10 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.5639, Test ECE: 0.1094
2026-02-12 23:29:10 - INFO - All results: {'f1_macro': 0.5639443362291109, 'ece': np.float64(0.10944447516209252)}
2026-02-12 23:29:10 - INFO - 
Total time taken: 630.86 seconds
2026-02-12 23:29:10 - INFO - Trial 6 finished with value: 0.5639443362291109 and parameters: {'learning_rate': 6.815085197501968e-05, 'weight_decay': 1.5465586479193072e-05, 'batch_size': 8, 'co_train_epochs': 19, 'epoch_patience': 4}. Best is trial 6 with value: 0.5639443362291109.
2026-02-12 23:29:10 - INFO - Using devices: cuda, cuda
2026-02-12 23:29:10 - INFO - Devices: cuda, cuda
2026-02-12 23:29:10 - INFO - Starting log
2026-02-12 23:29:10 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 23:29:10 - INFO - Learning Rate: 8.253955218964777e-05
Weight Decay: 0.00017770741081484637
Batch Size: 8
No. Epochs: 19
Epoch Patience: 6
 Accumulation Steps: 8
2026-02-12 23:29:11 - INFO - Generating initial weights
2026-02-12 23:29:30 - INFO - Time taken for Epoch 1:17.42 - F1: 0.0276
2026-02-12 23:29:47 - INFO - Time taken for Epoch 2:17.35 - F1: 0.0276
2026-02-12 23:30:04 - INFO - Time taken for Epoch 3:17.38 - F1: 0.0276
2026-02-12 23:30:22 - INFO - Time taken for Epoch 4:17.38 - F1: 0.0412
2026-02-12 23:30:39 - INFO - Time taken for Epoch 5:17.34 - F1: 0.2273
2026-02-12 23:30:56 - INFO - Time taken for Epoch 6:17.34 - F1: 0.2821
2026-02-12 23:31:14 - INFO - Time taken for Epoch 7:17.37 - F1: 0.3398
2026-02-12 23:31:31 - INFO - Time taken for Epoch 8:17.35 - F1: 0.3846
2026-02-12 23:31:48 - INFO - Time taken for Epoch 9:17.36 - F1: 0.3817
2026-02-12 23:32:06 - INFO - Time taken for Epoch 10:17.34 - F1: 0.3840
2026-02-12 23:32:23 - INFO - Time taken for Epoch 11:17.36 - F1: 0.4091
2026-02-12 23:32:41 - INFO - Time taken for Epoch 12:17.38 - F1: 0.4207
2026-02-12 23:32:58 - INFO - Time taken for Epoch 13:17.35 - F1: 0.4187
2026-02-12 23:33:15 - INFO - Time taken for Epoch 14:17.36 - F1: 0.4110
2026-02-12 23:33:33 - INFO - Time taken for Epoch 15:17.36 - F1: 0.4129
2026-02-12 23:33:50 - INFO - Time taken for Epoch 16:17.36 - F1: 0.4220
2026-02-12 23:34:07 - INFO - Time taken for Epoch 17:17.37 - F1: 0.4285
2026-02-12 23:34:25 - INFO - Time taken for Epoch 18:17.40 - F1: 0.4344
2026-02-12 23:34:42 - INFO - Time taken for Epoch 19:17.39 - F1: 0.4353
2026-02-12 23:34:42 - INFO - Best F1:0.4353 - Best Epoch:19
2026-02-12 23:34:43 - INFO - Starting co-training
2026-02-12 23:35:08 - INFO - Time taken for Epoch 1: 24.99s - F1: 0.36002053
2026-02-12 23:35:33 - INFO - Time taken for Epoch 2: 25.52s - F1: 0.44942381
2026-02-12 23:35:59 - INFO - Time taken for Epoch 3: 25.67s - F1: 0.42649033
2026-02-12 23:36:24 - INFO - Time taken for Epoch 4: 24.99s - F1: 0.43759478
2026-02-12 23:36:49 - INFO - Time taken for Epoch 5: 24.99s - F1: 0.42202083
2026-02-12 23:37:14 - INFO - Time taken for Epoch 6: 24.98s - F1: 0.40876036
2026-02-12 23:37:39 - INFO - Time taken for Epoch 7: 25.01s - F1: 0.44961817
2026-02-12 23:38:05 - INFO - Time taken for Epoch 8: 25.61s - F1: 0.40107068
2026-02-12 23:38:30 - INFO - Time taken for Epoch 9: 25.13s - F1: 0.45335798
2026-02-12 23:38:56 - INFO - Time taken for Epoch 10: 26.62s - F1: 0.43937344
2026-02-12 23:39:21 - INFO - Time taken for Epoch 11: 25.03s - F1: 0.43985665
2026-02-12 23:39:46 - INFO - Time taken for Epoch 12: 25.01s - F1: 0.45052075
2026-02-12 23:40:11 - INFO - Time taken for Epoch 13: 25.04s - F1: 0.44705576
2026-02-12 23:40:37 - INFO - Time taken for Epoch 14: 25.08s - F1: 0.45688180
2026-02-12 23:41:02 - INFO - Time taken for Epoch 15: 25.87s - F1: 0.47996628
2026-02-12 23:41:28 - INFO - Time taken for Epoch 16: 25.64s - F1: 0.50638691
2026-02-12 23:41:54 - INFO - Time taken for Epoch 17: 25.77s - F1: 0.51240261
2026-02-12 23:42:20 - INFO - Time taken for Epoch 18: 25.68s - F1: 0.45853354
2026-02-12 23:42:45 - INFO - Time taken for Epoch 19: 24.99s - F1: 0.49551185
2026-02-12 23:42:46 - INFO - Fine-tuning models
2026-02-12 23:42:49 - INFO - Time taken for Epoch 1:2.71 - F1: 0.5103
2026-02-12 23:42:52 - INFO - Time taken for Epoch 2:3.39 - F1: 0.5041
2026-02-12 23:42:55 - INFO - Time taken for Epoch 3:2.69 - F1: 0.4919
2026-02-12 23:42:57 - INFO - Time taken for Epoch 4:2.69 - F1: 0.4865
2026-02-12 23:43:00 - INFO - Time taken for Epoch 5:2.70 - F1: 0.4683
2026-02-12 23:43:03 - INFO - Time taken for Epoch 6:2.69 - F1: 0.4615
2026-02-12 23:43:06 - INFO - Time taken for Epoch 7:2.69 - F1: 0.4666
2026-02-12 23:43:08 - INFO - Time taken for Epoch 8:2.68 - F1: 0.4837
2026-02-12 23:43:11 - INFO - Time taken for Epoch 9:2.70 - F1: 0.4952
2026-02-12 23:43:14 - INFO - Time taken for Epoch 10:2.70 - F1: 0.5032
2026-02-12 23:43:16 - INFO - Time taken for Epoch 11:2.69 - F1: 0.5002
2026-02-12 23:43:16 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 23:43:16 - INFO - Best F1:0.5103 - Best Epoch:0
2026-02-12 23:43:22 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.5100, Test ECE: 0.0970
2026-02-12 23:43:22 - INFO - All results: {'f1_macro': 0.5100395856985366, 'ece': np.float64(0.0970067270396559)}
2026-02-12 23:43:22 - INFO - 
Total time taken: 852.40 seconds
2026-02-12 23:43:22 - INFO - Trial 7 finished with value: 0.5100395856985366 and parameters: {'learning_rate': 8.253955218964777e-05, 'weight_decay': 0.00017770741081484637, 'batch_size': 8, 'co_train_epochs': 19, 'epoch_patience': 6}. Best is trial 6 with value: 0.5639443362291109.
2026-02-12 23:43:22 - INFO - Using devices: cuda, cuda
2026-02-12 23:43:22 - INFO - Devices: cuda, cuda
2026-02-12 23:43:22 - INFO - Starting log
2026-02-12 23:43:22 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 23:43:22 - INFO - Learning Rate: 3.120507930880096e-05
Weight Decay: 0.00023667898484207417
Batch Size: 24
No. Epochs: 9
Epoch Patience: 4
 Accumulation Steps: 2
2026-02-12 23:43:23 - INFO - Generating initial weights
2026-02-12 23:43:41 - INFO - Time taken for Epoch 1:14.12 - F1: 0.0261
2026-02-12 23:43:55 - INFO - Time taken for Epoch 2:14.08 - F1: 0.0424
2026-02-12 23:44:09 - INFO - Time taken for Epoch 3:14.09 - F1: 0.0981
2026-02-12 23:44:23 - INFO - Time taken for Epoch 4:14.07 - F1: 0.1241
2026-02-12 23:44:37 - INFO - Time taken for Epoch 5:14.08 - F1: 0.1436
2026-02-12 23:44:51 - INFO - Time taken for Epoch 6:14.12 - F1: 0.1674
2026-02-12 23:45:05 - INFO - Time taken for Epoch 7:14.10 - F1: 0.1953
2026-02-12 23:45:19 - INFO - Time taken for Epoch 8:14.09 - F1: 0.2270
2026-02-12 23:45:34 - INFO - Time taken for Epoch 9:14.06 - F1: 0.2407
2026-02-12 23:45:34 - INFO - Best F1:0.2407 - Best Epoch:9
2026-02-12 23:45:34 - INFO - Starting co-training
2026-02-12 23:46:04 - INFO - Time taken for Epoch 1: 30.26s - F1: 0.44937135
2026-02-12 23:46:35 - INFO - Time taken for Epoch 2: 30.76s - F1: 0.44535469
2026-02-12 23:47:05 - INFO - Time taken for Epoch 3: 30.25s - F1: 0.42719169
2026-02-12 23:47:36 - INFO - Time taken for Epoch 4: 30.23s - F1: 0.46780438
2026-02-12 23:48:07 - INFO - Time taken for Epoch 5: 31.13s - F1: 0.48087139
2026-02-12 23:48:38 - INFO - Time taken for Epoch 6: 30.86s - F1: 0.47646052
2026-02-12 23:49:08 - INFO - Time taken for Epoch 7: 30.24s - F1: 0.55782113
2026-02-12 23:49:39 - INFO - Time taken for Epoch 8: 30.78s - F1: 0.55270338
2026-02-12 23:50:09 - INFO - Time taken for Epoch 9: 30.24s - F1: 0.59891076
2026-02-12 23:50:11 - INFO - Fine-tuning models
2026-02-12 23:50:13 - INFO - Time taken for Epoch 1:2.15 - F1: 0.6024
2026-02-12 23:50:17 - INFO - Time taken for Epoch 2:3.36 - F1: 0.5952
2026-02-12 23:50:19 - INFO - Time taken for Epoch 3:2.13 - F1: 0.5718
2026-02-12 23:50:21 - INFO - Time taken for Epoch 4:2.13 - F1: 0.5629
2026-02-12 23:50:23 - INFO - Time taken for Epoch 5:2.13 - F1: 0.5578
2026-02-12 23:50:25 - INFO - Time taken for Epoch 6:2.14 - F1: 0.5458
2026-02-12 23:50:27 - INFO - Time taken for Epoch 7:2.15 - F1: 0.5524
2026-02-12 23:50:29 - INFO - Time taken for Epoch 8:2.13 - F1: 0.5483
2026-02-12 23:50:32 - INFO - Time taken for Epoch 9:2.14 - F1: 0.5547
2026-02-12 23:50:34 - INFO - Time taken for Epoch 10:2.14 - F1: 0.5590
2026-02-12 23:50:36 - INFO - Time taken for Epoch 11:2.14 - F1: 0.5563
2026-02-12 23:50:36 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-12 23:50:36 - INFO - Best F1:0.6024 - Best Epoch:0
2026-02-12 23:50:41 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.5801, Test ECE: 0.0240
2026-02-12 23:50:41 - INFO - All results: {'f1_macro': 0.5800519897206141, 'ece': np.float64(0.02400005183896588)}
2026-02-12 23:50:41 - INFO - 
Total time taken: 438.62 seconds
2026-02-12 23:50:41 - INFO - Trial 8 finished with value: 0.5800519897206141 and parameters: {'learning_rate': 3.120507930880096e-05, 'weight_decay': 0.00023667898484207417, 'batch_size': 24, 'co_train_epochs': 9, 'epoch_patience': 4}. Best is trial 8 with value: 0.5800519897206141.
2026-02-12 23:50:41 - INFO - Using devices: cuda, cuda
2026-02-12 23:50:41 - INFO - Devices: cuda, cuda
2026-02-12 23:50:41 - INFO - Starting log
2026-02-12 23:50:41 - INFO - Dataset: humanitarian9, Event: hurricane_dorian_2019, N: 10, Seed: 1234, HF Model: GPT-4o, NumShots: 10, PLM: bert-tweet
2026-02-12 23:50:41 - INFO - Learning Rate: 2.6539823760603876e-05
Weight Decay: 0.00024278861679262353
Batch Size: 24
No. Epochs: 13
Epoch Patience: 7
 Accumulation Steps: 2
2026-02-12 23:50:42 - INFO - Generating initial weights
2026-02-12 23:50:57 - INFO - Time taken for Epoch 1:14.18 - F1: 0.0349
2026-02-12 23:51:11 - INFO - Time taken for Epoch 2:14.12 - F1: 0.0360
2026-02-12 23:51:26 - INFO - Time taken for Epoch 3:14.14 - F1: 0.0740
2026-02-12 23:51:40 - INFO - Time taken for Epoch 4:14.11 - F1: 0.0998
2026-02-12 23:51:54 - INFO - Time taken for Epoch 5:14.10 - F1: 0.1369
2026-02-12 23:52:08 - INFO - Time taken for Epoch 6:14.11 - F1: 0.1545
2026-02-12 23:52:22 - INFO - Time taken for Epoch 7:14.10 - F1: 0.1745
2026-02-12 23:52:36 - INFO - Time taken for Epoch 8:14.11 - F1: 0.1993
2026-02-12 23:52:50 - INFO - Time taken for Epoch 9:14.11 - F1: 0.2361
2026-02-12 23:53:04 - INFO - Time taken for Epoch 10:14.10 - F1: 0.2483
2026-02-12 23:53:18 - INFO - Time taken for Epoch 11:14.10 - F1: 0.2653
2026-02-12 23:53:32 - INFO - Time taken for Epoch 12:14.09 - F1: 0.2782
2026-02-12 23:53:47 - INFO - Time taken for Epoch 13:14.10 - F1: 0.2968
2026-02-12 23:53:47 - INFO - Best F1:0.2968 - Best Epoch:13
2026-02-12 23:53:47 - INFO - Starting co-training
2026-02-12 23:54:18 - INFO - Time taken for Epoch 1: 30.27s - F1: 0.43890804
2026-02-12 23:54:49 - INFO - Time taken for Epoch 2: 31.04s - F1: 0.44462310
2026-02-12 23:55:29 - INFO - Time taken for Epoch 3: 40.03s - F1: 0.42180240
2026-02-12 23:55:59 - INFO - Time taken for Epoch 4: 30.29s - F1: 0.46054420
2026-02-12 23:56:30 - INFO - Time taken for Epoch 5: 30.88s - F1: 0.47601612
2026-02-12 23:57:01 - INFO - Time taken for Epoch 6: 30.88s - F1: 0.51660043
2026-02-12 23:57:32 - INFO - Time taken for Epoch 7: 30.84s - F1: 0.52185898
2026-02-12 23:58:03 - INFO - Time taken for Epoch 8: 30.95s - F1: 0.52912660
2026-02-12 23:58:33 - INFO - Time taken for Epoch 9: 30.85s - F1: 0.58761481
2026-02-12 23:59:06 - INFO - Time taken for Epoch 10: 32.15s - F1: 0.59518298
2026-02-12 23:59:40 - INFO - Time taken for Epoch 11: 34.21s - F1: 0.57570831
2026-02-13 00:00:10 - INFO - Time taken for Epoch 12: 30.23s - F1: 0.60112390
2026-02-13 00:00:41 - INFO - Time taken for Epoch 13: 30.93s - F1: 0.56288939
2026-02-13 00:00:43 - INFO - Fine-tuning models
2026-02-13 00:00:45 - INFO - Time taken for Epoch 1:2.15 - F1: 0.5859
2026-02-13 00:00:48 - INFO - Time taken for Epoch 2:2.74 - F1: 0.5831
2026-02-13 00:00:50 - INFO - Time taken for Epoch 3:2.14 - F1: 0.5844
2026-02-13 00:00:52 - INFO - Time taken for Epoch 4:2.14 - F1: 0.5950
2026-02-13 00:00:55 - INFO - Time taken for Epoch 5:2.83 - F1: 0.5977
2026-02-13 00:00:57 - INFO - Time taken for Epoch 6:2.76 - F1: 0.5838
2026-02-13 00:01:00 - INFO - Time taken for Epoch 7:2.13 - F1: 0.5797
2026-02-13 00:01:02 - INFO - Time taken for Epoch 8:2.13 - F1: 0.5627
2026-02-13 00:01:04 - INFO - Time taken for Epoch 9:2.14 - F1: 0.5613
2026-02-13 00:01:06 - INFO - Time taken for Epoch 10:2.14 - F1: 0.5661
2026-02-13 00:01:08 - INFO - Time taken for Epoch 11:2.14 - F1: 0.5703
2026-02-13 00:01:10 - INFO - Time taken for Epoch 12:2.14 - F1: 0.5760
2026-02-13 00:01:12 - INFO - Time taken for Epoch 13:2.14 - F1: 0.5865
2026-02-13 00:01:15 - INFO - Time taken for Epoch 14:2.14 - F1: 0.5865
2026-02-13 00:01:17 - INFO - Time taken for Epoch 15:2.14 - F1: 0.5954
2026-02-13 00:01:17 - INFO - Performance not improving for 10 consecutive epochs.
2026-02-13 00:01:17 - INFO - Best F1:0.5977 - Best Epoch:4
2026-02-13 00:01:22 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian9, NumShots: 10, N: 10 Test SEED: 1234 F1: 0.5659, Test ECE: 0.0446
2026-02-13 00:01:22 - INFO - All results: {'f1_macro': 0.5658911379805871, 'ece': np.float64(0.0445724756157999)}
2026-02-13 00:01:22 - INFO - 
Total time taken: 640.93 seconds
2026-02-13 00:01:22 - INFO - Trial 9 finished with value: 0.5658911379805871 and parameters: {'learning_rate': 2.6539823760603876e-05, 'weight_decay': 0.00024278861679262353, 'batch_size': 24, 'co_train_epochs': 13, 'epoch_patience': 7}. Best is trial 8 with value: 0.5800519897206141.
2026-02-13 00:01:22 - INFO - 
[BEST TRIAL RESULTS]
2026-02-13 00:01:22 - INFO - F1 Score: 0.5801
2026-02-13 00:01:22 - INFO - Params: {'learning_rate': 3.120507930880096e-05, 'weight_decay': 0.00023667898484207417, 'batch_size': 24, 'co_train_epochs': 9, 'epoch_patience': 4}
2026-02-13 00:01:22 - INFO -   learning_rate: 3.120507930880096e-05
2026-02-13 00:01:22 - INFO -   weight_decay: 0.00023667898484207417
2026-02-13 00:01:22 - INFO -   batch_size: 24
2026-02-13 00:01:22 - INFO -   co_train_epochs: 9
2026-02-13 00:01:22 - INFO -   epoch_patience: 4
2026-02-13 00:01:22 - INFO - 
Total time taken: 5160.39 seconds
