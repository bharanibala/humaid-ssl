[Optuna] Starting hyperparameter search with 10 trials.
2026-02-12 07:50:32 - INFO - 
[Optuna] Starting hyperparameter search with 10 trials.
2026-02-12 07:50:32 - INFO - A new study created in memory with name: study_humanitarian10_cyclone_idai_2019
Using devices: cuda, cuda
2026-02-12 07:50:32 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 07:50:32 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 07:50:32 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 07:50:32 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
Learning Rate: 1.0084455944625857e-05
Weight Decay: 0.00022163663318369112
Batch Size: 8
No. Epochs: 14
Epoch Patience: 5
 Accumulation Steps: 8
2026-02-12 07:50:33 - INFO - Learning Rate: 1.0084455944625857e-05
Weight Decay: 0.00022163663318369112
Batch Size: 8
No. Epochs: 14
Epoch Patience: 5
 Accumulation Steps: 8
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 07:50:34 - INFO - Generating initial weights
Time taken for Epoch 1:9.76 - F1: 0.0259
2026-02-12 07:50:45 - INFO - Time taken for Epoch 1:9.76 - F1: 0.0259
Time taken for Epoch 2:9.76 - F1: 0.0303
2026-02-12 07:50:55 - INFO - Time taken for Epoch 2:9.76 - F1: 0.0303
Time taken for Epoch 3:9.72 - F1: 0.0308
2026-02-12 07:51:04 - INFO - Time taken for Epoch 3:9.72 - F1: 0.0308
Time taken for Epoch 4:9.79 - F1: 0.0457
2026-02-12 07:51:14 - INFO - Time taken for Epoch 4:9.79 - F1: 0.0457
Time taken for Epoch 5:9.80 - F1: 0.0450
2026-02-12 07:51:24 - INFO - Time taken for Epoch 5:9.80 - F1: 0.0450
Time taken for Epoch 6:9.67 - F1: 0.0508
2026-02-12 07:51:34 - INFO - Time taken for Epoch 6:9.67 - F1: 0.0508
Time taken for Epoch 7:9.76 - F1: 0.0537
2026-02-12 07:51:43 - INFO - Time taken for Epoch 7:9.76 - F1: 0.0537
Time taken for Epoch 8:9.68 - F1: 0.0561
2026-02-12 07:51:53 - INFO - Time taken for Epoch 8:9.68 - F1: 0.0561
Time taken for Epoch 9:9.71 - F1: 0.0630
2026-02-12 07:52:03 - INFO - Time taken for Epoch 9:9.71 - F1: 0.0630
Time taken for Epoch 10:9.70 - F1: 0.0646
2026-02-12 07:52:12 - INFO - Time taken for Epoch 10:9.70 - F1: 0.0646
Time taken for Epoch 11:9.68 - F1: 0.0716
2026-02-12 07:52:22 - INFO - Time taken for Epoch 11:9.68 - F1: 0.0716
Time taken for Epoch 12:9.65 - F1: 0.0720
2026-02-12 07:52:32 - INFO - Time taken for Epoch 12:9.65 - F1: 0.0720
Time taken for Epoch 13:9.61 - F1: 0.0819
2026-02-12 07:52:41 - INFO - Time taken for Epoch 13:9.61 - F1: 0.0819
Time taken for Epoch 14:9.70 - F1: 0.0872
2026-02-12 07:52:51 - INFO - Time taken for Epoch 14:9.70 - F1: 0.0872
Best F1:0.0872 - Best Epoch:14
2026-02-12 07:52:51 - INFO - Best F1:0.0872 - Best Epoch:14
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 07:52:52 - INFO - Starting co-training
Time taken for Epoch 1: 10.82s - F1: 0.06452703
2026-02-12 07:53:03 - INFO - Time taken for Epoch 1: 10.82s - F1: 0.06452703
Time taken for Epoch 2: 12.27s - F1: 0.06452703
2026-02-12 07:53:16 - INFO - Time taken for Epoch 2: 12.27s - F1: 0.06452703
Time taken for Epoch 3: 10.80s - F1: 0.13627820
2026-02-12 07:53:26 - INFO - Time taken for Epoch 3: 10.80s - F1: 0.13627820
Time taken for Epoch 4: 15.42s - F1: 0.21540038
2026-02-12 07:53:42 - INFO - Time taken for Epoch 4: 15.42s - F1: 0.21540038
Time taken for Epoch 5: 14.82s - F1: 0.21971781
2026-02-12 07:53:57 - INFO - Time taken for Epoch 5: 14.82s - F1: 0.21971781
Time taken for Epoch 6: 16.04s - F1: 0.21951110
2026-02-12 07:54:13 - INFO - Time taken for Epoch 6: 16.04s - F1: 0.21951110
Time taken for Epoch 7: 10.95s - F1: 0.22816375
2026-02-12 07:54:24 - INFO - Time taken for Epoch 7: 10.95s - F1: 0.22816375
Time taken for Epoch 8: 15.96s - F1: 0.22483138
2026-02-12 07:54:40 - INFO - Time taken for Epoch 8: 15.96s - F1: 0.22483138
Time taken for Epoch 9: 10.81s - F1: 0.22505770
2026-02-12 07:54:50 - INFO - Time taken for Epoch 9: 10.81s - F1: 0.22505770
Time taken for Epoch 10: 10.77s - F1: 0.22545974
2026-02-12 07:55:01 - INFO - Time taken for Epoch 10: 10.77s - F1: 0.22545974
Time taken for Epoch 11: 10.77s - F1: 0.27302353
2026-02-12 07:55:12 - INFO - Time taken for Epoch 11: 10.77s - F1: 0.27302353
Time taken for Epoch 12: 14.96s - F1: 0.30196959
2026-02-12 07:55:27 - INFO - Time taken for Epoch 12: 14.96s - F1: 0.30196959
Time taken for Epoch 13: 14.57s - F1: 0.30241598
2026-02-12 07:55:42 - INFO - Time taken for Epoch 13: 14.57s - F1: 0.30241598
Time taken for Epoch 14: 15.16s - F1: 0.30206647
2026-02-12 07:55:57 - INFO - Time taken for Epoch 14: 15.16s - F1: 0.30206647
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 07:55:59 - INFO - Fine-tuning models
Time taken for Epoch 1:1.87 - F1: 0.2908
2026-02-12 07:56:01 - INFO - Time taken for Epoch 1:1.87 - F1: 0.2908
Time taken for Epoch 2:3.05 - F1: 0.2935
2026-02-12 07:56:05 - INFO - Time taken for Epoch 2:3.05 - F1: 0.2935
Time taken for Epoch 3:7.36 - F1: 0.2946
2026-02-12 07:56:12 - INFO - Time taken for Epoch 3:7.36 - F1: 0.2946
Time taken for Epoch 4:7.45 - F1: 0.2958
2026-02-12 07:56:19 - INFO - Time taken for Epoch 4:7.45 - F1: 0.2958
Time taken for Epoch 5:7.23 - F1: 0.2900
2026-02-12 07:56:27 - INFO - Time taken for Epoch 5:7.23 - F1: 0.2900
Time taken for Epoch 6:1.82 - F1: 0.2882
2026-02-12 07:56:28 - INFO - Time taken for Epoch 6:1.82 - F1: 0.2882
Time taken for Epoch 7:1.82 - F1: 0.2769
2026-02-12 07:56:30 - INFO - Time taken for Epoch 7:1.82 - F1: 0.2769
Time taken for Epoch 8:1.80 - F1: 0.2703
2026-02-12 07:56:32 - INFO - Time taken for Epoch 8:1.80 - F1: 0.2703
Time taken for Epoch 9:1.80 - F1: 0.2627
2026-02-12 07:56:34 - INFO - Time taken for Epoch 9:1.80 - F1: 0.2627
Time taken for Epoch 10:1.79 - F1: 0.2554
2026-02-12 07:56:36 - INFO - Time taken for Epoch 10:1.79 - F1: 0.2554
Time taken for Epoch 11:1.79 - F1: 0.2520
2026-02-12 07:56:37 - INFO - Time taken for Epoch 11:1.79 - F1: 0.2520
Time taken for Epoch 12:1.80 - F1: 0.2483
2026-02-12 07:56:39 - INFO - Time taken for Epoch 12:1.80 - F1: 0.2483
Time taken for Epoch 13:1.82 - F1: 0.2483
2026-02-12 07:56:41 - INFO - Time taken for Epoch 13:1.82 - F1: 0.2483
Time taken for Epoch 14:1.83 - F1: 0.2476
2026-02-12 07:56:43 - INFO - Time taken for Epoch 14:1.83 - F1: 0.2476
Performance not improving for 10 consecutive epochs.
2026-02-12 07:56:43 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.2958 - Best Epoch:3
2026-02-12 07:56:43 - INFO - Best F1:0.2958 - Best Epoch:3
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.2975, Test ECE: 0.0917
2026-02-12 07:56:49 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.2975, Test ECE: 0.0917
All results: {'f1_macro': 0.29751790329931666, 'ece': 0.09169776448848464}
2026-02-12 07:56:49 - INFO - All results: {'f1_macro': 0.29751790329931666, 'ece': 0.09169776448848464}

Total time taken: 376.61 seconds
2026-02-12 07:56:49 - INFO - 
Total time taken: 376.61 seconds
2026-02-12 07:56:49 - INFO - Trial 0 finished with value: 0.29751790329931666 and parameters: {'learning_rate': 1.0084455944625857e-05, 'weight_decay': 0.00022163663318369112, 'batch_size': 8, 'co_train_epochs': 14, 'epoch_patience': 5}. Best is trial 0 with value: 0.29751790329931666.
Using devices: cuda, cuda
2026-02-12 07:56:49 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 07:56:49 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 07:56:49 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 07:56:49 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 5.73320538508271e-05
Weight Decay: 0.006187556075355219
Batch Size: 16
No. Epochs: 19
Epoch Patience: 4
 Accumulation Steps: 4
2026-02-12 07:56:49 - INFO - Learning Rate: 5.73320538508271e-05
Weight Decay: 0.006187556075355219
Batch Size: 16
No. Epochs: 19
Epoch Patience: 4
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 07:56:50 - INFO - Generating initial weights
Time taken for Epoch 1:9.15 - F1: 0.0218
2026-02-12 07:57:01 - INFO - Time taken for Epoch 1:9.15 - F1: 0.0218
Time taken for Epoch 2:9.05 - F1: 0.0218
2026-02-12 07:57:10 - INFO - Time taken for Epoch 2:9.05 - F1: 0.0218
Time taken for Epoch 3:8.95 - F1: 0.0230
2026-02-12 07:57:19 - INFO - Time taken for Epoch 3:8.95 - F1: 0.0230
Time taken for Epoch 4:9.02 - F1: 0.0318
2026-02-12 07:57:28 - INFO - Time taken for Epoch 4:9.02 - F1: 0.0318
Time taken for Epoch 5:9.00 - F1: 0.0544
2026-02-12 07:57:37 - INFO - Time taken for Epoch 5:9.00 - F1: 0.0544
Time taken for Epoch 6:8.97 - F1: 0.0571
2026-02-12 07:57:46 - INFO - Time taken for Epoch 6:8.97 - F1: 0.0571
Time taken for Epoch 7:8.98 - F1: 0.0565
2026-02-12 07:57:55 - INFO - Time taken for Epoch 7:8.98 - F1: 0.0565
Time taken for Epoch 8:8.92 - F1: 0.0596
2026-02-12 07:58:04 - INFO - Time taken for Epoch 8:8.92 - F1: 0.0596
Time taken for Epoch 9:8.91 - F1: 0.0631
2026-02-12 07:58:13 - INFO - Time taken for Epoch 9:8.91 - F1: 0.0631
Time taken for Epoch 10:8.95 - F1: 0.0656
2026-02-12 07:58:22 - INFO - Time taken for Epoch 10:8.95 - F1: 0.0656
Time taken for Epoch 11:8.96 - F1: 0.0659
2026-02-12 07:58:31 - INFO - Time taken for Epoch 11:8.96 - F1: 0.0659
Time taken for Epoch 12:9.01 - F1: 0.1127
2026-02-12 07:58:40 - INFO - Time taken for Epoch 12:9.01 - F1: 0.1127
Time taken for Epoch 13:9.04 - F1: 0.1694
2026-02-12 07:58:49 - INFO - Time taken for Epoch 13:9.04 - F1: 0.1694
Time taken for Epoch 14:9.01 - F1: 0.1765
2026-02-12 07:58:58 - INFO - Time taken for Epoch 14:9.01 - F1: 0.1765
Time taken for Epoch 15:8.91 - F1: 0.1924
2026-02-12 07:59:07 - INFO - Time taken for Epoch 15:8.91 - F1: 0.1924
Time taken for Epoch 16:9.02 - F1: 0.2040
2026-02-12 07:59:16 - INFO - Time taken for Epoch 16:9.02 - F1: 0.2040
Time taken for Epoch 17:8.96 - F1: 0.1989
2026-02-12 07:59:25 - INFO - Time taken for Epoch 17:8.96 - F1: 0.1989
Time taken for Epoch 18:8.94 - F1: 0.2059
2026-02-12 07:59:33 - INFO - Time taken for Epoch 18:8.94 - F1: 0.2059
Time taken for Epoch 19:8.96 - F1: 0.1986
2026-02-12 07:59:42 - INFO - Time taken for Epoch 19:8.96 - F1: 0.1986
Best F1:0.2059 - Best Epoch:18
2026-02-12 07:59:42 - INFO - Best F1:0.2059 - Best Epoch:18
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 07:59:44 - INFO - Starting co-training
Time taken for Epoch 1: 11.45s - F1: 0.20894063
2026-02-12 07:59:56 - INFO - Time taken for Epoch 1: 11.45s - F1: 0.20894063
Time taken for Epoch 2: 12.61s - F1: 0.30032045
2026-02-12 08:00:08 - INFO - Time taken for Epoch 2: 12.61s - F1: 0.30032045
Time taken for Epoch 3: 17.43s - F1: 0.30029532
2026-02-12 08:00:26 - INFO - Time taken for Epoch 3: 17.43s - F1: 0.30029532
Time taken for Epoch 4: 11.50s - F1: 0.30415102
2026-02-12 08:00:37 - INFO - Time taken for Epoch 4: 11.50s - F1: 0.30415102
Time taken for Epoch 5: 15.89s - F1: 0.31208438
2026-02-12 08:00:53 - INFO - Time taken for Epoch 5: 15.89s - F1: 0.31208438
Time taken for Epoch 6: 15.90s - F1: 0.30874928
2026-02-12 08:01:09 - INFO - Time taken for Epoch 6: 15.90s - F1: 0.30874928
Time taken for Epoch 7: 11.50s - F1: 0.32147506
2026-02-12 08:01:21 - INFO - Time taken for Epoch 7: 11.50s - F1: 0.32147506
Time taken for Epoch 8: 15.27s - F1: 0.33409728
2026-02-12 08:01:36 - INFO - Time taken for Epoch 8: 15.27s - F1: 0.33409728
Time taken for Epoch 9: 15.68s - F1: 0.35144244
2026-02-12 08:01:52 - INFO - Time taken for Epoch 9: 15.68s - F1: 0.35144244
Time taken for Epoch 10: 15.47s - F1: 0.38833724
2026-02-12 08:02:07 - INFO - Time taken for Epoch 10: 15.47s - F1: 0.38833724
Time taken for Epoch 11: 18.47s - F1: 0.37437599
2026-02-12 08:02:25 - INFO - Time taken for Epoch 11: 18.47s - F1: 0.37437599
Time taken for Epoch 12: 11.46s - F1: 0.43763079
2026-02-12 08:02:37 - INFO - Time taken for Epoch 12: 11.46s - F1: 0.43763079
Time taken for Epoch 13: 16.40s - F1: 0.42195289
2026-02-12 08:02:53 - INFO - Time taken for Epoch 13: 16.40s - F1: 0.42195289
Time taken for Epoch 14: 11.43s - F1: 0.38928332
2026-02-12 08:03:05 - INFO - Time taken for Epoch 14: 11.43s - F1: 0.38928332
Time taken for Epoch 15: 11.47s - F1: 0.43949365
2026-02-12 08:03:16 - INFO - Time taken for Epoch 15: 11.47s - F1: 0.43949365
Time taken for Epoch 16: 19.04s - F1: 0.45237318
2026-02-12 08:03:35 - INFO - Time taken for Epoch 16: 19.04s - F1: 0.45237318
Time taken for Epoch 17: 17.79s - F1: 0.44245398
2026-02-12 08:03:53 - INFO - Time taken for Epoch 17: 17.79s - F1: 0.44245398
Time taken for Epoch 18: 11.45s - F1: 0.42706842
2026-02-12 08:04:05 - INFO - Time taken for Epoch 18: 11.45s - F1: 0.42706842
Time taken for Epoch 19: 11.54s - F1: 0.44363436
2026-02-12 08:04:16 - INFO - Time taken for Epoch 19: 11.54s - F1: 0.44363436
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:04:19 - INFO - Fine-tuning models
Time taken for Epoch 1:1.78 - F1: 0.4582
2026-02-12 08:04:21 - INFO - Time taken for Epoch 1:1.78 - F1: 0.4582
Time taken for Epoch 2:3.02 - F1: 0.4629
2026-02-12 08:04:24 - INFO - Time taken for Epoch 2:3.02 - F1: 0.4629
Time taken for Epoch 3:18.10 - F1: 0.4821
2026-02-12 08:04:42 - INFO - Time taken for Epoch 3:18.10 - F1: 0.4821
Time taken for Epoch 4:7.38 - F1: 0.4546
2026-02-12 08:04:49 - INFO - Time taken for Epoch 4:7.38 - F1: 0.4546
Time taken for Epoch 5:1.71 - F1: 0.4417
2026-02-12 08:04:51 - INFO - Time taken for Epoch 5:1.71 - F1: 0.4417
Time taken for Epoch 6:1.71 - F1: 0.4316
2026-02-12 08:04:53 - INFO - Time taken for Epoch 6:1.71 - F1: 0.4316
Time taken for Epoch 7:1.69 - F1: 0.4256
2026-02-12 08:04:55 - INFO - Time taken for Epoch 7:1.69 - F1: 0.4256
Time taken for Epoch 8:1.69 - F1: 0.4357
2026-02-12 08:04:56 - INFO - Time taken for Epoch 8:1.69 - F1: 0.4357
Time taken for Epoch 9:1.69 - F1: 0.4361
2026-02-12 08:04:58 - INFO - Time taken for Epoch 9:1.69 - F1: 0.4361
Time taken for Epoch 10:1.69 - F1: 0.4456
2026-02-12 08:05:00 - INFO - Time taken for Epoch 10:1.69 - F1: 0.4456
Time taken for Epoch 11:1.70 - F1: 0.4467
2026-02-12 08:05:01 - INFO - Time taken for Epoch 11:1.70 - F1: 0.4467
Time taken for Epoch 12:1.71 - F1: 0.4637
2026-02-12 08:05:03 - INFO - Time taken for Epoch 12:1.71 - F1: 0.4637
Time taken for Epoch 13:1.72 - F1: 0.4642
2026-02-12 08:05:05 - INFO - Time taken for Epoch 13:1.72 - F1: 0.4642
Performance not improving for 10 consecutive epochs.
2026-02-12 08:05:05 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.4821 - Best Epoch:2
2026-02-12 08:05:05 - INFO - Best F1:0.4821 - Best Epoch:2
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.4657, Test ECE: 0.1368
2026-02-12 08:05:11 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.4657, Test ECE: 0.1368
All results: {'f1_macro': 0.46569309656363733, 'ece': 0.13680479672662102}
2026-02-12 08:05:11 - INFO - All results: {'f1_macro': 0.46569309656363733, 'ece': 0.13680479672662102}

Total time taken: 501.88 seconds
2026-02-12 08:05:11 - INFO - 
Total time taken: 501.88 seconds
2026-02-12 08:05:11 - INFO - Trial 1 finished with value: 0.46569309656363733 and parameters: {'learning_rate': 5.73320538508271e-05, 'weight_decay': 0.006187556075355219, 'batch_size': 16, 'co_train_epochs': 19, 'epoch_patience': 4}. Best is trial 1 with value: 0.46569309656363733.
Using devices: cuda, cuda
2026-02-12 08:05:11 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:05:11 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:05:11 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:05:11 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.0005595378397008414
Weight Decay: 0.0008468593122637478
Batch Size: 16
No. Epochs: 16
Epoch Patience: 3
 Accumulation Steps: 4
2026-02-12 08:05:11 - INFO - Learning Rate: 0.0005595378397008414
Weight Decay: 0.0008468593122637478
Batch Size: 16
No. Epochs: 16
Epoch Patience: 3
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:05:13 - INFO - Generating initial weights
Time taken for Epoch 1:9.05 - F1: 0.0218
2026-02-12 08:05:23 - INFO - Time taken for Epoch 1:9.05 - F1: 0.0218
Time taken for Epoch 2:8.95 - F1: 0.0645
2026-02-12 08:05:32 - INFO - Time taken for Epoch 2:8.95 - F1: 0.0645
Time taken for Epoch 3:8.94 - F1: 0.0656
2026-02-12 08:05:41 - INFO - Time taken for Epoch 3:8.94 - F1: 0.0656
Time taken for Epoch 4:8.88 - F1: 0.0477
2026-02-12 08:05:50 - INFO - Time taken for Epoch 4:8.88 - F1: 0.0477
Time taken for Epoch 5:9.09 - F1: 0.0645
2026-02-12 08:05:59 - INFO - Time taken for Epoch 5:9.09 - F1: 0.0645
Time taken for Epoch 6:9.13 - F1: 0.0643
2026-02-12 08:06:08 - INFO - Time taken for Epoch 6:9.13 - F1: 0.0643
Time taken for Epoch 7:9.20 - F1: 0.0691
2026-02-12 08:06:17 - INFO - Time taken for Epoch 7:9.20 - F1: 0.0691
Time taken for Epoch 8:8.91 - F1: 0.0218
2026-02-12 08:06:26 - INFO - Time taken for Epoch 8:8.91 - F1: 0.0218
Time taken for Epoch 9:8.95 - F1: 0.0270
2026-02-12 08:06:35 - INFO - Time taken for Epoch 9:8.95 - F1: 0.0270
Time taken for Epoch 10:9.00 - F1: 0.0218
2026-02-12 08:06:44 - INFO - Time taken for Epoch 10:9.00 - F1: 0.0218
Time taken for Epoch 11:8.90 - F1: 0.0218
2026-02-12 08:06:53 - INFO - Time taken for Epoch 11:8.90 - F1: 0.0218
Time taken for Epoch 12:8.89 - F1: 0.0218
2026-02-12 08:07:02 - INFO - Time taken for Epoch 12:8.89 - F1: 0.0218
Time taken for Epoch 13:8.95 - F1: 0.0645
2026-02-12 08:07:11 - INFO - Time taken for Epoch 13:8.95 - F1: 0.0645
Time taken for Epoch 14:8.91 - F1: 0.0645
2026-02-12 08:07:20 - INFO - Time taken for Epoch 14:8.91 - F1: 0.0645
Time taken for Epoch 15:8.88 - F1: 0.0645
2026-02-12 08:07:29 - INFO - Time taken for Epoch 15:8.88 - F1: 0.0645
Time taken for Epoch 16:8.94 - F1: 0.0645
2026-02-12 08:07:38 - INFO - Time taken for Epoch 16:8.94 - F1: 0.0645
Best F1:0.0691 - Best Epoch:7
2026-02-12 08:07:38 - INFO - Best F1:0.0691 - Best Epoch:7
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:07:39 - INFO - Starting co-training
Time taken for Epoch 1: 11.48s - F1: 0.06452703
2026-02-12 08:07:51 - INFO - Time taken for Epoch 1: 11.48s - F1: 0.06452703
Time taken for Epoch 2: 12.69s - F1: 0.06452703
2026-02-12 08:08:04 - INFO - Time taken for Epoch 2: 12.69s - F1: 0.06452703
Time taken for Epoch 3: 11.48s - F1: 0.06452703
2026-02-12 08:08:15 - INFO - Time taken for Epoch 3: 11.48s - F1: 0.06452703
Time taken for Epoch 4: 11.49s - F1: 0.06452703
2026-02-12 08:08:27 - INFO - Time taken for Epoch 4: 11.49s - F1: 0.06452703
Performance not improving for 3 consecutive epochs.
Performance not improving for 3 consecutive epochs.
2026-02-12 08:08:27 - INFO - Performance not improving for 3 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:08:29 - INFO - Fine-tuning models
Time taken for Epoch 1:1.78 - F1: 0.0645
2026-02-12 08:08:31 - INFO - Time taken for Epoch 1:1.78 - F1: 0.0645
Time taken for Epoch 2:3.03 - F1: 0.0218
2026-02-12 08:08:34 - INFO - Time taken for Epoch 2:3.03 - F1: 0.0218
Time taken for Epoch 3:1.71 - F1: 0.0218
2026-02-12 08:08:36 - INFO - Time taken for Epoch 3:1.71 - F1: 0.0218
Time taken for Epoch 4:1.73 - F1: 0.0218
2026-02-12 08:08:38 - INFO - Time taken for Epoch 4:1.73 - F1: 0.0218
Time taken for Epoch 5:1.71 - F1: 0.0218
2026-02-12 08:08:40 - INFO - Time taken for Epoch 5:1.71 - F1: 0.0218
Time taken for Epoch 6:1.71 - F1: 0.0645
2026-02-12 08:08:41 - INFO - Time taken for Epoch 6:1.71 - F1: 0.0645
Time taken for Epoch 7:1.72 - F1: 0.0645
2026-02-12 08:08:43 - INFO - Time taken for Epoch 7:1.72 - F1: 0.0645
Time taken for Epoch 8:1.72 - F1: 0.0645
2026-02-12 08:08:45 - INFO - Time taken for Epoch 8:1.72 - F1: 0.0645
Time taken for Epoch 9:1.72 - F1: 0.0645
2026-02-12 08:08:47 - INFO - Time taken for Epoch 9:1.72 - F1: 0.0645
Time taken for Epoch 10:1.71 - F1: 0.0645
2026-02-12 08:08:48 - INFO - Time taken for Epoch 10:1.71 - F1: 0.0645
Time taken for Epoch 11:1.71 - F1: 0.0645
2026-02-12 08:08:50 - INFO - Time taken for Epoch 11:1.71 - F1: 0.0645
Performance not improving for 10 consecutive epochs.
2026-02-12 08:08:50 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0645 - Best Epoch:0
2026-02-12 08:08:50 - INFO - Best F1:0.0645 - Best Epoch:0
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.0644, Test ECE: 0.1160
2026-02-12 08:08:56 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.0644, Test ECE: 0.1160
All results: {'f1_macro': 0.06440382941688425, 'ece': 0.11595182478504407}
2026-02-12 08:08:56 - INFO - All results: {'f1_macro': 0.06440382941688425, 'ece': 0.11595182478504407}

Total time taken: 225.39 seconds
2026-02-12 08:08:56 - INFO - 
Total time taken: 225.39 seconds
2026-02-12 08:08:56 - INFO - Trial 2 finished with value: 0.06440382941688425 and parameters: {'learning_rate': 0.0005595378397008414, 'weight_decay': 0.0008468593122637478, 'batch_size': 16, 'co_train_epochs': 16, 'epoch_patience': 3}. Best is trial 1 with value: 0.46569309656363733.
Using devices: cuda, cuda
2026-02-12 08:08:56 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:08:56 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:08:56 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:08:56 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 2.6996131563895056e-05
Weight Decay: 0.002562894024244702
Batch Size: 8
No. Epochs: 17
Epoch Patience: 1
 Accumulation Steps: 8
2026-02-12 08:08:57 - INFO - Learning Rate: 2.6996131563895056e-05
Weight Decay: 0.002562894024244702
Batch Size: 8
No. Epochs: 17
Epoch Patience: 1
 Accumulation Steps: 8
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:08:58 - INFO - Generating initial weights
Time taken for Epoch 1:9.77 - F1: 0.0304
2026-02-12 08:09:10 - INFO - Time taken for Epoch 1:9.77 - F1: 0.0304
Time taken for Epoch 2:9.69 - F1: 0.0518
2026-02-12 08:09:19 - INFO - Time taken for Epoch 2:9.69 - F1: 0.0518
Time taken for Epoch 3:9.75 - F1: 0.0780
2026-02-12 08:09:29 - INFO - Time taken for Epoch 3:9.75 - F1: 0.0780
Time taken for Epoch 4:9.71 - F1: 0.0990
2026-02-12 08:09:39 - INFO - Time taken for Epoch 4:9.71 - F1: 0.0990
Time taken for Epoch 5:9.67 - F1: 0.1002
2026-02-12 08:09:48 - INFO - Time taken for Epoch 5:9.67 - F1: 0.1002
Time taken for Epoch 6:9.76 - F1: 0.1018
2026-02-12 08:09:58 - INFO - Time taken for Epoch 6:9.76 - F1: 0.1018
Time taken for Epoch 7:9.74 - F1: 0.1030
2026-02-12 08:10:08 - INFO - Time taken for Epoch 7:9.74 - F1: 0.1030
Time taken for Epoch 8:9.73 - F1: 0.1057
2026-02-12 08:10:18 - INFO - Time taken for Epoch 8:9.73 - F1: 0.1057
Time taken for Epoch 9:9.71 - F1: 0.1077
2026-02-12 08:10:27 - INFO - Time taken for Epoch 9:9.71 - F1: 0.1077
Time taken for Epoch 10:9.71 - F1: 0.1070
2026-02-12 08:10:37 - INFO - Time taken for Epoch 10:9.71 - F1: 0.1070
Time taken for Epoch 11:9.69 - F1: 0.1062
2026-02-12 08:10:47 - INFO - Time taken for Epoch 11:9.69 - F1: 0.1062
Time taken for Epoch 12:9.68 - F1: 0.1091
2026-02-12 08:10:56 - INFO - Time taken for Epoch 12:9.68 - F1: 0.1091
Time taken for Epoch 13:9.73 - F1: 0.1135
2026-02-12 08:11:06 - INFO - Time taken for Epoch 13:9.73 - F1: 0.1135
Time taken for Epoch 14:9.71 - F1: 0.1242
2026-02-12 08:11:16 - INFO - Time taken for Epoch 14:9.71 - F1: 0.1242
Time taken for Epoch 15:9.69 - F1: 0.1199
2026-02-12 08:11:26 - INFO - Time taken for Epoch 15:9.69 - F1: 0.1199
Time taken for Epoch 16:9.75 - F1: 0.1275
2026-02-12 08:11:35 - INFO - Time taken for Epoch 16:9.75 - F1: 0.1275
Time taken for Epoch 17:9.74 - F1: 0.1403
2026-02-12 08:11:45 - INFO - Time taken for Epoch 17:9.74 - F1: 0.1403
Best F1:0.1403 - Best Epoch:17
2026-02-12 08:11:45 - INFO - Best F1:0.1403 - Best Epoch:17
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:11:47 - INFO - Starting co-training
Time taken for Epoch 1: 11.01s - F1: 0.06452703
2026-02-12 08:11:58 - INFO - Time taken for Epoch 1: 11.01s - F1: 0.06452703
Time taken for Epoch 2: 12.19s - F1: 0.22289059
2026-02-12 08:12:10 - INFO - Time taken for Epoch 2: 12.19s - F1: 0.22289059
Time taken for Epoch 3: 17.59s - F1: 0.21319922
2026-02-12 08:12:28 - INFO - Time taken for Epoch 3: 17.59s - F1: 0.21319922
Performance not improving for 1 consecutive epochs.
Performance not improving for 1 consecutive epochs.
2026-02-12 08:12:28 - INFO - Performance not improving for 1 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:12:31 - INFO - Fine-tuning models
Time taken for Epoch 1:1.96 - F1: 0.2219
2026-02-12 08:12:33 - INFO - Time taken for Epoch 1:1.96 - F1: 0.2219
Time taken for Epoch 2:3.02 - F1: 0.1767
2026-02-12 08:12:36 - INFO - Time taken for Epoch 2:3.02 - F1: 0.1767
Time taken for Epoch 3:1.83 - F1: 0.1225
2026-02-12 08:12:38 - INFO - Time taken for Epoch 3:1.83 - F1: 0.1225
Time taken for Epoch 4:2.01 - F1: 0.0985
2026-02-12 08:12:40 - INFO - Time taken for Epoch 4:2.01 - F1: 0.0985
Time taken for Epoch 5:1.96 - F1: 0.0989
2026-02-12 08:12:42 - INFO - Time taken for Epoch 5:1.96 - F1: 0.0989
Time taken for Epoch 6:1.90 - F1: 0.1114
2026-02-12 08:12:44 - INFO - Time taken for Epoch 6:1.90 - F1: 0.1114
Time taken for Epoch 7:1.83 - F1: 0.1281
2026-02-12 08:12:46 - INFO - Time taken for Epoch 7:1.83 - F1: 0.1281
Time taken for Epoch 8:1.88 - F1: 0.1462
2026-02-12 08:12:47 - INFO - Time taken for Epoch 8:1.88 - F1: 0.1462
Time taken for Epoch 9:1.79 - F1: 0.1948
2026-02-12 08:12:49 - INFO - Time taken for Epoch 9:1.79 - F1: 0.1948
Time taken for Epoch 10:1.89 - F1: 0.2247
2026-02-12 08:12:51 - INFO - Time taken for Epoch 10:1.89 - F1: 0.2247
Time taken for Epoch 11:5.24 - F1: 0.2255
2026-02-12 08:12:56 - INFO - Time taken for Epoch 11:5.24 - F1: 0.2255
Time taken for Epoch 12:7.46 - F1: 0.2357
2026-02-12 08:13:04 - INFO - Time taken for Epoch 12:7.46 - F1: 0.2357
Time taken for Epoch 13:7.04 - F1: 0.2368
2026-02-12 08:13:11 - INFO - Time taken for Epoch 13:7.04 - F1: 0.2368
Time taken for Epoch 14:6.37 - F1: 0.2183
2026-02-12 08:13:17 - INFO - Time taken for Epoch 14:6.37 - F1: 0.2183
Time taken for Epoch 15:1.79 - F1: 0.2335
2026-02-12 08:13:19 - INFO - Time taken for Epoch 15:1.79 - F1: 0.2335
Time taken for Epoch 16:1.81 - F1: 0.2110
2026-02-12 08:13:21 - INFO - Time taken for Epoch 16:1.81 - F1: 0.2110
Time taken for Epoch 17:1.81 - F1: 0.2060
2026-02-12 08:13:23 - INFO - Time taken for Epoch 17:1.81 - F1: 0.2060
Time taken for Epoch 18:1.83 - F1: 0.2296
2026-02-12 08:13:25 - INFO - Time taken for Epoch 18:1.83 - F1: 0.2296
Time taken for Epoch 19:1.82 - F1: 0.2255
2026-02-12 08:13:26 - INFO - Time taken for Epoch 19:1.82 - F1: 0.2255
Time taken for Epoch 20:1.79 - F1: 0.2501
2026-02-12 08:13:28 - INFO - Time taken for Epoch 20:1.79 - F1: 0.2501
Time taken for Epoch 21:7.91 - F1: 0.2640
2026-02-12 08:13:36 - INFO - Time taken for Epoch 21:7.91 - F1: 0.2640
Time taken for Epoch 22:5.63 - F1: 0.3013
2026-02-12 08:13:42 - INFO - Time taken for Epoch 22:5.63 - F1: 0.3013
Time taken for Epoch 23:5.62 - F1: 0.2982
2026-02-12 08:13:47 - INFO - Time taken for Epoch 23:5.62 - F1: 0.2982
Time taken for Epoch 24:1.81 - F1: 0.2941
2026-02-12 08:13:49 - INFO - Time taken for Epoch 24:1.81 - F1: 0.2941
Time taken for Epoch 25:1.80 - F1: 0.2828
2026-02-12 08:13:51 - INFO - Time taken for Epoch 25:1.80 - F1: 0.2828
Time taken for Epoch 26:1.94 - F1: 0.2720
2026-02-12 08:13:53 - INFO - Time taken for Epoch 26:1.94 - F1: 0.2720
Time taken for Epoch 27:1.83 - F1: 0.2688
2026-02-12 08:13:55 - INFO - Time taken for Epoch 27:1.83 - F1: 0.2688
Time taken for Epoch 28:1.80 - F1: 0.2867
2026-02-12 08:13:56 - INFO - Time taken for Epoch 28:1.80 - F1: 0.2867
Time taken for Epoch 29:1.79 - F1: 0.2933
2026-02-12 08:13:58 - INFO - Time taken for Epoch 29:1.79 - F1: 0.2933
Time taken for Epoch 30:1.79 - F1: 0.2881
2026-02-12 08:14:00 - INFO - Time taken for Epoch 30:1.79 - F1: 0.2881
Time taken for Epoch 31:1.79 - F1: 0.3006
2026-02-12 08:14:02 - INFO - Time taken for Epoch 31:1.79 - F1: 0.3006
Time taken for Epoch 32:1.81 - F1: 0.3098
2026-02-12 08:14:04 - INFO - Time taken for Epoch 32:1.81 - F1: 0.3098
Time taken for Epoch 33:7.96 - F1: 0.2820
2026-02-12 08:14:12 - INFO - Time taken for Epoch 33:7.96 - F1: 0.2820
Time taken for Epoch 34:1.79 - F1: 0.2761
2026-02-12 08:14:13 - INFO - Time taken for Epoch 34:1.79 - F1: 0.2761
Time taken for Epoch 35:1.79 - F1: 0.2966
2026-02-12 08:14:15 - INFO - Time taken for Epoch 35:1.79 - F1: 0.2966
Time taken for Epoch 36:1.79 - F1: 0.3006
2026-02-12 08:14:17 - INFO - Time taken for Epoch 36:1.79 - F1: 0.3006
Time taken for Epoch 37:1.79 - F1: 0.3066
2026-02-12 08:14:19 - INFO - Time taken for Epoch 37:1.79 - F1: 0.3066
Time taken for Epoch 38:1.80 - F1: 0.3090
2026-02-12 08:14:21 - INFO - Time taken for Epoch 38:1.80 - F1: 0.3090
Time taken for Epoch 39:1.80 - F1: 0.2998
2026-02-12 08:14:22 - INFO - Time taken for Epoch 39:1.80 - F1: 0.2998
Time taken for Epoch 40:1.80 - F1: 0.3013
2026-02-12 08:14:24 - INFO - Time taken for Epoch 40:1.80 - F1: 0.3013
Time taken for Epoch 41:1.80 - F1: 0.3049
2026-02-12 08:14:26 - INFO - Time taken for Epoch 41:1.80 - F1: 0.3049
Time taken for Epoch 42:1.79 - F1: 0.2912
2026-02-12 08:14:28 - INFO - Time taken for Epoch 42:1.79 - F1: 0.2912
Performance not improving for 10 consecutive epochs.
2026-02-12 08:14:28 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.3098 - Best Epoch:31
2026-02-12 08:14:28 - INFO - Best F1:0.3098 - Best Epoch:31
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.3094, Test ECE: 0.1432
2026-02-12 08:14:34 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.3094, Test ECE: 0.1432
All results: {'f1_macro': 0.309419857382932, 'ece': 0.14318196716525897}
2026-02-12 08:14:34 - INFO - All results: {'f1_macro': 0.309419857382932, 'ece': 0.14318196716525897}

Total time taken: 338.46 seconds
2026-02-12 08:14:34 - INFO - 
Total time taken: 338.46 seconds
2026-02-12 08:14:34 - INFO - Trial 3 finished with value: 0.309419857382932 and parameters: {'learning_rate': 2.6996131563895056e-05, 'weight_decay': 0.002562894024244702, 'batch_size': 8, 'co_train_epochs': 17, 'epoch_patience': 1}. Best is trial 1 with value: 0.46569309656363733.
Using devices: cuda, cuda
2026-02-12 08:14:34 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:14:34 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:14:34 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:14:34 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
Learning Rate: 0.0001100237976646814
Weight Decay: 5.600774647939888e-05
Batch Size: 32
No. Epochs: 16
Epoch Patience: 5
 Accumulation Steps: 2
2026-02-12 08:14:35 - INFO - Learning Rate: 0.0001100237976646814
Weight Decay: 5.600774647939888e-05
Batch Size: 32
No. Epochs: 16
Epoch Patience: 5
 Accumulation Steps: 2
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:14:37 - INFO - Generating initial weights
Time taken for Epoch 1:8.34 - F1: 0.0390
2026-02-12 08:14:46 - INFO - Time taken for Epoch 1:8.34 - F1: 0.0390
Time taken for Epoch 2:8.15 - F1: 0.0686
2026-02-12 08:14:54 - INFO - Time taken for Epoch 2:8.15 - F1: 0.0686
Time taken for Epoch 3:8.21 - F1: 0.1192
2026-02-12 08:15:03 - INFO - Time taken for Epoch 3:8.21 - F1: 0.1192
Time taken for Epoch 4:8.18 - F1: 0.1525
2026-02-12 08:15:11 - INFO - Time taken for Epoch 4:8.18 - F1: 0.1525
Time taken for Epoch 5:8.17 - F1: 0.1695
2026-02-12 08:15:19 - INFO - Time taken for Epoch 5:8.17 - F1: 0.1695
Time taken for Epoch 6:8.16 - F1: 0.1932
2026-02-12 08:15:27 - INFO - Time taken for Epoch 6:8.16 - F1: 0.1932
Time taken for Epoch 7:8.18 - F1: 0.1956
2026-02-12 08:15:35 - INFO - Time taken for Epoch 7:8.18 - F1: 0.1956
Time taken for Epoch 8:8.14 - F1: 0.1920
2026-02-12 08:15:43 - INFO - Time taken for Epoch 8:8.14 - F1: 0.1920
Time taken for Epoch 9:8.15 - F1: 0.1876
2026-02-12 08:15:52 - INFO - Time taken for Epoch 9:8.15 - F1: 0.1876
Time taken for Epoch 10:8.14 - F1: 0.1982
2026-02-12 08:16:00 - INFO - Time taken for Epoch 10:8.14 - F1: 0.1982
Time taken for Epoch 11:8.14 - F1: 0.2026
2026-02-12 08:16:08 - INFO - Time taken for Epoch 11:8.14 - F1: 0.2026
Time taken for Epoch 12:8.21 - F1: 0.2057
2026-02-12 08:16:16 - INFO - Time taken for Epoch 12:8.21 - F1: 0.2057
Time taken for Epoch 13:8.19 - F1: 0.2102
2026-02-12 08:16:24 - INFO - Time taken for Epoch 13:8.19 - F1: 0.2102
Time taken for Epoch 14:8.26 - F1: 0.2058
2026-02-12 08:16:33 - INFO - Time taken for Epoch 14:8.26 - F1: 0.2058
Time taken for Epoch 15:8.22 - F1: 0.2066
2026-02-12 08:16:41 - INFO - Time taken for Epoch 15:8.22 - F1: 0.2066
Time taken for Epoch 16:8.24 - F1: 0.2073
2026-02-12 08:16:49 - INFO - Time taken for Epoch 16:8.24 - F1: 0.2073
Best F1:0.2102 - Best Epoch:13
2026-02-12 08:16:49 - INFO - Best F1:0.2102 - Best Epoch:13
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:16:51 - INFO - Starting co-training
Time taken for Epoch 1: 13.69s - F1: 0.23286171
2026-02-12 08:17:04 - INFO - Time taken for Epoch 1: 13.69s - F1: 0.23286171
Time taken for Epoch 2: 14.67s - F1: 0.30053397
2026-02-12 08:17:19 - INFO - Time taken for Epoch 2: 14.67s - F1: 0.30053397
Time taken for Epoch 3: 19.86s - F1: 0.30672439
2026-02-12 08:17:39 - INFO - Time taken for Epoch 3: 19.86s - F1: 0.30672439
Time taken for Epoch 4: 20.22s - F1: 0.34941718
2026-02-12 08:17:59 - INFO - Time taken for Epoch 4: 20.22s - F1: 0.34941718
Time taken for Epoch 5: 20.36s - F1: 0.35040655
2026-02-12 08:18:20 - INFO - Time taken for Epoch 5: 20.36s - F1: 0.35040655
Time taken for Epoch 6: 19.35s - F1: 0.34519159
2026-02-12 08:18:39 - INFO - Time taken for Epoch 6: 19.35s - F1: 0.34519159
Time taken for Epoch 7: 13.66s - F1: 0.35345820
2026-02-12 08:18:53 - INFO - Time taken for Epoch 7: 13.66s - F1: 0.35345820
Time taken for Epoch 8: 22.42s - F1: 0.39498239
2026-02-12 08:19:15 - INFO - Time taken for Epoch 8: 22.42s - F1: 0.39498239
Time taken for Epoch 9: 20.19s - F1: 0.36494301
2026-02-12 08:19:35 - INFO - Time taken for Epoch 9: 20.19s - F1: 0.36494301
Time taken for Epoch 10: 13.65s - F1: 0.44944878
2026-02-12 08:19:49 - INFO - Time taken for Epoch 10: 13.65s - F1: 0.44944878
Time taken for Epoch 11: 52.74s - F1: 0.41223104
2026-02-12 08:20:42 - INFO - Time taken for Epoch 11: 52.74s - F1: 0.41223104
Time taken for Epoch 12: 13.65s - F1: 0.44530504
2026-02-12 08:20:55 - INFO - Time taken for Epoch 12: 13.65s - F1: 0.44530504
Time taken for Epoch 13: 13.64s - F1: 0.43929217
2026-02-12 08:21:09 - INFO - Time taken for Epoch 13: 13.64s - F1: 0.43929217
Time taken for Epoch 14: 13.66s - F1: 0.45226846
2026-02-12 08:21:23 - INFO - Time taken for Epoch 14: 13.66s - F1: 0.45226846
Time taken for Epoch 15: 21.37s - F1: 0.41681107
2026-02-12 08:21:44 - INFO - Time taken for Epoch 15: 21.37s - F1: 0.41681107
Time taken for Epoch 16: 13.62s - F1: 0.44339303
2026-02-12 08:21:58 - INFO - Time taken for Epoch 16: 13.62s - F1: 0.44339303
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:22:00 - INFO - Fine-tuning models
Time taken for Epoch 1:1.67 - F1: 0.4843
2026-02-12 08:22:02 - INFO - Time taken for Epoch 1:1.67 - F1: 0.4843
Time taken for Epoch 2:2.51 - F1: 0.4874
2026-02-12 08:22:05 - INFO - Time taken for Epoch 2:2.51 - F1: 0.4874
Time taken for Epoch 3:9.44 - F1: 0.4316
2026-02-12 08:22:14 - INFO - Time taken for Epoch 3:9.44 - F1: 0.4316
Time taken for Epoch 4:1.56 - F1: 0.4811
2026-02-12 08:22:16 - INFO - Time taken for Epoch 4:1.56 - F1: 0.4811
Time taken for Epoch 5:1.56 - F1: 0.4717
2026-02-12 08:22:17 - INFO - Time taken for Epoch 5:1.56 - F1: 0.4717
Time taken for Epoch 6:1.56 - F1: 0.4596
2026-02-12 08:22:19 - INFO - Time taken for Epoch 6:1.56 - F1: 0.4596
Time taken for Epoch 7:1.56 - F1: 0.4719
2026-02-12 08:22:20 - INFO - Time taken for Epoch 7:1.56 - F1: 0.4719
Time taken for Epoch 8:1.55 - F1: 0.4801
2026-02-12 08:22:22 - INFO - Time taken for Epoch 8:1.55 - F1: 0.4801
Time taken for Epoch 9:1.55 - F1: 0.4840
2026-02-12 08:22:23 - INFO - Time taken for Epoch 9:1.55 - F1: 0.4840
Time taken for Epoch 10:1.55 - F1: 0.4748
2026-02-12 08:22:25 - INFO - Time taken for Epoch 10:1.55 - F1: 0.4748
Time taken for Epoch 11:1.55 - F1: 0.4955
2026-02-12 08:22:26 - INFO - Time taken for Epoch 11:1.55 - F1: 0.4955
Time taken for Epoch 12:7.69 - F1: 0.5017
2026-02-12 08:22:34 - INFO - Time taken for Epoch 12:7.69 - F1: 0.5017
Time taken for Epoch 13:8.37 - F1: 0.5112
2026-02-12 08:22:42 - INFO - Time taken for Epoch 13:8.37 - F1: 0.5112
Time taken for Epoch 14:8.83 - F1: 0.5070
2026-02-12 08:22:51 - INFO - Time taken for Epoch 14:8.83 - F1: 0.5070
Time taken for Epoch 15:1.58 - F1: 0.5067
2026-02-12 08:22:53 - INFO - Time taken for Epoch 15:1.58 - F1: 0.5067
Time taken for Epoch 16:1.59 - F1: 0.5036
2026-02-12 08:22:54 - INFO - Time taken for Epoch 16:1.59 - F1: 0.5036
Time taken for Epoch 17:1.56 - F1: 0.4832
2026-02-12 08:22:56 - INFO - Time taken for Epoch 17:1.56 - F1: 0.4832
Time taken for Epoch 18:1.55 - F1: 0.4765
2026-02-12 08:22:58 - INFO - Time taken for Epoch 18:1.55 - F1: 0.4765
Time taken for Epoch 19:1.55 - F1: 0.4724
2026-02-12 08:22:59 - INFO - Time taken for Epoch 19:1.55 - F1: 0.4724
Time taken for Epoch 20:1.55 - F1: 0.4825
2026-02-12 08:23:01 - INFO - Time taken for Epoch 20:1.55 - F1: 0.4825
Time taken for Epoch 21:1.55 - F1: 0.4808
2026-02-12 08:23:02 - INFO - Time taken for Epoch 21:1.55 - F1: 0.4808
Time taken for Epoch 22:1.54 - F1: 0.4830
2026-02-12 08:23:04 - INFO - Time taken for Epoch 22:1.54 - F1: 0.4830
Time taken for Epoch 23:1.54 - F1: 0.4825
2026-02-12 08:23:05 - INFO - Time taken for Epoch 23:1.54 - F1: 0.4825
Performance not improving for 10 consecutive epochs.
2026-02-12 08:23:05 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.5112 - Best Epoch:12
2026-02-12 08:23:05 - INFO - Best F1:0.5112 - Best Epoch:12
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.5570, Test ECE: 0.1309
2026-02-12 08:23:10 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.5570, Test ECE: 0.1309
All results: {'f1_macro': 0.5570103374065091, 'ece': 0.13094418762737126}
2026-02-12 08:23:10 - INFO - All results: {'f1_macro': 0.5570103374065091, 'ece': 0.13094418762737126}

Total time taken: 515.80 seconds
2026-02-12 08:23:10 - INFO - 
Total time taken: 515.80 seconds
2026-02-12 08:23:10 - INFO - Trial 4 finished with value: 0.5570103374065091 and parameters: {'learning_rate': 0.0001100237976646814, 'weight_decay': 5.600774647939888e-05, 'batch_size': 32, 'co_train_epochs': 16, 'epoch_patience': 5}. Best is trial 4 with value: 0.5570103374065091.
Using devices: cuda, cuda
2026-02-12 08:23:10 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:23:10 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:23:10 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:23:10 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
Learning Rate: 0.0003386107300246221
Weight Decay: 0.005053663030270446
Batch Size: 8
No. Epochs: 5
Epoch Patience: 5
 Accumulation Steps: 8
2026-02-12 08:23:11 - INFO - Learning Rate: 0.0003386107300246221
Weight Decay: 0.005053663030270446
Batch Size: 8
No. Epochs: 5
Epoch Patience: 5
 Accumulation Steps: 8
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:23:12 - INFO - Generating initial weights
Time taken for Epoch 1:9.81 - F1: 0.0214
2026-02-12 08:23:23 - INFO - Time taken for Epoch 1:9.81 - F1: 0.0214
Time taken for Epoch 2:9.66 - F1: 0.0356
2026-02-12 08:23:33 - INFO - Time taken for Epoch 2:9.66 - F1: 0.0356
Time taken for Epoch 3:9.70 - F1: 0.0673
2026-02-12 08:23:43 - INFO - Time taken for Epoch 3:9.70 - F1: 0.0673
Time taken for Epoch 4:9.71 - F1: 0.1033
2026-02-12 08:23:52 - INFO - Time taken for Epoch 4:9.71 - F1: 0.1033
Time taken for Epoch 5:9.69 - F1: 0.1081
2026-02-12 08:24:02 - INFO - Time taken for Epoch 5:9.69 - F1: 0.1081
Best F1:0.1081 - Best Epoch:5
2026-02-12 08:24:02 - INFO - Best F1:0.1081 - Best Epoch:5
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:24:03 - INFO - Starting co-training
Time taken for Epoch 1: 10.89s - F1: 0.01977528
2026-02-12 08:24:15 - INFO - Time taken for Epoch 1: 10.89s - F1: 0.01977528
Time taken for Epoch 2: 11.78s - F1: 0.01977528
2026-02-12 08:24:26 - INFO - Time taken for Epoch 2: 11.78s - F1: 0.01977528
Time taken for Epoch 3: 10.91s - F1: 0.01977528
2026-02-12 08:24:37 - INFO - Time taken for Epoch 3: 10.91s - F1: 0.01977528
Time taken for Epoch 4: 10.97s - F1: 0.06452703
2026-02-12 08:24:48 - INFO - Time taken for Epoch 4: 10.97s - F1: 0.06452703
Time taken for Epoch 5: 16.40s - F1: 0.06452703
2026-02-12 08:25:05 - INFO - Time taken for Epoch 5: 16.40s - F1: 0.06452703
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:25:07 - INFO - Fine-tuning models
Time taken for Epoch 1:1.82 - F1: 0.0645
2026-02-12 08:25:09 - INFO - Time taken for Epoch 1:1.82 - F1: 0.0645
Time taken for Epoch 2:2.83 - F1: 0.0645
2026-02-12 08:25:12 - INFO - Time taken for Epoch 2:2.83 - F1: 0.0645
Time taken for Epoch 3:1.79 - F1: 0.0198
2026-02-12 08:25:14 - INFO - Time taken for Epoch 3:1.79 - F1: 0.0198
Time taken for Epoch 4:1.79 - F1: 0.0214
2026-02-12 08:25:16 - INFO - Time taken for Epoch 4:1.79 - F1: 0.0214
Time taken for Epoch 5:1.79 - F1: 0.0010
2026-02-12 08:25:17 - INFO - Time taken for Epoch 5:1.79 - F1: 0.0010
Time taken for Epoch 6:1.80 - F1: 0.0010
2026-02-12 08:25:19 - INFO - Time taken for Epoch 6:1.80 - F1: 0.0010
Time taken for Epoch 7:1.83 - F1: 0.0010
2026-02-12 08:25:21 - INFO - Time taken for Epoch 7:1.83 - F1: 0.0010
Time taken for Epoch 8:1.79 - F1: 0.0010
2026-02-12 08:25:23 - INFO - Time taken for Epoch 8:1.79 - F1: 0.0010
Time taken for Epoch 9:1.79 - F1: 0.0029
2026-02-12 08:25:25 - INFO - Time taken for Epoch 9:1.79 - F1: 0.0029
Time taken for Epoch 10:1.79 - F1: 0.0029
2026-02-12 08:25:26 - INFO - Time taken for Epoch 10:1.79 - F1: 0.0029
Time taken for Epoch 11:1.81 - F1: 0.0029
2026-02-12 08:25:28 - INFO - Time taken for Epoch 11:1.81 - F1: 0.0029
Performance not improving for 10 consecutive epochs.
2026-02-12 08:25:28 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0645 - Best Epoch:0
2026-02-12 08:25:28 - INFO - Best F1:0.0645 - Best Epoch:0
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.0644, Test ECE: 0.0980
2026-02-12 08:25:35 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.0644, Test ECE: 0.0980
All results: {'f1_macro': 0.06440382941688425, 'ece': 0.09804712058031817}
2026-02-12 08:25:35 - INFO - All results: {'f1_macro': 0.06440382941688425, 'ece': 0.09804712058031817}

Total time taken: 144.71 seconds
2026-02-12 08:25:35 - INFO - 
Total time taken: 144.71 seconds
2026-02-12 08:25:35 - INFO - Trial 5 finished with value: 0.06440382941688425 and parameters: {'learning_rate': 0.0003386107300246221, 'weight_decay': 0.005053663030270446, 'batch_size': 8, 'co_train_epochs': 5, 'epoch_patience': 5}. Best is trial 4 with value: 0.5570103374065091.
Using devices: cuda, cuda
2026-02-12 08:25:35 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:25:35 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:25:35 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:25:35 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 1.611088355656026e-05
Weight Decay: 2.375568346227297e-05
Batch Size: 16
No. Epochs: 20
Epoch Patience: 5
 Accumulation Steps: 4
2026-02-12 08:25:36 - INFO - Learning Rate: 1.611088355656026e-05
Weight Decay: 2.375568346227297e-05
Batch Size: 16
No. Epochs: 20
Epoch Patience: 5
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:25:37 - INFO - Generating initial weights
Time taken for Epoch 1:9.06 - F1: 0.0473
2026-02-12 08:25:47 - INFO - Time taken for Epoch 1:9.06 - F1: 0.0473
Time taken for Epoch 2:9.02 - F1: 0.0381
2026-02-12 08:25:56 - INFO - Time taken for Epoch 2:9.02 - F1: 0.0381
Time taken for Epoch 3:9.00 - F1: 0.0218
2026-02-12 08:26:05 - INFO - Time taken for Epoch 3:9.00 - F1: 0.0218
Time taken for Epoch 4:8.98 - F1: 0.0218
2026-02-12 08:26:14 - INFO - Time taken for Epoch 4:8.98 - F1: 0.0218
Time taken for Epoch 5:9.00 - F1: 0.0218
2026-02-12 08:26:23 - INFO - Time taken for Epoch 5:9.00 - F1: 0.0218
Time taken for Epoch 6:9.00 - F1: 0.0218
2026-02-12 08:26:32 - INFO - Time taken for Epoch 6:9.00 - F1: 0.0218
Time taken for Epoch 7:8.97 - F1: 0.0218
2026-02-12 08:26:41 - INFO - Time taken for Epoch 7:8.97 - F1: 0.0218
Time taken for Epoch 8:9.02 - F1: 0.0229
2026-02-12 08:26:50 - INFO - Time taken for Epoch 8:9.02 - F1: 0.0229
Time taken for Epoch 9:8.99 - F1: 0.0229
2026-02-12 08:26:59 - INFO - Time taken for Epoch 9:8.99 - F1: 0.0229
Time taken for Epoch 10:8.98 - F1: 0.0230
2026-02-12 08:27:08 - INFO - Time taken for Epoch 10:8.98 - F1: 0.0230
Time taken for Epoch 11:9.00 - F1: 0.0251
2026-02-12 08:27:17 - INFO - Time taken for Epoch 11:9.00 - F1: 0.0251
Time taken for Epoch 12:8.96 - F1: 0.0278
2026-02-12 08:27:26 - INFO - Time taken for Epoch 12:8.96 - F1: 0.0278
Time taken for Epoch 13:9.02 - F1: 0.0318
2026-02-12 08:27:35 - INFO - Time taken for Epoch 13:9.02 - F1: 0.0318
Time taken for Epoch 14:9.01 - F1: 0.0362
2026-02-12 08:27:44 - INFO - Time taken for Epoch 14:9.01 - F1: 0.0362
Time taken for Epoch 15:8.98 - F1: 0.0435
2026-02-12 08:27:53 - INFO - Time taken for Epoch 15:8.98 - F1: 0.0435
Time taken for Epoch 16:9.01 - F1: 0.0487
2026-02-12 08:28:02 - INFO - Time taken for Epoch 16:9.01 - F1: 0.0487
Time taken for Epoch 17:9.01 - F1: 0.0539
2026-02-12 08:28:11 - INFO - Time taken for Epoch 17:9.01 - F1: 0.0539
Time taken for Epoch 18:8.99 - F1: 0.0579
2026-02-12 08:28:20 - INFO - Time taken for Epoch 18:8.99 - F1: 0.0579
Time taken for Epoch 19:9.03 - F1: 0.0602
2026-02-12 08:28:29 - INFO - Time taken for Epoch 19:9.03 - F1: 0.0602
Time taken for Epoch 20:9.01 - F1: 0.0636
2026-02-12 08:28:38 - INFO - Time taken for Epoch 20:9.01 - F1: 0.0636
Best F1:0.0636 - Best Epoch:20
2026-02-12 08:28:38 - INFO - Best F1:0.0636 - Best Epoch:20
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:28:40 - INFO - Starting co-training
Time taken for Epoch 1: 11.48s - F1: 0.06452703
2026-02-12 08:28:51 - INFO - Time taken for Epoch 1: 11.48s - F1: 0.06452703
Time taken for Epoch 2: 12.48s - F1: 0.13783107
2026-02-12 08:29:04 - INFO - Time taken for Epoch 2: 12.48s - F1: 0.13783107
Time taken for Epoch 3: 16.54s - F1: 0.21717331
2026-02-12 08:29:20 - INFO - Time taken for Epoch 3: 16.54s - F1: 0.21717331
Time taken for Epoch 4: 15.05s - F1: 0.21512088
2026-02-12 08:29:35 - INFO - Time taken for Epoch 4: 15.05s - F1: 0.21512088
Time taken for Epoch 5: 11.49s - F1: 0.22707571
2026-02-12 08:29:47 - INFO - Time taken for Epoch 5: 11.49s - F1: 0.22707571
Time taken for Epoch 6: 15.12s - F1: 0.29786125
2026-02-12 08:30:02 - INFO - Time taken for Epoch 6: 15.12s - F1: 0.29786125
Time taken for Epoch 7: 15.31s - F1: 0.29432772
2026-02-12 08:30:17 - INFO - Time taken for Epoch 7: 15.31s - F1: 0.29432772
Time taken for Epoch 8: 11.47s - F1: 0.30586422
2026-02-12 08:30:29 - INFO - Time taken for Epoch 8: 11.47s - F1: 0.30586422
Time taken for Epoch 9: 17.48s - F1: 0.30169249
2026-02-12 08:30:46 - INFO - Time taken for Epoch 9: 17.48s - F1: 0.30169249
Time taken for Epoch 10: 11.51s - F1: 0.31146218
2026-02-12 08:30:58 - INFO - Time taken for Epoch 10: 11.51s - F1: 0.31146218
Time taken for Epoch 11: 27.98s - F1: 0.30145310
2026-02-12 08:31:26 - INFO - Time taken for Epoch 11: 27.98s - F1: 0.30145310
Time taken for Epoch 12: 11.48s - F1: 0.34367635
2026-02-12 08:31:37 - INFO - Time taken for Epoch 12: 11.48s - F1: 0.34367635
Time taken for Epoch 13: 12.72s - F1: 0.33789289
2026-02-12 08:31:50 - INFO - Time taken for Epoch 13: 12.72s - F1: 0.33789289
Time taken for Epoch 14: 11.46s - F1: 0.36175715
2026-02-12 08:32:01 - INFO - Time taken for Epoch 14: 11.46s - F1: 0.36175715
Time taken for Epoch 15: 19.18s - F1: 0.37376981
2026-02-12 08:32:21 - INFO - Time taken for Epoch 15: 19.18s - F1: 0.37376981
Time taken for Epoch 16: 17.80s - F1: 0.39040754
2026-02-12 08:32:38 - INFO - Time taken for Epoch 16: 17.80s - F1: 0.39040754
Time taken for Epoch 17: 17.17s - F1: 0.39973709
2026-02-12 08:32:56 - INFO - Time taken for Epoch 17: 17.17s - F1: 0.39973709
Time taken for Epoch 18: 15.82s - F1: 0.39566539
2026-02-12 08:33:11 - INFO - Time taken for Epoch 18: 15.82s - F1: 0.39566539
Time taken for Epoch 19: 11.43s - F1: 0.41459077
2026-02-12 08:33:23 - INFO - Time taken for Epoch 19: 11.43s - F1: 0.41459077
Time taken for Epoch 20: 15.50s - F1: 0.40903958
2026-02-12 08:33:38 - INFO - Time taken for Epoch 20: 15.50s - F1: 0.40903958
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:33:41 - INFO - Fine-tuning models
Time taken for Epoch 1:1.74 - F1: 0.4304
2026-02-12 08:33:43 - INFO - Time taken for Epoch 1:1.74 - F1: 0.4304
Time taken for Epoch 2:2.73 - F1: 0.4639
2026-02-12 08:33:46 - INFO - Time taken for Epoch 2:2.73 - F1: 0.4639
Time taken for Epoch 3:5.32 - F1: 0.4514
2026-02-12 08:33:51 - INFO - Time taken for Epoch 3:5.32 - F1: 0.4514
Time taken for Epoch 4:1.69 - F1: 0.4479
2026-02-12 08:33:53 - INFO - Time taken for Epoch 4:1.69 - F1: 0.4479
Time taken for Epoch 5:1.70 - F1: 0.4437
2026-02-12 08:33:55 - INFO - Time taken for Epoch 5:1.70 - F1: 0.4437
Time taken for Epoch 6:1.71 - F1: 0.4231
2026-02-12 08:33:56 - INFO - Time taken for Epoch 6:1.71 - F1: 0.4231
Time taken for Epoch 7:1.71 - F1: 0.4059
2026-02-12 08:33:58 - INFO - Time taken for Epoch 7:1.71 - F1: 0.4059
Time taken for Epoch 8:1.72 - F1: 0.4029
2026-02-12 08:34:00 - INFO - Time taken for Epoch 8:1.72 - F1: 0.4029
Time taken for Epoch 9:1.70 - F1: 0.4043
2026-02-12 08:34:01 - INFO - Time taken for Epoch 9:1.70 - F1: 0.4043
Time taken for Epoch 10:1.70 - F1: 0.4159
2026-02-12 08:34:03 - INFO - Time taken for Epoch 10:1.70 - F1: 0.4159
Time taken for Epoch 11:1.71 - F1: 0.4063
2026-02-12 08:34:05 - INFO - Time taken for Epoch 11:1.71 - F1: 0.4063
Time taken for Epoch 12:1.70 - F1: 0.4106
2026-02-12 08:34:07 - INFO - Time taken for Epoch 12:1.70 - F1: 0.4106
Performance not improving for 10 consecutive epochs.
2026-02-12 08:34:07 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.4639 - Best Epoch:1
2026-02-12 08:34:07 - INFO - Best F1:0.4639 - Best Epoch:1
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.4669, Test ECE: 0.0454
2026-02-12 08:34:12 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.4669, Test ECE: 0.0454
All results: {'f1_macro': 0.4668612716631954, 'ece': 0.04541125074889754}
2026-02-12 08:34:12 - INFO - All results: {'f1_macro': 0.4668612716631954, 'ece': 0.04541125074889754}

Total time taken: 517.40 seconds
2026-02-12 08:34:12 - INFO - 
Total time taken: 517.40 seconds
2026-02-12 08:34:12 - INFO - Trial 6 finished with value: 0.4668612716631954 and parameters: {'learning_rate': 1.611088355656026e-05, 'weight_decay': 2.375568346227297e-05, 'batch_size': 16, 'co_train_epochs': 20, 'epoch_patience': 5}. Best is trial 4 with value: 0.5570103374065091.
Using devices: cuda, cuda
2026-02-12 08:34:12 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:34:12 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:34:12 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:34:12 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 2.532893888492756e-05
Weight Decay: 2.663520369965658e-05
Batch Size: 16
No. Epochs: 12
Epoch Patience: 10
 Accumulation Steps: 4
2026-02-12 08:34:13 - INFO - Learning Rate: 2.532893888492756e-05
Weight Decay: 2.663520369965658e-05
Batch Size: 16
No. Epochs: 12
Epoch Patience: 10
 Accumulation Steps: 4
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:34:14 - INFO - Generating initial weights
Time taken for Epoch 1:9.04 - F1: 0.0413
2026-02-12 08:34:25 - INFO - Time taken for Epoch 1:9.04 - F1: 0.0413
Time taken for Epoch 2:9.03 - F1: 0.0218
2026-02-12 08:34:34 - INFO - Time taken for Epoch 2:9.03 - F1: 0.0218
Time taken for Epoch 3:9.01 - F1: 0.0218
2026-02-12 08:34:43 - INFO - Time taken for Epoch 3:9.01 - F1: 0.0218
Time taken for Epoch 4:8.97 - F1: 0.0218
2026-02-12 08:34:52 - INFO - Time taken for Epoch 4:8.97 - F1: 0.0218
Time taken for Epoch 5:8.98 - F1: 0.0229
2026-02-12 08:35:01 - INFO - Time taken for Epoch 5:8.98 - F1: 0.0229
Time taken for Epoch 6:8.98 - F1: 0.0230
2026-02-12 08:35:10 - INFO - Time taken for Epoch 6:8.98 - F1: 0.0230
Time taken for Epoch 7:8.95 - F1: 0.0241
2026-02-12 08:35:19 - INFO - Time taken for Epoch 7:8.95 - F1: 0.0241
Time taken for Epoch 8:9.00 - F1: 0.0304
2026-02-12 08:35:28 - INFO - Time taken for Epoch 8:9.00 - F1: 0.0304
Time taken for Epoch 9:8.96 - F1: 0.0345
2026-02-12 08:35:37 - INFO - Time taken for Epoch 9:8.96 - F1: 0.0345
Time taken for Epoch 10:9.04 - F1: 0.0419
2026-02-12 08:35:46 - INFO - Time taken for Epoch 10:9.04 - F1: 0.0419
Time taken for Epoch 11:8.98 - F1: 0.0474
2026-02-12 08:35:55 - INFO - Time taken for Epoch 11:8.98 - F1: 0.0474
Time taken for Epoch 12:8.98 - F1: 0.0532
2026-02-12 08:36:04 - INFO - Time taken for Epoch 12:8.98 - F1: 0.0532
Best F1:0.0532 - Best Epoch:12
2026-02-12 08:36:04 - INFO - Best F1:0.0532 - Best Epoch:12
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:36:05 - INFO - Starting co-training
Time taken for Epoch 1: 11.47s - F1: 0.06452703
2026-02-12 08:36:17 - INFO - Time taken for Epoch 1: 11.47s - F1: 0.06452703
Time taken for Epoch 2: 12.55s - F1: 0.22254880
2026-02-12 08:36:29 - INFO - Time taken for Epoch 2: 12.55s - F1: 0.22254880
Time taken for Epoch 3: 18.74s - F1: 0.21792775
2026-02-12 08:36:48 - INFO - Time taken for Epoch 3: 18.74s - F1: 0.21792775
Time taken for Epoch 4: 11.48s - F1: 0.22321268
2026-02-12 08:37:00 - INFO - Time taken for Epoch 4: 11.48s - F1: 0.22321268
Time taken for Epoch 5: 28.57s - F1: 0.30359279
2026-02-12 08:37:28 - INFO - Time taken for Epoch 5: 28.57s - F1: 0.30359279
Time taken for Epoch 6: 15.35s - F1: 0.30487332
2026-02-12 08:37:44 - INFO - Time taken for Epoch 6: 15.35s - F1: 0.30487332
Time taken for Epoch 7: 15.24s - F1: 0.30196718
2026-02-12 08:37:59 - INFO - Time taken for Epoch 7: 15.24s - F1: 0.30196718
Time taken for Epoch 8: 11.49s - F1: 0.30288745
2026-02-12 08:38:10 - INFO - Time taken for Epoch 8: 11.49s - F1: 0.30288745
Time taken for Epoch 9: 11.48s - F1: 0.33397816
2026-02-12 08:38:22 - INFO - Time taken for Epoch 9: 11.48s - F1: 0.33397816
Time taken for Epoch 10: 16.76s - F1: 0.34734484
2026-02-12 08:38:38 - INFO - Time taken for Epoch 10: 16.76s - F1: 0.34734484
Time taken for Epoch 11: 16.54s - F1: 0.36684566
2026-02-12 08:38:55 - INFO - Time taken for Epoch 11: 16.54s - F1: 0.36684566
Time taken for Epoch 12: 17.22s - F1: 0.39047669
2026-02-12 08:39:12 - INFO - Time taken for Epoch 12: 17.22s - F1: 0.39047669
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:39:20 - INFO - Fine-tuning models
Time taken for Epoch 1:1.74 - F1: 0.3831
2026-02-12 08:39:22 - INFO - Time taken for Epoch 1:1.74 - F1: 0.3831
Time taken for Epoch 2:2.67 - F1: 0.4092
2026-02-12 08:39:25 - INFO - Time taken for Epoch 2:2.67 - F1: 0.4092
Time taken for Epoch 3:9.63 - F1: 0.4638
2026-02-12 08:39:34 - INFO - Time taken for Epoch 3:9.63 - F1: 0.4638
Time taken for Epoch 4:8.73 - F1: 0.4579
2026-02-12 08:39:43 - INFO - Time taken for Epoch 4:8.73 - F1: 0.4579
Time taken for Epoch 5:1.69 - F1: 0.4726
2026-02-12 08:39:45 - INFO - Time taken for Epoch 5:1.69 - F1: 0.4726
Time taken for Epoch 6:8.90 - F1: 0.4592
2026-02-12 08:39:54 - INFO - Time taken for Epoch 6:8.90 - F1: 0.4592
Time taken for Epoch 7:1.71 - F1: 0.4590
2026-02-12 08:39:55 - INFO - Time taken for Epoch 7:1.71 - F1: 0.4590
Time taken for Epoch 8:1.70 - F1: 0.4304
2026-02-12 08:39:57 - INFO - Time taken for Epoch 8:1.70 - F1: 0.4304
Time taken for Epoch 9:1.70 - F1: 0.4268
2026-02-12 08:39:59 - INFO - Time taken for Epoch 9:1.70 - F1: 0.4268
Time taken for Epoch 10:1.71 - F1: 0.4290
2026-02-12 08:40:01 - INFO - Time taken for Epoch 10:1.71 - F1: 0.4290
Time taken for Epoch 11:1.70 - F1: 0.4301
2026-02-12 08:40:02 - INFO - Time taken for Epoch 11:1.70 - F1: 0.4301
Time taken for Epoch 12:1.69 - F1: 0.4383
2026-02-12 08:40:04 - INFO - Time taken for Epoch 12:1.69 - F1: 0.4383
Time taken for Epoch 13:1.70 - F1: 0.4466
2026-02-12 08:40:06 - INFO - Time taken for Epoch 13:1.70 - F1: 0.4466
Time taken for Epoch 14:1.71 - F1: 0.4356
2026-02-12 08:40:07 - INFO - Time taken for Epoch 14:1.71 - F1: 0.4356
Time taken for Epoch 15:1.71 - F1: 0.4387
2026-02-12 08:40:09 - INFO - Time taken for Epoch 15:1.71 - F1: 0.4387
Performance not improving for 10 consecutive epochs.
2026-02-12 08:40:09 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.4726 - Best Epoch:4
2026-02-12 08:40:09 - INFO - Best F1:0.4726 - Best Epoch:4
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.4488, Test ECE: 0.0969
2026-02-12 08:40:15 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.4488, Test ECE: 0.0969
All results: {'f1_macro': 0.44879335074866306, 'ece': 0.09691789872533091}
2026-02-12 08:40:15 - INFO - All results: {'f1_macro': 0.44879335074866306, 'ece': 0.09691789872533091}

Total time taken: 362.87 seconds
2026-02-12 08:40:15 - INFO - 
Total time taken: 362.87 seconds
2026-02-12 08:40:15 - INFO - Trial 7 finished with value: 0.44879335074866306 and parameters: {'learning_rate': 2.532893888492756e-05, 'weight_decay': 2.663520369965658e-05, 'batch_size': 16, 'co_train_epochs': 12, 'epoch_patience': 10}. Best is trial 4 with value: 0.5570103374065091.
Using devices: cuda, cuda
2026-02-12 08:40:15 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:40:15 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:40:15 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:40:15 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.0002023610557470539
Weight Decay: 0.0006033036248342923
Batch Size: 8
No. Epochs: 12
Epoch Patience: 10
 Accumulation Steps: 8
2026-02-12 08:40:16 - INFO - Learning Rate: 0.0002023610557470539
Weight Decay: 0.0006033036248342923
Batch Size: 8
No. Epochs: 12
Epoch Patience: 10
 Accumulation Steps: 8
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:40:17 - INFO - Generating initial weights
Time taken for Epoch 1:9.89 - F1: 0.0343
2026-02-12 08:40:29 - INFO - Time taken for Epoch 1:9.89 - F1: 0.0343
Time taken for Epoch 2:9.73 - F1: 0.0864
2026-02-12 08:40:38 - INFO - Time taken for Epoch 2:9.73 - F1: 0.0864
Time taken for Epoch 3:9.70 - F1: 0.0807
2026-02-12 08:40:48 - INFO - Time taken for Epoch 3:9.70 - F1: 0.0807
Time taken for Epoch 4:9.75 - F1: 0.1594
2026-02-12 08:40:58 - INFO - Time taken for Epoch 4:9.75 - F1: 0.1594
Time taken for Epoch 5:9.75 - F1: 0.1950
2026-02-12 08:41:08 - INFO - Time taken for Epoch 5:9.75 - F1: 0.1950
Time taken for Epoch 6:9.73 - F1: 0.2047
2026-02-12 08:41:17 - INFO - Time taken for Epoch 6:9.73 - F1: 0.2047
Time taken for Epoch 7:9.66 - F1: 0.1921
2026-02-12 08:41:27 - INFO - Time taken for Epoch 7:9.66 - F1: 0.1921
Time taken for Epoch 8:9.73 - F1: 0.2039
2026-02-12 08:41:37 - INFO - Time taken for Epoch 8:9.73 - F1: 0.2039
Time taken for Epoch 9:9.72 - F1: 0.2161
2026-02-12 08:41:46 - INFO - Time taken for Epoch 9:9.72 - F1: 0.2161
Time taken for Epoch 10:9.69 - F1: 0.2090
2026-02-12 08:41:56 - INFO - Time taken for Epoch 10:9.69 - F1: 0.2090
Time taken for Epoch 11:9.74 - F1: 0.2085
2026-02-12 08:42:06 - INFO - Time taken for Epoch 11:9.74 - F1: 0.2085
Time taken for Epoch 12:9.74 - F1: 0.2056
2026-02-12 08:42:16 - INFO - Time taken for Epoch 12:9.74 - F1: 0.2056
Best F1:0.2161 - Best Epoch:9
2026-02-12 08:42:16 - INFO - Best F1:0.2161 - Best Epoch:9
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:42:17 - INFO - Starting co-training
Time taken for Epoch 1: 10.92s - F1: 0.14554693
2026-02-12 08:42:28 - INFO - Time taken for Epoch 1: 10.92s - F1: 0.14554693
Time taken for Epoch 2: 11.98s - F1: 0.06452703
2026-02-12 08:42:40 - INFO - Time taken for Epoch 2: 11.98s - F1: 0.06452703
Time taken for Epoch 3: 10.79s - F1: 0.06452703
2026-02-12 08:42:51 - INFO - Time taken for Epoch 3: 10.79s - F1: 0.06452703
Time taken for Epoch 4: 10.86s - F1: 0.06452703
2026-02-12 08:43:01 - INFO - Time taken for Epoch 4: 10.86s - F1: 0.06452703
Time taken for Epoch 5: 10.84s - F1: 0.06452703
2026-02-12 08:43:12 - INFO - Time taken for Epoch 5: 10.84s - F1: 0.06452703
Time taken for Epoch 6: 10.81s - F1: 0.06452703
2026-02-12 08:43:23 - INFO - Time taken for Epoch 6: 10.81s - F1: 0.06452703
Time taken for Epoch 7: 10.77s - F1: 0.06452703
2026-02-12 08:43:34 - INFO - Time taken for Epoch 7: 10.77s - F1: 0.06452703
Time taken for Epoch 8: 10.94s - F1: 0.06452703
2026-02-12 08:43:45 - INFO - Time taken for Epoch 8: 10.94s - F1: 0.06452703
Time taken for Epoch 9: 10.90s - F1: 0.06452703
2026-02-12 08:43:56 - INFO - Time taken for Epoch 9: 10.90s - F1: 0.06452703
Time taken for Epoch 10: 10.79s - F1: 0.06452703
2026-02-12 08:44:06 - INFO - Time taken for Epoch 10: 10.79s - F1: 0.06452703
Time taken for Epoch 11: 10.76s - F1: 0.06452703
2026-02-12 08:44:17 - INFO - Time taken for Epoch 11: 10.76s - F1: 0.06452703
Performance not improving for 10 consecutive epochs.
Performance not improving for 10 consecutive epochs.
2026-02-12 08:44:17 - INFO - Performance not improving for 10 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:44:20 - INFO - Fine-tuning models
Time taken for Epoch 1:2.00 - F1: 0.1167
2026-02-12 08:44:22 - INFO - Time taken for Epoch 1:2.00 - F1: 0.1167
Time taken for Epoch 2:3.03 - F1: 0.1086
2026-02-12 08:44:25 - INFO - Time taken for Epoch 2:3.03 - F1: 0.1086
Time taken for Epoch 3:1.79 - F1: 0.1091
2026-02-12 08:44:27 - INFO - Time taken for Epoch 3:1.79 - F1: 0.1091
Time taken for Epoch 4:1.81 - F1: 0.1096
2026-02-12 08:44:29 - INFO - Time taken for Epoch 4:1.81 - F1: 0.1096
Time taken for Epoch 5:1.79 - F1: 0.1027
2026-02-12 08:44:30 - INFO - Time taken for Epoch 5:1.79 - F1: 0.1027
Time taken for Epoch 6:1.79 - F1: 0.0970
2026-02-12 08:44:32 - INFO - Time taken for Epoch 6:1.79 - F1: 0.0970
Time taken for Epoch 7:1.80 - F1: 0.1100
2026-02-12 08:44:34 - INFO - Time taken for Epoch 7:1.80 - F1: 0.1100
Time taken for Epoch 8:1.81 - F1: 0.0941
2026-02-12 08:44:36 - INFO - Time taken for Epoch 8:1.81 - F1: 0.0941
Time taken for Epoch 9:1.81 - F1: 0.1072
2026-02-12 08:44:38 - INFO - Time taken for Epoch 9:1.81 - F1: 0.1072
Time taken for Epoch 10:1.80 - F1: 0.0904
2026-02-12 08:44:39 - INFO - Time taken for Epoch 10:1.80 - F1: 0.0904
Time taken for Epoch 11:1.79 - F1: 0.0821
2026-02-12 08:44:41 - INFO - Time taken for Epoch 11:1.79 - F1: 0.0821
Performance not improving for 10 consecutive epochs.
2026-02-12 08:44:41 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.1167 - Best Epoch:0
2026-02-12 08:44:41 - INFO - Best F1:0.1167 - Best Epoch:0
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.1219, Test ECE: 0.1517
2026-02-12 08:44:48 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.1219, Test ECE: 0.1517
All results: {'f1_macro': 0.1219428202697008, 'ece': 0.151737192016817}
2026-02-12 08:44:48 - INFO - All results: {'f1_macro': 0.1219428202697008, 'ece': 0.151737192016817}

Total time taken: 272.24 seconds
2026-02-12 08:44:48 - INFO - 
Total time taken: 272.24 seconds
2026-02-12 08:44:48 - INFO - Trial 8 finished with value: 0.1219428202697008 and parameters: {'learning_rate': 0.0002023610557470539, 'weight_decay': 0.0006033036248342923, 'batch_size': 8, 'co_train_epochs': 12, 'epoch_patience': 10}. Best is trial 4 with value: 0.5570103374065091.
Using devices: cuda, cuda
2026-02-12 08:44:48 - INFO - Using devices: cuda, cuda
Devices: cuda, cuda
2026-02-12 08:44:48 - INFO - Devices: cuda, cuda
Starting log
2026-02-12 08:44:48 - INFO - Starting log
Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
2026-02-12 08:44:48 - INFO - Dataset: humanitarian10, Event: cyclone_idai_2019, N: 5, Seed: 1234, HF Model: GPT-4o, NumShots: 5, PLM: bert-tweet
/opt/conda/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))
Learning Rate: 0.00033371414423911835
Weight Decay: 6.51029488347075e-05
Batch Size: 32
No. Epochs: 16
Epoch Patience: 3
 Accumulation Steps: 2
2026-02-12 08:44:48 - INFO - Learning Rate: 0.00033371414423911835
Weight Decay: 6.51029488347075e-05
Batch Size: 32
No. Epochs: 16
Epoch Patience: 3
 Accumulation Steps: 2
Using Bert Tweet model: bert-tweet
Generating initial weights
2026-02-12 08:44:50 - INFO - Generating initial weights
Time taken for Epoch 1:8.27 - F1: 0.0152
2026-02-12 08:44:59 - INFO - Time taken for Epoch 1:8.27 - F1: 0.0152
Time taken for Epoch 2:8.22 - F1: 0.1632
2026-02-12 08:45:07 - INFO - Time taken for Epoch 2:8.22 - F1: 0.1632
Time taken for Epoch 3:8.12 - F1: 0.1383
2026-02-12 08:45:16 - INFO - Time taken for Epoch 3:8.12 - F1: 0.1383
Time taken for Epoch 4:8.12 - F1: 0.1826
2026-02-12 08:45:24 - INFO - Time taken for Epoch 4:8.12 - F1: 0.1826
Time taken for Epoch 5:8.14 - F1: 0.2162
2026-02-12 08:45:32 - INFO - Time taken for Epoch 5:8.14 - F1: 0.2162
Time taken for Epoch 6:8.14 - F1: 0.2206
2026-02-12 08:45:40 - INFO - Time taken for Epoch 6:8.14 - F1: 0.2206
Time taken for Epoch 7:8.21 - F1: 0.2354
2026-02-12 08:45:48 - INFO - Time taken for Epoch 7:8.21 - F1: 0.2354
Time taken for Epoch 8:8.31 - F1: 0.2381
2026-02-12 08:45:57 - INFO - Time taken for Epoch 8:8.31 - F1: 0.2381
Time taken for Epoch 9:8.26 - F1: 0.2342
2026-02-12 08:46:05 - INFO - Time taken for Epoch 9:8.26 - F1: 0.2342
Time taken for Epoch 10:8.21 - F1: 0.2252
2026-02-12 08:46:13 - INFO - Time taken for Epoch 10:8.21 - F1: 0.2252
Time taken for Epoch 11:8.15 - F1: 0.2373
2026-02-12 08:46:21 - INFO - Time taken for Epoch 11:8.15 - F1: 0.2373
Time taken for Epoch 12:8.11 - F1: 0.2172
2026-02-12 08:46:29 - INFO - Time taken for Epoch 12:8.11 - F1: 0.2172
Time taken for Epoch 13:8.21 - F1: 0.2154
2026-02-12 08:46:37 - INFO - Time taken for Epoch 13:8.21 - F1: 0.2154
Time taken for Epoch 14:8.15 - F1: 0.2158
2026-02-12 08:46:46 - INFO - Time taken for Epoch 14:8.15 - F1: 0.2158
Time taken for Epoch 15:8.15 - F1: 0.2190
2026-02-12 08:46:54 - INFO - Time taken for Epoch 15:8.15 - F1: 0.2190
Time taken for Epoch 16:8.18 - F1: 0.2143
2026-02-12 08:47:02 - INFO - Time taken for Epoch 16:8.18 - F1: 0.2143
Best F1:0.2381 - Best Epoch:8
2026-02-12 08:47:02 - INFO - Best F1:0.2381 - Best Epoch:8
Using Bert Tweet model: bert-tweet
Starting co-training
2026-02-12 08:47:03 - INFO - Starting co-training
Time taken for Epoch 1: 13.63s - F1: 0.06452703
2026-02-12 08:47:17 - INFO - Time taken for Epoch 1: 13.63s - F1: 0.06452703
Time taken for Epoch 2: 14.78s - F1: 0.06452703
2026-02-12 08:47:32 - INFO - Time taken for Epoch 2: 14.78s - F1: 0.06452703
Time taken for Epoch 3: 13.62s - F1: 0.06452703
2026-02-12 08:47:46 - INFO - Time taken for Epoch 3: 13.62s - F1: 0.06452703
Time taken for Epoch 4: 13.65s - F1: 0.06452703
2026-02-12 08:47:59 - INFO - Time taken for Epoch 4: 13.65s - F1: 0.06452703
Performance not improving for 3 consecutive epochs.
Performance not improving for 3 consecutive epochs.
2026-02-12 08:47:59 - INFO - Performance not improving for 3 consecutive epochs.
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:775: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:776: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/co_trained_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Fine-tuning models
2026-02-12 08:48:02 - INFO - Fine-tuning models
Time taken for Epoch 1:1.61 - F1: 0.0645
2026-02-12 08:48:04 - INFO - Time taken for Epoch 1:1.61 - F1: 0.0645
Time taken for Epoch 2:2.83 - F1: 0.0212
2026-02-12 08:48:07 - INFO - Time taken for Epoch 2:2.83 - F1: 0.0212
Time taken for Epoch 3:1.57 - F1: 0.0186
2026-02-12 08:48:08 - INFO - Time taken for Epoch 3:1.57 - F1: 0.0186
Time taken for Epoch 4:1.57 - F1: 0.0030
2026-02-12 08:48:10 - INFO - Time taken for Epoch 4:1.57 - F1: 0.0030
Time taken for Epoch 5:1.57 - F1: 0.0039
2026-02-12 08:48:12 - INFO - Time taken for Epoch 5:1.57 - F1: 0.0039
Time taken for Epoch 6:1.57 - F1: 0.0044
2026-02-12 08:48:13 - INFO - Time taken for Epoch 6:1.57 - F1: 0.0044
Time taken for Epoch 7:1.56 - F1: 0.0010
2026-02-12 08:48:15 - INFO - Time taken for Epoch 7:1.56 - F1: 0.0010
Time taken for Epoch 8:1.55 - F1: 0.0010
2026-02-12 08:48:16 - INFO - Time taken for Epoch 8:1.55 - F1: 0.0010
Time taken for Epoch 9:1.55 - F1: 0.0010
2026-02-12 08:48:18 - INFO - Time taken for Epoch 9:1.55 - F1: 0.0010
Time taken for Epoch 10:1.56 - F1: 0.0218
2026-02-12 08:48:19 - INFO - Time taken for Epoch 10:1.56 - F1: 0.0218
Time taken for Epoch 11:1.55 - F1: 0.0645
2026-02-12 08:48:21 - INFO - Time taken for Epoch 11:1.55 - F1: 0.0645
Performance not improving for 10 consecutive epochs.
2026-02-12 08:48:21 - INFO - Performance not improving for 10 consecutive epochs.
Best F1:0.0645 - Best Epoch:0
2026-02-12 08:48:21 - INFO - Best F1:0.0645 - Best Epoch:0
Using Bert Tweet model: bert-tweet
/tmp/ipykernel_213/485473895.py:816: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_1.load_state_dict(torch.load(model_1_path))
/tmp/ipykernel_213/485473895.py:817: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_2.load_state_dict(torch.load(model_2_path))
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_1_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt
Successfully deleted /home/jovyan/saved_models/humanitarian10/optuna-bertweet-cyclone-idai-2019-label5-set1/final_model_2_optuna-bertweet-cyclone-idai-2019-label5-set1_gpt4o_5_shot_bert-tweet_5_seed_1234.pt


Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.0644, Test ECE: 0.1212
2026-02-12 08:48:26 - INFO - 

Hf Model: GPT-4o PLM: bert-tweet Dataset: humanitarian10, NumShots: 5, N: 5 Test SEED: 1234 F1: 0.0644, Test ECE: 0.1212
All results: {'f1_macro': 0.06440382941688425, 'ece': 0.12116407223323189}
2026-02-12 08:48:26 - INFO - All results: {'f1_macro': 0.06440382941688425, 'ece': 0.12116407223323189}

Total time taken: 218.20 seconds
2026-02-12 08:48:26 - INFO - 
Total time taken: 218.20 seconds
2026-02-12 08:48:26 - INFO - Trial 9 finished with value: 0.06440382941688425 and parameters: {'learning_rate': 0.00033371414423911835, 'weight_decay': 6.51029488347075e-05, 'batch_size': 32, 'co_train_epochs': 16, 'epoch_patience': 3}. Best is trial 4 with value: 0.5570103374065091.

[BEST TRIAL RESULTS]
2026-02-12 08:48:26 - INFO - 
[BEST TRIAL RESULTS]
F1 Score: 0.5570
2026-02-12 08:48:26 - INFO - F1 Score: 0.5570
Params: {'learning_rate': 0.0001100237976646814, 'weight_decay': 5.600774647939888e-05, 'batch_size': 32, 'co_train_epochs': 16, 'epoch_patience': 5}
2026-02-12 08:48:26 - INFO - Params: {'learning_rate': 0.0001100237976646814, 'weight_decay': 5.600774647939888e-05, 'batch_size': 32, 'co_train_epochs': 16, 'epoch_patience': 5}
  learning_rate: 0.0001100237976646814
2026-02-12 08:48:26 - INFO -   learning_rate: 0.0001100237976646814
  weight_decay: 5.600774647939888e-05
2026-02-12 08:48:26 - INFO -   weight_decay: 5.600774647939888e-05
  batch_size: 32
2026-02-12 08:48:26 - INFO -   batch_size: 32
  co_train_epochs: 16
2026-02-12 08:48:26 - INFO -   co_train_epochs: 16
  epoch_patience: 5
2026-02-12 08:48:26 - INFO -   epoch_patience: 5

Total time taken: 3473.83 seconds
2026-02-12 08:48:26 - INFO - 
Total time taken: 3473.83 seconds